[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "FCOR 599: Workshop Artifacts",
    "section": "",
    "text": "Home Page\nHey there,\nThis webpage contains workshop artifacts created by your FCOR 599 TA’s. Many of these artifacts were initially developed as workshops, and have been archived here for your reference. The topics range from cartography to advanced figure development and python scripting - most of which were requested by previous cohorts of your peers. If you have any questions, or have suggestions for additional modules that can be included here, please talk to your FCOR 599 teaching team.\n\n\n\nReuseCC BY 4.0",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "cartography.html",
    "href": "cartography.html",
    "title": "Cartography",
    "section": "",
    "text": "“All maps are lies, but some are useful” ~ Dr. Paul Pickell, circa 2020\nCartography is the art and science of creating, studying, and distributing maps and other visual representations of geographical areas. It involves a combination of scientific and artistic skills to communicate information about a place.\n\n\n\nEratosthenes’ World Map (220 BCE) showing the results of Alexander the Great’s conquests. Eratosthenes was the first geographer to include parallels and meridians in his maps, allowing for the calculation of distance.",
    "crumbs": [
      "Cartography"
    ]
  },
  {
    "objectID": "cartography.html#quarto",
    "href": "cartography.html#quarto",
    "title": "Cartography",
    "section": "",
    "text": "blah blah blah",
    "crumbs": [
      "Cartography"
    ]
  },
  {
    "objectID": "art_of_maps.html",
    "href": "art_of_maps.html",
    "title": "The Art of Map Making",
    "section": "",
    "text": "Lets add some text here about the history of maps. Some are very beautiful, some less so. Although we rightfully place emphasis on ensuring the scientific integrity of maps, the artistic component of map making is a key component of science communication, and should not be overlooked.",
    "crumbs": [
      "Cartography",
      "The Art of Map Making"
    ]
  },
  {
    "objectID": "cartography.html#what-is-cartography",
    "href": "cartography.html#what-is-cartography",
    "title": "Cartography",
    "section": "",
    "text": "Cartography is the art and science of creating, studying, and distributing maps and other visual representations of geographical areas. It involves a combination of scientific and artistic skills to communicate information about a place.",
    "crumbs": [
      "Cartography"
    ]
  },
  {
    "objectID": "arcgis_pro_demo.html",
    "href": "arcgis_pro_demo.html",
    "title": "ArcGIS Pro Demo",
    "section": "",
    "text": "As MGEM students, you all have access to ArcGIS Pro, a powerful GIS software that allows users to perform geospatial tasks and create beautiful maps. This demo focuses on the map-making capabilities of ArcGIS Pro, and provides an easy reference guide for the implementation of core cartography concepts and best-practices.",
    "crumbs": [
      "Cartography",
      "ArcGIS Pro Demo"
    ]
  },
  {
    "objectID": "interactive_maps.html",
    "href": "interactive_maps.html",
    "title": "Interactive Maps",
    "section": "",
    "text": "Although conventional maps are static and do not allow for user interaction, geospatial practitioners have developed exciting new ways in which we can present geographic information in interactive formats. Although not exhaustive by any means, this section will cover several key ways in which you can create digital maps that allow for user-interaction.",
    "crumbs": [
      "Interactive Maps"
    ]
  },
  {
    "objectID": "leaflet.html",
    "href": "leaflet.html",
    "title": "Leaflet",
    "section": "",
    "text": "The Basics:\nMany software and coding packages can be used to create interactive maps. In this particular demo, we will show you an easy way to produce interactive maps in leaflet - a popular R package. Leaflet is intuitive, fast, and has many arguments that allow us to easily adjust the way in which we present our maps. In the example below, we used NTEMs land cover from 2020 to product a simple interactive map for Vancouver Island. In the code below, you will notice that we add in a basemap using the ‘addProviderTiles’ argument. You can browse for available leaflet basemaps here: https://leaflet-extras.github.io/leaflet-providers/preview/\n\nl &lt;- leaflet(width = 600, height = 600)%&gt;%\n  \n  #lets use some base imagery from ESRI\n  addProviderTiles(\"Esri.WorldImagery\") %&gt;%\n  \n  #now lets add our NTEMS land cover from 2020\n  addRasterImage(ntems2020, \n                 #you can increase the allowable size of the rast here\n                 maxBytes = 10 * 1024 *1024) %&gt;%\n  #add a legend\n  addRasterLegend(ntems2020, opacity = 1)%&gt;%\n  #add scale bar\n  addScaleBar(position = c(\"bottomleft\"))\n\n\n\n\n\n\n\n \nComparing/Showing Multiple Layers:\nNow let’s step things up a notch, and add some additional content to our map. For the purposes of this demonstration, let’s say you have been tasked with showcasing changes in land cover on Vancouver Island from 2000 to 2020. To do so, we can use 2 key leaflet functionalities: 1) adding a toggle menu - allowing us to switch between layers, 2) adding a ‘slider’, which we can use to visualize two layers side-by-side.\n1) In order to add a toggle menu and provide NTEMs land cover of both 2000 and 2020 in our map, we do need to provide a name for our layers using the ‘group’ argument within the ‘addRasterImage’ function.\n\nl2 &lt;- leaflet(width = 600, height = 600)%&gt;%\n  \n  #lets use some base imagery from ESRI\n  addProviderTiles(\"Esri.WorldImagery\") %&gt;%\n  \n  #now lets add our NTEMS land cover from 2000\n  addRasterImage(ntems2000, \n                 #you can increase the allowable size of the rast here\n                 maxBytes = 10 * 1024 *1024,\n                 #provide a name for the layer\n                 group = \"LC-2000\") %&gt;%\n  \n  #now lets add our NTEMS land cover from 2020\n  addRasterImage(ntems2020, \n                 #you can increase the allowable size of the rast here\n                 maxBytes = 10 * 1024 *1024,\n                 #provide a name for the layer\n                 group = \"LC-2020\") %&gt;%\n  \n  #allow for layers to be toggles on/off by adding them to the layers control\n  addLayersControl(baseGroups = c(\"LC-2000\",\"LC-2020\")) %&gt;%\n  \n  #add a legend\n  addRasterLegend(ntems2000, opacity = 1)%&gt;%\n  \n  #add scale bar\n  addScaleBar(position = c(\"bottomleft\"))\n\n\n\n\n\n\n\n \n2) In order to visualize layers side-by-side and compare them using a window slider, we need to create a left and right pane, and assign our NTEMS land cover rasters to one of these panes.\n\nl3 &lt;- leaflet(width = 600, height = 600)%&gt;%\n  \n  #set up the two map panes\n  addMapPane(\"right\", zIndex = 1) %&gt;%\n  addMapPane(\"left\",  zIndex = 2) %&gt;%\n  \n  #add the ESRI basemap to both map panes\n  addProviderTiles(\"Esri.WorldImagery\", group = \"base\", layerId = \"baseid1\", options = pathOptions(pane = \"right\")) %&gt;%\n  addProviderTiles(\"Esri.WorldImagery\", group = \"base\", layerId = \"baseid2\", options = pathOptions(pane = \"left\")) %&gt;%\n  \n  #now lets add our NTEMS land cover from 2000\n  addRasterImage(ntems2000, \n                 #you can increase the allowable size of the rast here\n                 maxBytes = 10 * 1024 *1024,\n                 #provide a name for the layer\n                 group = \"LC-2000\",\n                 #assign to a pane\n                 options = leafletOptions(pane = \"left\")) %&gt;%\n  \n  #now lets add our NTEMS land cover from 2020\n  addRasterImage(ntems2020, \n                 #you can increase the allowable size of the rast here\n                 maxBytes = 10 * 1024 *1024,\n                 #provide a name for the layer\n                 group = \"LC-2020\",\n                 #assign to a pane\n                 options = leafletOptions(pane = \"right\")) %&gt;%\n  \n  #allow for layers to be toggles on/off by adding them to the layers control\n  addLayersControl(overlayGroups = c(\"LC-2000\", \"LC-2020\")) %&gt;%\n  \n  #add slider control\n  addSidebyside(layerId = \"sidecontrols\",\n                rightId = \"baseid1\",\n                leftId  = \"baseid2\",\n                options = list(padding = 0)) %&gt;%\n  \n  #add a legend\n  addRasterLegend(ntems2000, opacity = 1)%&gt;%\n  \n  #add scale bar\n  addScaleBar(position = c(\"bottomleft\"))",
    "crumbs": [
      "Interactive Maps",
      "Leaflet"
    ]
  },
  {
    "objectID": "Landing_Page/index.html",
    "href": "Landing_Page/index.html",
    "title": "FCOR 599: Workshop Artifacts",
    "section": "",
    "text": "Home Page\nHey there,\nThis webpage contains workshop artifacts created by your FCOR 599 TA’s. Many of these artifacts were initially developed as workshops, and have been archived here for your reference. The topics range from cartography to advanced figure development and python scripting - most of which were requested by previous cohorts of your peers. If you have any questions, or have suggestions for additional modules that can be included here, please talk to your FCOR 599 teaching team.\n\n\n\nReuseCC BY 4.0",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "Cartography/arcgis_pro_demo.html",
    "href": "Cartography/arcgis_pro_demo.html",
    "title": "ArcGIS Pro Demo",
    "section": "",
    "text": "As MGEM students, you all have access to ArcGIS Pro, a powerful GIS software that allows users to perform geospatial tasks and create beautiful maps. This demo focuses on the map-making capabilities of ArcGIS Pro and provides an easy reference guide for implementing core cartographic concepts and best practices. While you may have experience using ArcGIS either in or outside of MGEM, you can use this guide as a best practice resource to refer to either during your courses, or any time you’re trying to solve a tricky map.\n\n\nDisplaying your map frame in an appropriate coordinate system is important for visualization. For example, the two photos below show very different projections, and while both are technically not wrong, the one using the Mercator is clearly much better suited for our data\n\n\n\nRobinson\n\n\n\n\n\nMercator\n\n\nYou can change the projection of your map view by right-clicking on the ‘Map’ in your drawing order, and going to properties (below-left). Under the Coordinate Systems tab, you may then select a projection suitable for viewing your map (bottom-right).\nTip: Using the search bar can be the fastest way to find a projection you’re looking for, but the layers drop-down will have all the projections of any layers on your map already ready for easy selection. You can also save your most common projections under Favorites if you find yourself using the same projections over and over.\n\n\n\nSelecting a projection\n\n\n\n\n\nIn order to help our map-viewers out a little more, we can insert another map frame on our layout, showing where in Canada we are. To do so we will want to put this data in a separate ‘Map’ tab. To create one, simply click on the ‘New Map’ button on the top left of your Arc screen. Now that we have this new ’Map”, and have added our data, we can go back to our layout, and add our helpful extent map.\n\n\n\nSome of the helpful buttons for creating an inset map highlighted\n\n\nAfter selecting your layout, navigate to the ‘Insert’ tab on the top of your screen, and select ‘Map Frame’. This will give you an overview of all the maps you have created in your Arc Project, and will allow you to select one to add to your layout. We can now select the one created above, and add it to our layout by dragging a box in the spot where we wish to place it. You can then add elements such as leader lines, and separate scale bars if you feel it is appropriate.\n\n\n\n\n\nLegends are a fundamental component of any map. It is where we give the map-viewer the tools they need to interpret the data that we are presenting to them. Inserting a Legend is relatively straightforward – you can simply navigate to the ‘Insert’ tab for your layout, and click on ‘Legend’. However, once you have inserted a Legend, you may find it doesn’t look exactly appealing, and we may have to take some steps to clean things up a bit. First and foremost, there may be layers on display which we do not wish to include in our legend – to avoid clutter.\n\n\n\nCustomizing you legend can probably be one of the more frustrating things to do in ArcGIS. The quickest way to make changes is to use the properties of the legend, accessed by right clicking it and selecting the Properties option at the bottom. This will open a window on the right with lots and lots of options on things you can change. See this link for some helpful tips Legends Tips\nChanging the name of your layers can be one of the easiest things to forget when creating a map in ArcGIS, but probably the biggest difference maker when creating a map. To do so, simply right click the layer to access its Properties. In the top option, General, there is a name bar where you can type whatever name you feel is best, the great thing about this is you can use spaces and capitalized letters which often isn’t the default with GIS!\n\n\n\n\nIt can sometimes be easy to forget that the people looking at your maps are not as familiar with the data, area, and topic as you are. People from all over the world map end up looking at your map, so it is always important to make sure everyone – regardless of their background knowledge – is able to interpret and read your map. For the example shown in this document so far, people from Eastern Canada may recognize the Hudson’s Bay area in the map, yet many of us may be initially confused as to where this study area is located. There are a few ways by which we can make this easier for our map-viewer to interpret. On of these ways is by inserting grid-lines which show lat/lon lines across our map. To do so, navigate to the ‘Grid’ option in the Insert bar for your layout, and select one of the grid options.\n\n\n\nGridlines\n\n\nThis will add grid-lines to our drawing order, as well as map view. Similarly to the legend, we can right click on the grid lines in our drawing order, select properties, and make adjustments as we wish to alter the appearance of thegrid lines (not shown here).\n\n\n\nNow that we have got ourselves a nice looking map, we have to add the finishing touches. No map is complete without the essential North Arrow and Scale Bars. Thankfuly, both are easy to add! Simply select the ‘North Arrow’ Dropdown at the top of your screen, and choose whichever strikes your fancy.\nFor scale bars, simply select the ‘Scale Bar’ dropdown, select one of the available options, and drag a box where you would like to place it. Now it is important to note that when you add a scale bar or north arrow, it will do so based on the map frame you have selected in your layout. Since we are making use of an inset in this example, we will then need to make sure to add a second scale bar to show the scale of our inset. Simply select the inset map frame in the layout, and add a second scale bar – placing it in an appropriate spot.",
    "crumbs": [
      "Cartography",
      "ArcGIS Pro Demo"
    ]
  },
  {
    "objectID": "Cartography/art_of_maps.html",
    "href": "Cartography/art_of_maps.html",
    "title": "The Art of Map Making",
    "section": "",
    "text": "Although the emphasis in this course and programme is rightly on ensuring the scientific integrity of maps, the artistic component of mapmaking is a key component of science communication and should not be overlooked. Cartography is the art and science of mapmaking. Finding the balance between art and science can be very difficult and will look different for each individual map maker. However, finding this balance is key to creating beautiful maps that people want to look at, but that also effectively communicate your data and your take-home message.\nMap making, especially cartography, is an art as we have just discussed. There are so many beautiful maps and amazing ways to display data or information. While here at MGEM, or in any GIS position or work you do, it’s always helpful and inspiring to find maps that tell a story visually. These can either inspire you to make better maps, or maybe even give you ideas about how you might want to visualise data.\n\n\nThere are many beautiful maps out in the world that are more art than science but that doesn’t disqualify them from being called a map. Here are a few examples of what might not traditionally be called maps in a scientific sense, but can be used as either a cool visualization or maybe even some inspiration for your work:\n\n\n\n\n\n\n\nWhistler village, Canada, by James Niehues\n\n\nMaps like the one above are a great example that not every map needs to have every single detail shown, like we’ve talked about “all maps are lies”, so sometimes you need to lie a little to better convey a message and visualize your work.\n\n\n\n3D map of Manhattan by Luis Dilger\n\n\nWhile these shift a little bit from what we talked about in the cartography section of today, hopefully these can serve as a reminder that map making is an art its core, don’t be afraid to put your own style and touch on your maps!",
    "crumbs": [
      "Cartography",
      "The Art of Map Making"
    ]
  },
  {
    "objectID": "Cartography/cartography.html",
    "href": "Cartography/cartography.html",
    "title": "Cartography",
    "section": "",
    "text": "Cartography is the art and science of creating, studying, and distributing maps and other visual representations of geographical areas. It involves a combination of scientific and artistic skills to communicate information about a place. In this workshop module, you will learn about the history and modern applications of cartography, followed by some specific demonstrations on the art of map making and advanced map making in ArcGIS Pro.\n\nBrief History of Cartography\nIn our modern world, we have access to detailed street maps, global satellite imagery, and GPS navigation. Through these tools, maps are often seen as direct representations of our environment - but how did we arrive at this point? Maps are one of the oldest forms of human communication, serving as tools which help us make sense of our surroundings at various scales (Harley and Woodward 1994). Historically, the map served as an appealing method of communication since it did not require formal literacy from its’ creator or user. However, this does not mean maps were easy to produce - having to provide two-dimensional combinations of shapes, sizes and orientations between locations. Indeed, many early maps failed to to take one or more of these elements into account, resulting in maps they may be more symbolic that literal in their representation of the world. Today, many of these works are on display at museums across the world, valued as anthropological artifacts mroe than as geographic reference material. For example, one of the earliest and most famous world maps was produced on clay tablets in Babylon ~ 600 BCE. This map captured the Babylon and Euphrates rivers, along with the neighboring cities of Assyria and Susa. Outside the circular disk representing the known world, triangular shapes point to lands from Babylonian myth and cosmology (“Babylonian World Map Tablet,” n.d.)\n\n\n\nBablynonian World Map (circa ~600 BCE)\n\n\nAs scientific knowledge advanced throughout classical antiquity, advances in mapping followed suit. The Greeks were among the first to explore mathematical concepts for representing the Earth’s curved surface on a two-dimensional plane - starting in the 6th century BCE. It wasn’t until the 2nd century CE however, that Greek Mathematician and Astrologer Ptolemy (100-170 CE) produced the planishpaerium, a celestial chart mapping stars onto a two-dimensional plane using the first stereographic projection (Harley and Woodward 1994). His geographia provided an instructional framework for the projection of geographic coordinates onto two-dimensional planes, forming the foundation of cartographic advances for centuries to come. Shortly after Ptolemy’s success in the Western world, Chinese cartographer Pei Xiu (224-271 CE) revolutionized map-making in China by prescribing key principles for the use of rectangular grids and graduated scales in measuring distances for the creation of maps.\nDuring the middle ages (5th to 15th centuries) advancement in map-making was largely concentrated in the Islamic world. Built on the foundations of Ptolemy’s methods, maps of the known world were expanded and improved based on information from explorers and merchants travelling from the Muslim world to Spain, India, Africa, China and Russia. Notably, the 9th century Persian mathematician and geographer Habash al-Hasib al-Marwazi developed one of the earliest examples of spherical trigonometry in cartography by projecting coordinates to different coordinate systems. Founded in the early 10th century, these methods were applied to develop atlases and world maps at the famous Balkhi school of terrestrial mapping in Baghdad (Wheatley 1996) (Hiatt and Brill Online Books 2021). Meanwhile in Europe, most maps produced during this era served more as symbolic representations than mathematical navigation tools. These maps were not typically made to serve as general reference tools for navigation, typically being confined to specific areas and use-cases (Harley and Woodward 1994). It was not until the 11th century that the transmission of scientific knowledge from the Arabic-Islamic world began to signicantly effect European-Christian life (Hiatt and Brill Online Books 2021).\nThe next major period of cartographic advancement occurred during the ‘Age of Exploration’ (1450-1750 CE), where European nations began navigating and colonizing the globe. With a particular focus on navigating ships across vast oceans, the Mercator projection was invented in 1569 by the Belgian geographer/cartographer Gerardus Mercator (“Gerardus Mercator,” n.d.). Although many advances in cartography have taken place since, the Mercator projection remains possibly the most famous projection of all time, hanging on many a classroom wall to this day.\n\n\n\nGerardus Mercator’s 1569 Map of the World\n\n\nDespite these technological advances in mathematics and map-making, representations of our environments continued to contain notable flaws and mistakes. In the early 1500’s, Spanish author Garcia Rodriguez de Montalvo first described the ‘mythical island’ of California. Despite exploration of the area by explorers (who determined California was a peninsula) map-makers simply denied their claims and continued to portray California as an island over the next two centuries. Although seemingly obvious now, such ‘mistakes’ reflect a core concept of cartography that persists today - that maps reflect knowledge, ideas and assumptions which are a susceptible to human error. In our modern era, we have access to highly accurate information about our environments, countries, cities, navigation routes, etc. Regardless, the way in which we present this information to an audience is an exercise that requires diligence and expertise. In the workshops associated to this Cartography section, we will discuss some key considerations and best-practices for modern map-making.\n\n\n\n1720 Map of California by Nicholas de Fer (Paris)\n\n\n\n\n\n\n\nReferences\n\n“Babylonian World Map Tablet.” n.d. https://www.britishmuseum.org/collection/object/W_1882-0714-509.\n\n\n“Gerardus Mercator.” n.d. https://education.nationalgeographic.org/resource/gerardus-mercator.\n\n\nHarley, John Brian, and David Woodward. 1994. “Cartography in Prehistoric, Ancient, and Medieval Europe and the Mediterranean (1987). Vol. 1 of the History of Cartography., Eds.” Cartography in the Traditional East and Southeast Asian Societies 2.\n\n\nHiatt, Alfred, and Brill Online Books. 2021. Cartography Between Christian Europe and the Arabic-Islamic World, 1100-1500: Divergent Traditions. 1st ed. Vol. 3. Book, Whole. Leiden;Boston; Brill. https://ubc.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwfV3PS8MwFH647aA3dYpzbuQyT1aypK7pcRsbCsOT95I2KfZSocyD_70vr-nsRvESQiDkyw-Sl5fvywOQ4pkHJ3sC7ggqUsaoVIcZrmsTZlxZtZibWFgr9AlVp5Hj_5X9N_EdAabJXy5CFxIzemzU_tXe_wI9E9yzoDBXi_gL527ktQccM0Qq5GiCYbqsdFpkAU1RkWEB_WWKIzCjw5MHaFNxzOOSwtQ4OoVTRbn6lTY18aoHPbyJ1AEWjmzZltbfHWjbSxhYp3K4gjNbXsO5D4X--TOEXasHzONnB_Ssxs4QOUPc7Bg1I8xP7ID3Bsbbzcf6NcD2E-8pStz3bwJNLnkL_fKrtHfAZJ4qp181Tq0wj3MtpYnTEC-SeSa55iNgTWcSet71nNJks1ov0NZC624Ew65GRjBpFzePbQk99cXRy313tTFcCEcrIS_IA_T31bed0DBOaXSnMFiudu9vv_anvEM.\n\n\nWheatley, Paul. 1996. “Asia in the History of Cartography. \"The History of Cartography, Volume Two, Book One: Cartography in the Traditional Islamic and South Asian Societies. Volume Two, Book Two: Cartography in the Traditional East and Southeast Asian Societies\". Edited by j. B. Harley and David Woodward.” Imago Mundi (Lympne) 48 (Journal Article): 216. https://ubc.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwtV1JT8JAFB6Bi16Ma1zQvOix0NCFJSYewKBConBo4pEAnSYcKIYlht_pH_K9N1PasOrBS9N0yjeh38f0zeMtQji2WcgvrQluYNu9vo_mc7nctd0S1THvWT6Koxho304iVCf1HaXGxBf_lXm8htxTJu0f2F-A4gU8Rw3gEVWAx1_pAKfsRsGMqiaIzskaT3W1ahPpt72NwxwJy2uY4X2xY5XzI1ohZ7UnboxmwdefP9AuRlacLgnL3fqMKmdtqmBR2qWvw6bz3dj17mQaA1MPomVw_F6mUffZqkYzu2kaNZPSlmgh5BBsCug3PkYj7lydtNMbQ4pPGc5Cf8BNT-bDz1AmvCb8DtPu_kVwpa-zCZedJwrsjcHiKCpOJitU8sWS6r8cvShUSdDFSr-mgne72uq0G61O6x03IlS7fegP-tNHGeZnk7RIO5bu7rBwCaD9p__nUtOtWARs5nhH4lDvT6CqhHQsUjI8EfsvUvNwupelZwyDEPCRg1YMjAJICgruvI2DOVCEA5KcA6IbUEoPyVsi9ATZoIUESBsw38BcQyykVVw824lLIopBSUTLwHcmKAlBbw5NE2omKAnxx1hCEEnoTNw_172n13z0eDv6Nzrp0B6hYqHd7TjnIhOOQnkhoC97lPVtIUN9l3ZR0nFtKrdZDqQVuMGlyG5Duto-fC0OYjVmRWY6nskbrvtxy_r4AcfVtLQ.",
    "crumbs": [
      "Cartography"
    ]
  },
  {
    "objectID": "Interactive_Maps/interactive_maps.html",
    "href": "Interactive_Maps/interactive_maps.html",
    "title": "Interactive Maps",
    "section": "",
    "text": "Although conventional maps are static and do not allow for user interaction, geospatial practitioners have developed exciting new ways in which we can present geographic information in interactive formats. Although not exhaustive by any means, this section will cover several key ways in which you can create digital maps that allow for user-interaction.",
    "crumbs": [
      "Interactive Maps"
    ]
  },
  {
    "objectID": "Interactive_Maps/leaflet.html",
    "href": "Interactive_Maps/leaflet.html",
    "title": "Leaflet",
    "section": "",
    "text": "Many software and coding packages can be used to create interactive maps. In this particular demo, we will show you an easy way to produce interactive maps in leaflet - a popular R package. Leaflet is intuitive, fast, and has many arguments that allow us to easily adjust the way in which we present our maps. In the example below, we used NTEMs land cover from 2020 to product a simple interactive map for Vancouver Island. In the code below, you will notice that we add in a basemap using the ‘addProviderTiles’ argument. You can browse for available leaflet basemaps here: https://leaflet-extras.github.io/leaflet-providers/preview/\n\nl &lt;- leaflet(width = 600, height = 600)%&gt;%\n  \n  #lets use some base imagery from ESRI\n  addProviderTiles(\"Esri.WorldImagery\") %&gt;%\n  \n  #now lets add our NTEMS land cover from 2020\n  addRasterImage(ntems2020, \n                 #you can increase the allowable size of the rast here\n                 maxBytes = 10 * 1024 *1024) %&gt;%\n  #add a legend\n  addRasterLegend(ntems2020, opacity = 1)%&gt;%\n  #add scale bar\n  addScaleBar(position = c(\"bottomleft\"))",
    "crumbs": [
      "Interactive Maps",
      "Leaflet"
    ]
  },
  {
    "objectID": "E-Portfolio/eportfolio.html",
    "href": "E-Portfolio/eportfolio.html",
    "title": "E-Portfolio",
    "section": "",
    "text": "As part of FCOR 599, you are required to produce a professional E-Portfolio. This portfolio is intended to capture the breadth of skills you have developed throughout the program, including scientific writing & reporting, figure design, cartography, coding, etc. As has been introduced in the E-Portfolio workshop, a portfolio is essentially an organized digital collection of artifacts that highlight key pieces of work, accomplishments and skills. This is a great place for you to present your learning, experience, achievements, etc. - and serves as a great reference for researchers, colleagues and potential employers to see what you’re all about.\nIn other words, an E-Portfolio goes beyond what you might present in a resume or social media (i.e. linkedin) page, and allows you to express yourself through written work, images, media, etc. Rather than focusing on presenting entire bodies of finished work like a report, your E-Portfolio is a great place to demonstrate your learning and skills by presenting smaller pieces of work. Whilst many of your MGEM deliverables are the product of rubrics and assignment instructions, your E-Portfolio is ultimately entirely your own - so feel free to adjust, edit, add, and remove from your program deliverables as you see fit.\nWe highly recommend to design elements of learning into your E-Portfolio. Rather than just sharing a figure, you may want to also share some annotated code that you used to produce said figure. You could also add several iterations of a figure (of varying complexity) to demonstrate your learning trajectory. Before we dive into the techincal aspects of building your E-Portfolio using Quarto & GitHub, here are some key considerations from the UBC library workshop to remember:\n\nYour work will be visible to anyone on the internet. Ensure that you are representing yourself accurately.\nProvide credit to those who have contributed to your work.\nRespect and follow copyright and privacy laws where appropriate.",
    "crumbs": [
      "E-portfolio"
    ]
  },
  {
    "objectID": "E-Portfolio/eportfolio.html#quarto",
    "href": "E-Portfolio/eportfolio.html#quarto",
    "title": "E-Portfolio",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org.",
    "crumbs": [
      "E-portfolio (Quarto)"
    ]
  },
  {
    "objectID": "E-Portfolio/eportfolio.html#running-code",
    "href": "E-Portfolio/eportfolio.html#running-code",
    "title": "E-Portfolio",
    "section": "Running Code",
    "text": "Running Code\nWhen you click the Render button a document will be generated that includes both content and the output of embedded code. You can embed code like this:\n\n1 + 1\n\n[1] 2\n\n\nYou can add options to executable code like this\n\n\n[1] 4\n\n\nThe echo: false option disables the printing of code (only output is displayed).",
    "crumbs": [
      "E-portfolio (Quarto)"
    ]
  },
  {
    "objectID": "E-Portfolio/eportfolio.html#building-a-portfolio-in-quarto",
    "href": "E-Portfolio/eportfolio.html#building-a-portfolio-in-quarto",
    "title": "E-Portfolio",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org. In this module, we will be using Quarto to construct an E-portfolio. The key advantage of building your portfolio in Quarto is that you can easily integrate any workflow, results, figures etc. that you have created in R-Studio. This workshop repository itself was built in Quarto, and is hosted on Github. In order to build your own portfolio, we have put together a simple github repository that provides the basic files you will need. In order to interact with the repository and build your own e-portfolio using quarto and github, you will need the following:\n\nA github account.\nGithub deskptop (make sure you are logged in).\nR-Studio.\nThe sample repository (available here).",
    "crumbs": [
      "E-portfolio (Quarto)"
    ]
  },
  {
    "objectID": "E-Portfolio/eportfolio.html#e-portfolio-basics",
    "href": "E-Portfolio/eportfolio.html#e-portfolio-basics",
    "title": "E-Portfolio",
    "section": "",
    "text": "As part of FCOR 599, you are required to produce a professional E-Portfolio. This portfolio is intended to capture the breadth of skills you have developed throughout the program, including scientific writing & reporting, figure design, cartography, coding, etc. As has been introduced in the E-Portfolio workshop, a portfolio is essentially an organized digital collection of artifacts that highlight key pieces of work, accomplishments and skills. This is a great place for you to present your learning, experience, achievements, etc. - and serves as a great reference for researchers, colleagues and potential employers to see what you’re all about.\nIn other words, an E-Portfolio goes beyond what you might present in a resume or social media (i.e. linkedin) page, and allows you to express yourself through written work, images, media, etc. Rather than focusing on presenting entire bodies of finished work like a report, your E-Portfolio is a great place to demonstrate your learning and skills by presenting smaller pieces of work. Whilst many of your MGEM deliverables are the product of rubrics and assignment instructions, your E-Portfolio is ultimately entirely your own - so feel free to adjust, edit, add, and remove from your program deliverables as you see fit.\nWe highly recommend to design elements of learning into your E-Portfolio. Rather than just sharing a figure, you may want to also share some annotated code that you used to produce said figure. You could also add several iterations of a figure (of varying complexity) to demonstrate your learning trajectory. Before we dive into the techincal aspects of building your E-Portfolio using Quarto & GitHub, here are some key considerations from the UBC library workshop to remember:\n\nYour work will be visible to anyone on the internet. Ensure that you are representing yourself accurately.\nProvide credit to those who have contributed to your work.\nRespect and follow copyright and privacy laws where appropriate.",
    "crumbs": [
      "E-portfolio"
    ]
  },
  {
    "objectID": "E-Portfolio/eportfolio.html#building-an-e-portfolio-in-quarto",
    "href": "E-Portfolio/eportfolio.html#building-an-e-portfolio-in-quarto",
    "title": "E-Portfolio",
    "section": "Building an E-Portfolio in Quarto",
    "text": "Building an E-Portfolio in Quarto\nIn your E-Portfolio workshop, you were introduced to UBC blogs, where you can host a portfolio via wordpress. Since many of you are quite familiar with coding in R-studio at this stage in the pogram, the demo below will demonstrate how you can build a portfolio using Quarto in R-Studio. Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org.\nThe key advantage of building your portfolio in Quarto is that you can easily integrate any workflow, results, figures etc. that you have created in R-Studio. This workshop repository itself was built in Quarto, and is hosted on Github. In order to build your own portfolio, we have put together a simple github repository that provides the basic files you will need. In order to interact with the repository and build your own e-portfolio using quarto and github, you will need the following:\n\nA github account.\nGithub deskptop (make sure you are logged in).\nR-Studio.\nThe sample repository (available here).\n\nQuarto Portfolio Instructions:\nBefore we begin, make sure you have Github desktop installed on your device, that you are logged in to your github account in the desktop app, and that you have R-Studio installed on your device.\n\nNavigate to the sample repository using the link above.\nNow ‘fork’ the repository - this will create a copy of all of the files on your github account. You can make changes to this ‘forked’ repository without affecting the original or getting things mixed up with your peers. Make sure you provide a descriptive name for the forked repo.\nOpen up your Github Desktop app and navigate to ‘File &gt; Clone Repository’. This will show you all of the repositories that are available to be cloned based on your github account. Find the forked repo and clone it to a local path. You will get a pop-up that asks you how you plan to use this fork - make sure you select the ‘for my own purposes’ option.\nIn the Github Desktop app, click on the ‘Show in Explorer’ button - this will navigate to the folder on your computer where all the repo files are stored. This folder is where you will make changes to your E-Portfolio files.\nOpen up an R-Studio session and click on ‘File &gt; Open File’. Navigate to your explorer folder with all of the repo files, and open up the ‘index.qmd’ file. Edit the file with your own profile picture (if you’d like), contact information, and introduction blurb. When you are finished editing the page, save the .qmd file and hit ‘render’. This will give you a preview of what the page will look like in your E-Portfolio. Repeat this step for the ‘resume.qmd’ file.\nIn your Github Desktop, you will now notice that there are local changes to the repository files based on your edits. You can push these edits to your github by clicking ‘commit to main’.\n\nIn order to customize your E-Portfolio, we encourage you to review the following resources:\n\nQuarto HTML Basics\nQuarto HTML Options\nQuarto Theming\n\nOnce you are satisfied with the content of your E-Portfolio, it is time to publish your website. Before you do so, make sure you have committed all local changes from your desktop. Once you are ready:\n\nOpen your github account in your web browser, and navigate to your E-Portfolio repository.\nIn the top bar, select ‘Settings’ and navigate to ‘Pages’ under the ‘Code and automation’ column.\nUnder ‘Build and deployment’ &gt; ‘Branch’, select the ‘Main’ branch, and click save.\nYour website is now being built. This will take a few minutes, so be patient and refresh the page after ~ 2-5 minutes. Once complete, a url for your website will now be available to you.",
    "crumbs": [
      "E-portfolio"
    ]
  },
  {
    "objectID": "Interactive_Maps/leaflet.html#the-basics",
    "href": "Interactive_Maps/leaflet.html#the-basics",
    "title": "Leaflet",
    "section": "",
    "text": "Many software and coding packages can be used to create interactive maps. In this particular demo, we will show you an easy way to produce interactive maps in leaflet - a popular R package. Leaflet is intuitive, fast, and has many arguments that allow us to easily adjust the way in which we present our maps. In the example below, we used NTEMs land cover from 2020 to product a simple interactive map for Vancouver Island. In the code below, you will notice that we add in a basemap using the ‘addProviderTiles’ argument. You can browse for available leaflet basemaps here: https://leaflet-extras.github.io/leaflet-providers/preview/\n\nl &lt;- leaflet(width = 600, height = 600)%&gt;%\n  \n  #lets use some base imagery from ESRI\n  addProviderTiles(\"Esri.WorldImagery\") %&gt;%\n  \n  #now lets add our NTEMS land cover from 2020\n  addRasterImage(ntems2020, \n                 #you can increase the allowable size of the rast here\n                 maxBytes = 10 * 1024 *1024) %&gt;%\n  #add a legend\n  addRasterLegend(ntems2020, opacity = 1)%&gt;%\n  #add scale bar\n  addScaleBar(position = c(\"bottomleft\"))",
    "crumbs": [
      "Interactive Maps",
      "Leaflet"
    ]
  },
  {
    "objectID": "Interactive_Maps/leaflet.html#comparingshowing-multiple-layers",
    "href": "Interactive_Maps/leaflet.html#comparingshowing-multiple-layers",
    "title": "Leaflet",
    "section": "Comparing/Showing Multiple Layers",
    "text": "Comparing/Showing Multiple Layers\nNow let’s step things up a notch, and add some additional content to our map. For the purposes of this demonstration, let’s say you have been tasked with showcasing changes in land cover on Vancouver Island from 2000 to 2020. To do so, we can use 2 key leaflet functionalities: 1) adding a toggle menu - allowing us to switch between layers, 2) adding a ‘slider’, which we can use to visualize two layers side-by-side.\n1) In order to add a toggle menu and provide NTEMs land cover of both 2000 and 2020 in our map, we do need to provide a name for our layers using the ‘group’ argument within the ‘addRasterImage’ function.\n\nl2 &lt;- leaflet(width = 600, height = 600)%&gt;%\n  \n  #lets use some base imagery from ESRI\n  addProviderTiles(\"Esri.WorldImagery\") %&gt;%\n  \n  #now lets add our NTEMS land cover from 2000\n  addRasterImage(ntems2000, \n                 #you can increase the allowable size of the rast here\n                 maxBytes = 10 * 1024 *1024,\n                 #provide a name for the layer\n                 group = \"LC-2000\") %&gt;%\n  \n  #now lets add our NTEMS land cover from 2020\n  addRasterImage(ntems2020, \n                 #you can increase the allowable size of the rast here\n                 maxBytes = 10 * 1024 *1024,\n                 #provide a name for the layer\n                 group = \"LC-2020\") %&gt;%\n  \n  #allow for layers to be toggles on/off by adding them to the layers control\n  addLayersControl(baseGroups = c(\"LC-2000\",\"LC-2020\")) %&gt;%\n  \n  #add a legend\n  addRasterLegend(ntems2000, opacity = 1)%&gt;%\n  \n  #add scale bar\n  addScaleBar(position = c(\"bottomleft\"))\n\n\n\n\n\n\n\n \n2) In order to visualize layers side-by-side and compare them using a window slider, we need to create a left and right pane, and assign our NTEMS land cover rasters to one of these panes.\n\nl3 &lt;- leaflet(width = 600, height = 600)%&gt;%\n  \n  #set up the two map panes\n  addMapPane(\"right\", zIndex = 1) %&gt;%\n  addMapPane(\"left\",  zIndex = 2) %&gt;%\n  \n  #add the ESRI basemap to both map panes\n  addProviderTiles(\"Esri.WorldImagery\", group = \"base\", layerId = \"baseid1\", options = pathOptions(pane = \"right\")) %&gt;%\n  addProviderTiles(\"Esri.WorldImagery\", group = \"base\", layerId = \"baseid2\", options = pathOptions(pane = \"left\")) %&gt;%\n  \n  #now lets add our NTEMS land cover from 2000\n  addRasterImage(ntems2000, \n                 #you can increase the allowable size of the rast here\n                 maxBytes = 10 * 1024 *1024,\n                 #provide a name for the layer\n                 group = \"LC-2000\",\n                 #assign to a pane\n                 options = leafletOptions(pane = \"left\")) %&gt;%\n  \n  #now lets add our NTEMS land cover from 2020\n  addRasterImage(ntems2020, \n                 #you can increase the allowable size of the rast here\n                 maxBytes = 10 * 1024 *1024,\n                 #provide a name for the layer\n                 group = \"LC-2020\",\n                 #assign to a pane\n                 options = leafletOptions(pane = \"right\")) %&gt;%\n  \n  #allow for layers to be toggles on/off by adding them to the layers control\n  addLayersControl(overlayGroups = c(\"LC-2000\", \"LC-2020\")) %&gt;%\n  \n  #add slider control\n  addSidebyside(layerId = \"sidecontrols\",\n                rightId = \"baseid1\",\n                leftId  = \"baseid2\",\n                options = list(padding = 0)) %&gt;%\n  \n  #add a legend\n  addRasterLegend(ntems2000, opacity = 1)%&gt;%\n  \n  #add scale bar\n  addScaleBar(position = c(\"bottomleft\"))",
    "crumbs": [
      "Interactive Maps",
      "Leaflet"
    ]
  },
  {
    "objectID": "CodingCrossover/codingcrossover.html",
    "href": "CodingCrossover/codingcrossover.html",
    "title": "Coding Crossover",
    "section": "",
    "text": "This repository provides a side-by-side comparison of how to perform common geomatics tasks in R and Python. It focuses on the libraries terra and sf in R, and rasterio, numpy, pandas, and geopandas in Python.",
    "crumbs": [
      "Coding Crossover"
    ]
  },
  {
    "objectID": "CodingCrossover/codingcrossover.html#quarto",
    "href": "CodingCrossover/codingcrossover.html#quarto",
    "title": "Coding Crossover",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org.",
    "crumbs": [
      "Coding Crossover"
    ]
  },
  {
    "objectID": "CodingCrossover/codingcrossover.html#running-code",
    "href": "CodingCrossover/codingcrossover.html#running-code",
    "title": "Coding Crossover",
    "section": "Running Code",
    "text": "Running Code\nWhen you click the Render button a document will be generated that includes both content and the output of embedded code. You can embed code like this:\n\n1 + 1\n\n[1] 2\n\n\nYou can add options to executable code like this\n\n\n[1] 4\n\n\nThe echo: false option disables the printing of code (only output is displayed).",
    "crumbs": [
      "Coding Crossover"
    ]
  },
  {
    "objectID": "CodingCrossover/scripts/supervised_classification.html",
    "href": "CodingCrossover/scripts/supervised_classification.html",
    "title": "Supervised Image Classification in Python",
    "section": "",
    "text": "This notebook will walk you through how to do the supervised image classification that was completed in GEM 520 but this time we will complete it Python. It is recommended that you create a new folder with your training polygons and the raster image, as you do not want to overwrite any information from your lab for this process. We will only be going over the scripting part of the lab in this activity to show the differences between R and Python, so it is encouraged that you have your R scripts from that lab open as well to see what the similarities and differences are.\nWe have already installed the correct packages used in this script when you ran the create_environment.py script. Now we can import the packages that we will need to run this activity.\nimport fiona\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport rasterio\nfrom matplotlib.colors import ListedColormap\nfrom rasterio.features import geometry_mask\nfrom skimage import exposure\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, confusion_matrix, f1_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.svm import SVC\nWe will start by reading in the Landsat image into Python and plotting it.\nNote: This image can also be found here if you are unable to find the image from this assignment.\n# Read in the Landsat image (CHANGE PATH TO YOUR SYSTEM)\nwith rasterio.open(\n    r\"D:\\MurrayBrent\\git\\CodingCrossover\\data\\LC09_L2SP_047026_20240716_20240717_02_T1_SR_BSTACK.tif\"\n) as src:\n    raster = src.read()  # read raster as an array\n    transform = src.transform  # get the transform information\n\n# Create a true colour composite\nrgb_image = np.stack(\n    (raster[2], raster[1], raster[0]),\n    axis=-1,\n)  # remember that python starts with 0\n\n# Plot the true colour composite\nplt.figure(figsize=(10, 10))  # initalize figure and set size\nplt.axis(\"off\")  # turn axis off for visualization\nplt.imshow(rgb_image)  # show the true colour composite\nYou will notice when we plot this image that it is very dark and that there are some pixels that have a nan value. Below is a function that will implement an image stretch and replace the nan values with 0. We will then plot the true colour composite again.\ndef percentile_stretch(band, lower_percentile=2, upper_percentile=98):\n    band[np.isnan(band)] = 0  # set nan values to 0\n    band_min, band_max = np.percentile(\n        band, (lower_percentile, upper_percentile)\n    )  # get min and max values based on defined percentiles\n    stretched_band = (band - band_min) / (\n        band_max - band_min\n    )  # perform stretch on band\n    return np.clip(stretched_band, 0, 1)  # return band within value range (0-1)\n# Create a true colour composite with stretch\nrgb_image = np.stack(\n    (\n        percentile_stretch(raster[2]),\n        percentile_stretch(raster[1]),\n        percentile_stretch(raster[0]),\n    ),\n    axis=-1,\n)  # remember that python starts with 0\n\n# Plot the true colour composite\nplt.figure(figsize=(10, 10))  # initalize figure and set size\nplt.axis(\"off\")  # turn axis off for visualization\nplt.imshow(rgb_image)  # show the true colour composite\nThen, we load the delineated polygons and plot them with the image.\nNote: A version of these polygons can also be found here if you are unable to find your polygons from the original assignment.\n# Read in classification polygons as geopandas dataframe (CHANGE PATH TO YOUR SYSTEM)\nwith fiona.open(\n    r\"D:\\MurrayBrent\\git\\CodingCrossover\\data\\classification_polygons.shp\"\n) as poly:\n    gdf = gpd.GeoDataFrame.from_features(poly, crs=poly.crs)\n# Plot the image with the polygons\nfig, ax = plt.subplots(figsize=(10, 10))  # initialize figure\nax.imshow(\n    rgb_image,\n    extent=(src.bounds.left, src.bounds.right, src.bounds.bottom, src.bounds.top),\n)  # plot the image\ngdf.boundary.plot(ax=ax, color=\"red\", linewidth=1)  # plot the boundary of the polygons\nplt.axis(\"off\")  # turn axis off for visualization\nplt.show()  # show full plot\nYou will notice when we plotted the polygon boundaries that we called it straight from the geopandas dataframe (gdf). Both geopandas and pandas have built in plotting using matplotlib, so we dont need to specifically call any matplotlib functions. The functions that are built into geopandas and pandas use the standard matplotlib convention, meaning you can edit and change the plots in the same way you would in matplotlib.\nHere is a summary of the number of polygons per class.\npoly_summary = gdf[\"lc_class\"].value_counts()  # get a count of the `lc_class` field\npoly_summary\nFor each land cover class, we will use 70% of the polygons to train the classification algorithm and the remaining 30% for validation. We are going to add a column to the dataframe called ‘set’ to identify which polygons will be used for training and which will be used for validation based on a stratified random sample of the ‘lc_class’ column. We will then split the dataframe into two one for training and one for validation.\n# Encode 'lc_class' so that it is a class number (factor in R)\ngdf[\"lc_class_encoded\"] = gdf[\"lc_class\"].astype(\"category\").cat.codes\n# Split the data into a 70:30 split\ntrain_idx, val_idx = train_test_split(\n    gdf.index, test_size=0.3, stratify=gdf[\"lc_class\"], random_state=1234\n)  # stratified random sample based on 'lc_class'\n\n# Create new column 'set'\ngdf[\"set\"] = \"Training\"  # set default value to training\ngdf.loc[val_idx, \"set\"] = \"Validation\"  # replace value with 'Validation'\n\n# Create a Training and a Validation dataframe\ntrain_gdf = gdf[gdf[\"set\"] == \"Training\"]  # training dataframe\nval_gdf = gdf[gdf[\"set\"] == \"Validation\"]  # validation dataframe\nWe now need to get the raster data ready to perform the maximum likelihood classification. We need to get the shape of the raster, replace any nan values, and flatten the raster for easier processing.\n# Preprocess raster for classificaiton\n(\n    B,  # band\n    H,  # height\n    W,  # width\n) = raster.shape  # get shape of raster\nraster = np.nan_to_num(raster, nan=0)  # replace nan to 0\nflattened_raster = raster.reshape(B, -1).T  # Flatten raster to shape (H*W, B)\nNow we can extract the values of the Landsat image based on the training polygons.\n# Prepare training data\nx_train, y_train = [], []  # empty lists for pixel values and labels\nfor idx, row in train_gdf.iterrows():  # iterate through each polygon\n    # Generate a mask for the polygon\n    mask = geometry_mask(\n        [row.geometry], transform=transform, invert=True, out_shape=(H, W)\n    )\n\n    # Collect pixel values and labels\n    pixels = flattened_raster[mask.flatten()]  # extract pixel values\n    labels = np.full(len(pixels), row[\"lc_class_encoded\"])  # get label\n\n    # Append to lists\n    x_train.append(pixels)\n    y_train.append(labels)\n\n# Concatenate training data\nx_train = np.vstack(x_train)\ny_train = np.concatenate(y_train)\nThe maximum likelihood classification will be performed using the GaussianNB() function from the scikit-learn package. The GaussianNB() function implements the Gaussian Naive Bayes algorithm for classification. This function fits to the training data we extracted in the previous step and then predicting the class for each pixel in the raster image. For more information on this function visit the scikit-learn user guide.\n# Train maximum likeihood classifier (Gaussian Naive Bayes)\nclassifier = GaussianNB()  # call model to use\nclassifier.fit(x_train, y_train)  # fit/train model to training data\n\n# Classify entier raster\npredicted = classifier.predict(flattened_raster)  # predict class to each pixel\nclassified_raster = predicted.reshape(\n    H, W\n)  # reshape prediction from flattened raster to original dimensions\nNow let’s plot the classified raster to see how this model worked.\n# Set appropriate colours for each class\ncolors = [\"#A6D96A\", \"#33A02C\", \"#DE3B13\", \"#D63CF1\", \"#00D2D2\", \"#F1A026\", \"#2B83BA\"]\ncmap = ListedColormap(colors)\n\n# Plot classified image\nplt.figure(figsize=(10, 10))  # initialize figure and set size\nplt.axis(\"off\")  # turn axis off for visualization\nplt.imshow(classified_raster, cmap=cmap)  # plot classified raster with defined colours\nUsing the validation polygons, we can extract the predicted classes and the ‘true’ values so we can calculate our accuracy metrics and create a confusion matrix.\n# Prepare validation data\ntrue_classes, predicted_classes = [], []  # empty lists for true and predicted classes\nfor idx, row in val_gdf.iterrows():  # iterate through each polygon\n    # Generate a mask for the polygon\n    mask = geometry_mask(\n        [row.geometry], transform=transform, invert=True, out_shape=(H, W)\n    )\n\n    # Extract true clas labels\n    true_label = row[\"lc_class_encoded\"]  # Column with the true encoded class labels\n    true_values = np.full(np.sum(mask), true_label)\n\n    # Extract predicted class labels from classified raster\n    predicted_values = classified_raster[mask]\n\n    # Append to lists\n    true_classes.extend(true_values)\n    predicted_classes.extend(predicted_values)\n\n# Convert lists to numpy arrays\ntrue_classes = np.array(true_classes)\npredicted_classes = np.array(predicted_classes)\nNow we can calculate the overall accuracy and F1 score.\n# Calculate accuracy metrics and print values\noa = accuracy_score(true_classes, predicted_classes)  # overall accuracy\nf1 = f1_score(true_classes, predicted_classes, average=\"weighted\")  # f1 score\nprint(f\"Overall Accuracy: {oa}\\nF1 Score: {f1}\")\nWe can also create a confusion matrix and calculate the Producer’s and User’s accuracies.\n# Create confusion matrix\nconf_matrix = confusion_matrix(true_classes, predicted_classes)\n\n# Calculate producers and users accuracies from confusion matrix\npa = np.diag(conf_matrix) / np.sum(conf_matrix, axis=1)  # producers accuracy\nua = np.diag(conf_matrix) / np.sum(conf_matrix, axis=0)  # users accuracy\n\n# Create dataframe for confusion matrix\nclasses = np.unique(gdf[\"lc_class\"])  # get unique class label\nconf_matrix_df = pd.DataFrame(\n    conf_matrix.T, index=classes, columns=classes\n)  # create dataframe\n\n# Add producers and users accuracies to dataframe\nconf_matrix_df.loc[\"Producer's Accuracy\"] = np.round(pa * 100, 3)\nconf_matrix_df[\"User's Accuracy\"] = np.append(\n    np.round(ua * 100, 2), [np.nan]\n)  # Append NaN for alignment\n\n# Add titles to show which values are Predicted and which are Actual\nconf_matrix_df.index.name = \"Predicted\"\nconf_matrix_df.columns.name = \"Actual\"\n\n# Print confusion matrix\nconf_matrix_df"
  },
  {
    "objectID": "CodingCrossover/scripts/supervised_classification.html#comparison-to-other-classifiers",
    "href": "CodingCrossover/scripts/supervised_classification.html#comparison-to-other-classifiers",
    "title": "Supervised Image Classification in Python",
    "section": "Comparison to other classifiers",
    "text": "Comparison to other classifiers\nNow that we have the training and validation data created we can run other classifiers to see how they differ. We should use the same data and split as we did previously for a true comparison of these models.\n\nRandom Forest\nFirst let’s train a Random Forest Classification. Similar to the GaussianNB() function we can use the RandomForestClassifier() function from scikit-learn (User Guide).\nIn this example we will have 100 ‘trees’ in our forest but feel free to adjust this parameter to see how the output changes.\n\n# Train Random Forest Classifier\nrf_classifier = RandomForestClassifier(\n    n_estimators=100, random_state=42\n)  # call model to use and set parameters\nrf_classifier.fit(x_train, y_train)  # fit/train model to training data\n\n# Classify entier raster\npredicted = rf_classifier.predict(flattened_raster)  # predict class to each pixel\nclassified_raster = predicted.reshape(\n    H, W\n)  # reshape prediction from flattened raster to original dimensions\n\n\n# Set appropriate colours for each class\ncolors = [\"#A6D96A\", \"#33A02C\", \"#DE3B13\", \"#D63CF1\", \"#00D2D2\", \"#F1A026\", \"#2B83BA\"]\ncmap = ListedColormap(colors)\n\n# Plot classified image\nplt.figure(figsize=(10, 10))  # initialize figure and set size\nplt.axis(\"off\")  # turn axis off for visualization\nplt.imshow(classified_raster, cmap=cmap)  # plot classified raster with defined colours\n\n\n# Prepare validation data\ntrue_classes, predicted_classes = [], []  # empty lists for true and predicted classes\nfor idx, row in val_gdf.iterrows():  # iterate through each polygon\n    # Generate a mask for the polygon\n    mask = geometry_mask(\n        [row.geometry], transform=transform, invert=True, out_shape=(H, W)\n    )\n\n    # Extract true clas labels\n    true_label = row[\"lc_class_encoded\"]  # Column with the true encoded class labels\n    true_values = np.full(np.sum(mask), true_label)\n\n    # Extract predicted class labels from classified raster\n    predicted_values = classified_raster[mask]\n\n    # Append to lists\n    true_classes.extend(true_values)\n    predicted_classes.extend(predicted_values)\n\n# Convert lists to numpy arrays\ntrue_classes = np.array(true_classes)\npredicted_classes = np.array(predicted_classes)\n\n\n# Calculate accuracy metrics and print values\noa = accuracy_score(true_classes, predicted_classes)  # overall accuracy\nf1 = f1_score(true_classes, predicted_classes, average=\"weighted\")  # f1 score\nprint(f\"Overall Accuracy: {oa}\\nF1 Score: {f1}\")\n\n\n# Create confusion matrix\nconf_matrix = confusion_matrix(true_classes, predicted_classes)\n\n# Calculate producers and users accuracies from confusion matrix\npa = np.diag(conf_matrix) / np.sum(conf_matrix, axis=1)  # producers accuracy\nua = np.diag(conf_matrix) / np.sum(conf_matrix, axis=0)  # users accuracy\n\n# Create dataframe for confusion matrix\nclasses = np.unique(gdf[\"lc_class\"])  # get unique class label\nconf_matrix_df = pd.DataFrame(\n    conf_matrix.T, index=classes, columns=classes\n)  # create dataframe\n\n# Add producers and users accuracies to dataframe\nconf_matrix_df.loc[\"Producer's Accuracy\"] = np.round(pa * 100, 3)\nconf_matrix_df[\"User's Accuracy\"] = np.append(\n    np.round(ua * 100, 2), [np.nan]\n)  # Append NaN for alignment\n\n# Add titles to show which values are Predicted and which are Actual\nconf_matrix_df.index.name = \"Predicted\"\nconf_matrix_df.columns.name = \"Actual\"\n\n# Print confusion matrix\nconf_matrix_df\n\n\nRandom Forest - Feature Importance\nAn additional analysis we can do with Random Forest is see the feature importance of the different inputs for the classification. This allows us to further understand why our outputs might be influenced by our inputs.\n\nfeature_importance = rf_classifier.feature_importances_\nbands = [\"Blue\", \"Green\", \"Red\", \"NIR\", \"SWIR1\", \"SWIR2\"]\nfor band, importance in zip(bands, feature_importance):\n    print(f\"{band}: {importance}\")\n\nplt.figure(figsize=(10, 6))\nplt.barh(bands, feature_importance, color=\"orange\")\nplt.xlabel(\"Feature Importance\")\nplt.ylabel(\"Band\")\nplt.title(\"Feature Importance in Random Forest\")\nplt.show()\n\n\n\n\nSupport Vector Machine\nNow lets train a Support Vector Machine (SVM) using the SVC() function (User Guide)\n\n# Train Support Vector Machine (SVM) Classifier\nsvm_classifier = SVC(\n    kernel=\"linear\", C=1.0, random_state=42\n)  # call model to use and set parameters\nsvm_classifier.fit(x_train, y_train)  # fit/train model to training data\n\n# Classify entier raster\npredicted = svm_classifier.predict(flattened_raster)  # predict class to each pixel\nclassified_raster = predicted.reshape(\n    H, W\n)  # reshape prediction from flattened raster to original dimensions\n\n\n# Set appropriate colours for each class\ncolors = [\"#A6D96A\", \"#33A02C\", \"#DE3B13\", \"#D63CF1\", \"#00D2D2\", \"#F1A026\", \"#2B83BA\"]\ncmap = ListedColormap(colors)\n\n# Plot classified image\nplt.figure(figsize=(10, 10))  # initialize figure and set size\nplt.axis(\"off\")  # turn axis off for visualization\nplt.imshow(classified_raster, cmap=cmap)  # plot classified raster with defined colours\n\n\n# Prepare validation data\ntrue_classes, predicted_classes = [], []  # empty lists for true and predicted classes\nfor idx, row in val_gdf.iterrows():  # iterate through each polygon\n    # Generate a mask for the polygon\n    mask = geometry_mask(\n        [row.geometry], transform=transform, invert=True, out_shape=(H, W)\n    )\n\n    # Extract true clas labels\n    true_label = row[\"lc_class_encoded\"]  # Column with the true encoded class labels\n    true_values = np.full(np.sum(mask), true_label)\n\n    # Extract predicted class labels from classified raster\n    predicted_values = classified_raster[mask]\n\n    # Append to lists\n    true_classes.extend(true_values)\n    predicted_classes.extend(predicted_values)\n\n# Convert lists to numpy arrays\ntrue_classes = np.array(true_classes)\npredicted_classes = np.array(predicted_classes)\n\n\n# Calculate accuracy metrics and print values\noa = accuracy_score(true_classes, predicted_classes)  # overall accuracy\nf1 = f1_score(true_classes, predicted_classes, average=\"weighted\")  # f1 score\nprint(f\"Overall Accuracy: {oa}\\nF1 Score: {f1}\")\n\n\n# Create confusion matrix\nconf_matrix = confusion_matrix(true_classes, predicted_classes)\n\n# Calculate producers and users accuracies from confusion matrix\npa = np.diag(conf_matrix) / np.sum(conf_matrix, axis=1)  # producers accuracy\nua = np.diag(conf_matrix) / np.sum(conf_matrix, axis=0)  # users accuracy\n\n# Create dataframe for confusion matrix\nclasses = np.unique(gdf[\"lc_class\"])  # get unique class label\nconf_matrix_df = pd.DataFrame(\n    conf_matrix.T, index=classes, columns=classes\n)  # create dataframe\n\n# Add producers and users accuracies to dataframe\nconf_matrix_df.loc[\"Producer's Accuracy\"] = np.round(pa * 100, 3)\nconf_matrix_df[\"User's Accuracy\"] = np.append(\n    np.round(ua * 100, 2), [np.nan]\n)  # Append NaN for alignment\n\n# Add titles to show which values are Predicted and which are Actual\nconf_matrix_df.index.name = \"Predicted\"\nconf_matrix_df.columns.name = \"Actual\"\n\n# Print confusion matrix\nconf_matrix_df\n\n\n\nNeural Networks (Multi-Layer Perceptron)\nFinally, let’s train a simple neural network to compare the other classification outputs. This neural network is a Multi-Layer Perceptron with three hidden layers containing 100, 50, and 25 neurons. Feel free to adjust the number of layers as well as the number of neurons to see how this changes the output. For more information on the MLPClassifier() function see the User Guide.\n\n# Train Multi-Layer Perceptron Classifier\nmlp_classifier = MLPClassifier(\n    hidden_layer_sizes=(\n        100,\n        50,\n        25,\n    ),  # Three hidden layer with 100, 50, and 25 neurons\n    activation=\"relu\",  # Activation function for hidden layers\n    solver=\"adam\",  # Optimization algorithm\n    max_iter=300,  # Maximum number of iterations\n    random_state=42,\n)\nmlp_classifier.fit(x_train, y_train)  # fit/train model to training data\n\n# Classify entier raster\npredicted = mlp_classifier.predict(flattened_raster)  # predict class to each pixel\nclassified_raster = predicted.reshape(\n    H, W\n)  # reshape prediction from flattened raster to original dimensions\n\n\n# Set appropriate colours for each class\ncolors = [\"#A6D96A\", \"#33A02C\", \"#DE3B13\", \"#D63CF1\", \"#00D2D2\", \"#F1A026\", \"#2B83BA\"]\ncmap = ListedColormap(colors)\n\n# Plot classified image\nplt.figure(figsize=(10, 10))  # initialize figure and set size\nplt.axis(\"off\")  # turn axis off for visualization\nplt.imshow(classified_raster, cmap=cmap)  # plot classified raster with defined colours\n\n\n# Prepare validation data\ntrue_classes, predicted_classes = [], []  # empty lists for true and predicted classes\nfor idx, row in val_gdf.iterrows():  # iterate through each polygon\n    # Generate a mask for the polygon\n    mask = geometry_mask(\n        [row.geometry], transform=transform, invert=True, out_shape=(H, W)\n    )\n\n    # Extract true clas labels\n    true_label = row[\"lc_class_encoded\"]  # Column with the true encoded class labels\n    true_values = np.full(np.sum(mask), true_label)\n\n    # Extract predicted class labels from classified raster\n    predicted_values = classified_raster[mask]\n\n    # Append to lists\n    true_classes.extend(true_values)\n    predicted_classes.extend(predicted_values)\n\n# Convert lists to numpy arrays\ntrue_classes = np.array(true_classes)\npredicted_classes = np.array(predicted_classes)\n\n\n# Calculate accuracy metrics and print values\noa = accuracy_score(true_classes, predicted_classes)  # overall accuracy\nf1 = f1_score(true_classes, predicted_classes, average=\"weighted\")  # f1 score\nprint(f\"Overall Accuracy: {oa}\\nF1 Score: {f1}\")\n\n\n# Create confusion matrix\nconf_matrix = confusion_matrix(true_classes, predicted_classes)\n\n# Calculate producers and users accuracies from confusion matrix\npa = np.diag(conf_matrix) / np.sum(conf_matrix, axis=1)  # producers accuracy\nua = np.diag(conf_matrix) / np.sum(conf_matrix, axis=0)  # users accuracy\n\n# Create dataframe for confusion matrix\nclasses = np.unique(gdf[\"lc_class\"])  # get unique class label\nconf_matrix_df = pd.DataFrame(\n    conf_matrix.T, index=classes, columns=classes\n)  # create dataframe\n\n# Add producers and users accuracies to dataframe\nconf_matrix_df.loc[\"Producer's Accuracy\"] = np.round(pa * 100, 3)\nconf_matrix_df[\"User's Accuracy\"] = np.append(\n    np.round(ua * 100, 2), [np.nan]\n)  # Append NaN for alignment\n\n# Add titles to show which values are Predicted and which are Actual\nconf_matrix_df.index.name = \"Predicted\"\nconf_matrix_df.columns.name = \"Actual\"\n\n# Print confusion matrix\nconf_matrix_df"
  },
  {
    "objectID": "CodingCrossover/scripts/supervised_classification.html#questions",
    "href": "CodingCrossover/scripts/supervised_classification.html#questions",
    "title": "Supervised Image Classification in Python",
    "section": "Questions",
    "text": "Questions\nQuestion 1 - Why is it important to use the same training and validation data when comparing different model outputs?\nQuestion 2 - Which classifier performed best with your data? Why do you think this is?"
  },
  {
    "objectID": "CodingCrossover/codingcrossover.html#key-differences-in-python-vs.-r",
    "href": "CodingCrossover/codingcrossover.html#key-differences-in-python-vs.-r",
    "title": "Coding Crossover",
    "section": "Key Differences in Python vs. R",
    "text": "Key Differences in Python vs. R\nThere are some key differences between Python and R that may take some time to get used to when switching between them.\nIndexing:\n\nPython uses zero-based indexing (lists, arrays start from index 0).\nR uses one-based indexing (vectors, matrices start from index 1).\n\nData structures:\n\nPython’s primary sequence structures are lists (mutable) and tuples (immutable), and numpy arrays for numerical operations.\nR’s core structures are vectores, matrices, data frames and lists, where vectors are a fundamental unit of operation.\n\nVectorization and broadcasting\n\nR is inherently vectorized; many operations naturally apply element-wise without extra effort.\nPython requires libraries like NumPy for similar vectorized operations and broadcasting.\n\nFunction arguments\n\nIn Python, keyword arguments (kwargs) are passed by name after positional arguments, and default values are common.\nIn R, arguments can be matched by position or name, and partial argument matching (unique abbreviations) is allowed.\n\nAssignment\n\nPython uses = for assignment.\nR commonly uses &lt;- for assignment, though = can also be used.\n\nLooping and iteration\n\nPython encourages explicit loops (e.g., for, while), and list comprehension is widely used.\nsquares = [x**2 for x in range(10)] # example list comprehension\nR encourages vectorized operations and apply functions over explicit for loops for efficiency and clarity.\n\nString handling\n\nPython has robust built-in string operations, slicing and methods.\nR relies on more external packages (like stringr) for advanced text manipulation, though basic operations are available natively.",
    "crumbs": [
      "Coding Crossover"
    ]
  },
  {
    "objectID": "CodingCrossover/codingcrossover.html#common-geomatics-libraries",
    "href": "CodingCrossover/codingcrossover.html#common-geomatics-libraries",
    "title": "Coding Crossover",
    "section": "Common Geomatics Libraries",
    "text": "Common Geomatics Libraries\nR Libraries\n\n\n\n\n\n\n\nLibrary\nDescription\n\n\n\n\nterra\nFor spatial data manipulation, raster data processing, and geospatial analysis.\n\n\nsf\nFor handling vector spatial data, including shapefiles, GeoJSON, and other formats.\n\n\ndplyr\nFor data manipulation.\n\n\ncaret\nFor training and plotting classification and regression models.\n\n\nggplot2\nFor creating graphics with provided data.\n\n\n\nPython Libraries\n\n\n\n\n\n\n\nLibrary\nDescription\n\n\n\n\nrasterio\nFor raster file I/O and processing.\n\n\nnumpy\nFor numerical data manipulation, often used with raster data.\n\n\npandas\nFor tabular data manipulation.\n\n\ngeopandas\nFor handling vector spatial data, extending pandas to work with geospatial formats.\n\n\nshapely\nFor manipulation and analysis of geometric objects.\n\n\nscikit-learn\nFor training classification, regression, and clustering models, and data preprocessing.\n\n\nmatplotlib\nFor creating graphics with provided data.",
    "crumbs": [
      "Coding Crossover"
    ]
  },
  {
    "objectID": "CodingCrossover/codingcrossover.html#importing-libraries",
    "href": "CodingCrossover/codingcrossover.html#importing-libraries",
    "title": "Coding Crossover",
    "section": "Importing Libraries",
    "text": "Importing Libraries\nR\n# Import libraries \nlibrary(terra)     # For raster operations \nlibrary(sf)        # For vector operations \nlibrary(dplyr)     # For data manipulation \nlibrary(ggplot2)   # For creating visualizations\nPython\n# Import libraries\nimport rasterio                                                     # For raster operations \nimport geopandas as gpd                                             # For vector data \nimport numpy as np                                                  # For numerical data \nimport pandas as pd                                                 # For tabular data manipulation \nimport matplotlib.pyplot as plt                                     # For creating visulizations \nfrom rasterio.features import rasterize                             # For rasterizing vector data \nfrom rasterio.mask import mask                                      # For masking raster data \nfrom rasterio.warp import calculate_default_transform, reproject    # For raster reprojection \nfrom shapely.geometry import box                                    # For creating bounding box",
    "crumbs": [
      "Coding Crossover"
    ]
  },
  {
    "objectID": "CodingCrossover/codingcrossover.html#cheat-sheet-common-geomatics-functions",
    "href": "CodingCrossover/codingcrossover.html#cheat-sheet-common-geomatics-functions",
    "title": "Coding Crossover",
    "section": "Cheat Sheet: Common Geomatics Functions",
    "text": "Cheat Sheet: Common Geomatics Functions\n\n\n\n\n\n\n\n\nFunctionality\nR (terra, sf)\nPython (rasterio, geopandas, etc.)\n\n\n\n\nRead a shapefile\nshp &lt;- sf::st_read(\"path/to/file.shp\")\nshp = gpd.read_file(\"path/to/file.shp\")\n\n\nWrite a shapefile\nsf::st_write(shp, \"path/to/output.shp\")\nshp.to_file(\"path/to/output.shp\")\n\n\nRead a raster\nraster &lt;- terra::rast(\"path/to/file.tif\")\nwith rasterio.open(\"path/to/file.tif\") as src:\n    raster = src.read()\n\n\nWrite a raster\nterra::writeRaster(raster, \"path/to/output.tif\", overwrite=TRUE)\nwith rasterio.open(\"path/to/output.tif\", \"w\", **kwargs) as dst:\n    dst.write(raster)\n\n\nCalculate NDVI\nndvi &lt;- (nir - red) / (nir + red)\n(assuming nir and red are terra raster objects)\nndvi = (nir - red) / (nir + red)\n(assuming nir and red are numpy arrays)\n\n\nClip a raster by extent\nclipped &lt;- terra::crop(raster, extent)\nclipped, _ = mask(src, shapes, crop=True)\n\n\nClip a vector by extent\nclipped &lt;- sf::st_crop(vector, xmin = x1, ymin = y1, xmax = x2, ymax = y2)\nbbox = box(x1, y1, x2, y2)\nclipped = vector.clip(bbox)\n\n\nReproject a shapefile\nreproj &lt;- sf::st_transform(shp, crs = 4326)\nshp = shp.to_crs(epsg=4326)\n\n\nReproject a raster\nreproj &lt;- terra::project(raster, \"EPSG:4326\")\nreprojected_raster = reproject(src, transform)\n\n\nCalculate area of polygons\nshp$area &lt;- sf::st_area(shp)\nshp[\"area\"] = shp.geometry.area\n\n\nSort polygons by attribute\nsorted &lt;- shp[order(shp$attribute), ]\nsorted = shp.sort_values(\"attribute\")\n\n\nExtract raster values\nvalues &lt;- terra::extract(raster, sf::st_coordinates(points))\nvalues = [raster[row, col] for row, col in points] (requires array coordinates for numpy)\n\n\nBuffer around features\nbuffered &lt;- sf::st_buffer(shp, dist = 500)\nbuffered = shp.buffer(500)\n\n\nRasterize a vector layer\nrasterized &lt;- terra::rasterize(shp, raster)\nrasterized = rasterize([(geom, 1) for geom in shp.geometry], out_shape=shape, transform=transform)",
    "crumbs": [
      "Coding Crossover"
    ]
  },
  {
    "objectID": "CodingCrossover/codingcrossover.html#classification-example",
    "href": "CodingCrossover/codingcrossover.html#classification-example",
    "title": "Coding Crossover",
    "section": "Classification Example",
    "text": "Classification Example\nIn GEM520 there was a lab assignment that focused on how to perform a supervised image classification using QGIS and R to represent the 7 land cover classes for the Gulf Islands. Within this lab training and validation polygons were delineated using QGIS and then used to train a Maximum Likelihood Classifier in R. In this example we will be using those same polygons and Landsat image but we will be doing the classification step using Python instead.\nNote: it is recommended that you use the same polygons that you delineated for the lab to see if there are any differences in the outputs, but if you do not have them still you can access them here.\n\nStep 1\nBefore being able to run this example you will need to set up a Conda environment with the correct packages installed. To do this you will first need to download the create_environment.py script from here.\nNext you need to open up Anaconda Prompt and type in python [path/to/create_environment.py]. This will create a new Conda environment for you with the correct packages and then open a new Jupyter Lab IDE.\nNote: you do not need to run this example in the Jupter Lab IDE but the live tutorial will be done using it.\n\n\nStep 2\nOnce the environment is created and Jupyter Lab is opened you can download the supervised_classification.ipynb from here. This notebook will walk you through similar steps to the ones found in the original lab assignment. Open this notebook and run each of the code chunks.\nNote: you will need to change the file paths within this notebook to the ones in your system and run each code chunk to show your results.",
    "crumbs": [
      "Coding Crossover"
    ]
  },
  {
    "objectID": "Cartography/art_of_maps.html#data",
    "href": "Cartography/art_of_maps.html#data",
    "title": "The Art of Map Making",
    "section": "Data",
    "text": "Data\nWhile the data you chose to map and display isn’t something that will or won’t be mandated and controlled, it’s always important think about what data you want to map, and why. For example, a study area map is very common and almost expected for many journals or papers in GIS and remote sensing due to the fact that giving the reader an idea of where the study is can be essential for understanding the context of the work.\nAs for everything besides a study map, a good rule of thumb on whether to make a map is if there is a spatial element in your data, then its probably a good idea! However, always keep your maps as simple as you can, an overcrowded map is one of the easiest ways to have your reader simply ignore your map or not get the message\n\n\n\nAn example of a map with maybe too much data\n\n\nWhen it comes to how much, or which data, to add on your map always keep things as simple as possible and it’s never a bad idea to just make a few maps.",
    "crumbs": [
      "Cartography",
      "The Art of Map Making"
    ]
  },
  {
    "objectID": "Cartography/art_of_maps.html#colour",
    "href": "Cartography/art_of_maps.html#colour",
    "title": "The Art of Map Making",
    "section": "Colour",
    "text": "Colour\nThe colours you chose for you map, like many things in cartography, is up to you but you can definitely get it wrong. For example, when it comes to publication, sometimes you may need to have colours that are colourblind friendly or even can print in black and white. However, those may be laid out for you in plain to read rules, but today I think its best to think of some rules or guidelines that aren’t as obvious. Such as for land classification:\n\nWater is blue\nGreen for vegetation\nBrown for mountains or rough terrain\n\nSounds simple enough, but easy to stick to ideas like this take just a second to step back and think of which colour you’re choosing and why. What data your representing can also help decide your colour, for example a map showing hotter temperatures in blue might not be trusted as much as one that shows the same in red….\nAs for choosing a colour ramp that is diverging or sequential depends on your range of data, but resources such as ColourBrewer are an amazing place to go back for inspiration and any help:\nColourBrewer",
    "crumbs": [
      "Cartography",
      "The Art of Map Making"
    ]
  },
  {
    "objectID": "Cartography/art_of_maps.html#examples-of-artistic-maps",
    "href": "Cartography/art_of_maps.html#examples-of-artistic-maps",
    "title": "The Art of Map Making",
    "section": "",
    "text": "There are many beautiful maps out in the world that are more art than science but that doesn’t disqualify them from being called a map. Here are a few examples of what might not traditionally be called maps in a scientific sense, but can be used as either a cool visualization or maybe even some inspiration for your work:\n\n\n\n\n\n\n\nWhistler village, Canada, by James Niehues\n\n\nMaps like the one above are a great example that not every map needs to have every single detail shown, like we’ve talked about “all maps are lies”, so sometimes you need to lie a little to better convey a message and visualize your work.\n\n\n\n3D map of Manhattan by Luis Dilger\n\n\nWhile these shift a little bit from what we talked about in the cartography section of today, hopefully these can serve as a reminder that map making is an art its core, don’t be afraid to put your own style and touch on your maps!",
    "crumbs": [
      "Cartography",
      "The Art of Map Making"
    ]
  },
  {
    "objectID": "Cartography/arcgis_pro_demo.html#projections",
    "href": "Cartography/arcgis_pro_demo.html#projections",
    "title": "ArcGIS Pro Demo",
    "section": "",
    "text": "Displaying your map frame in an appropriate coordinate system is important for visualization. For example, the two photos below show very different projections, and while both are technically not wrong, the one using the Mercator is clearly much better suited for our data\n\n\n\nRobinson\n\n\n\n\n\nMercator\n\n\nYou can change the projection of your map view by right-clicking on the ‘Map’ in your drawing order, and going to properties (below-left). Under the Coordinate Systems tab, you may then select a projection suitable for viewing your map (bottom-right).\nTip: Using the search bar can be the fastest way to find a projection you’re looking for, but the layers drop-down will have all the projections of any layers on your map already ready for easy selection. You can also save your most common projections under Favorites if you find yourself using the same projections over and over.\n\n\n\nSelecting a projection",
    "crumbs": [
      "Cartography",
      "ArcGIS Pro Demo"
    ]
  },
  {
    "objectID": "Cartography/arcgis_pro_demo.html#inset-maps",
    "href": "Cartography/arcgis_pro_demo.html#inset-maps",
    "title": "ArcGIS Pro Demo",
    "section": "",
    "text": "In order to help our map-viewers out a little more, we can insert another map frame on our layout, showing where in Canada we are. To do so we will want to put this data in a separate ‘Map’ tab. To create one, simply click on the ‘New Map’ button on the top left of your Arc screen. Now that we have this new ’Map”, and have added our data, we can go back to our layout, and add our helpful extent map.\n\n\n\nSome of the helpful buttons for creating an inset map highlighted\n\n\nAfter selecting your layout, navigate to the ‘Insert’ tab on the top of your screen, and select ‘Map Frame’. This will give you an overview of all the maps you have created in your Arc Project, and will allow you to select one to add to your layout. We can now select the one created above, and add it to our layout by dragging a box in the spot where we wish to place it. You can then add elements such as leader lines, and separate scale bars if you feel it is appropriate.",
    "crumbs": [
      "Cartography",
      "ArcGIS Pro Demo"
    ]
  },
  {
    "objectID": "Cartography/arcgis_pro_demo.html#legends",
    "href": "Cartography/arcgis_pro_demo.html#legends",
    "title": "ArcGIS Pro Demo",
    "section": "",
    "text": "Legends are a fundamental component of any map. It is where we give the map-viewer the tools they need to interpret the data that we are presenting to them. Inserting a Legend is relatively straightforward – you can simply navigate to the ‘Insert’ tab for your layout, and click on ‘Legend’. However, once you have inserted a Legend, you may find it doesn’t look exactly appealing, and we may have to take some steps to clean things up a bit. First and foremost, there may be layers on display which we do not wish to include in our legend – to avoid clutter.\n\n\n\nCustomizing you legend can probably be one of the more frustrating things to do in ArcGIS. The quickest way to make changes is to use the properties of the legend, accessed by right clicking it and selecting the Properties option at the bottom. This will open a window on the right with lots and lots of options on things you can change. See this link for some helpful tips Legends Tips\nChanging the name of your layers can be one of the easiest things to forget when creating a map in ArcGIS, but probably the biggest difference maker when creating a map. To do so, simply right click the layer to access its Properties. In the top option, General, there is a name bar where you can type whatever name you feel is best, the great thing about this is you can use spaces and capitalized letters which often isn’t the default with GIS!",
    "crumbs": [
      "Cartography",
      "ArcGIS Pro Demo"
    ]
  },
  {
    "objectID": "Cartography/arcgis_pro_demo.html#gridlines-and-graticules",
    "href": "Cartography/arcgis_pro_demo.html#gridlines-and-graticules",
    "title": "ArcGIS Pro Demo",
    "section": "",
    "text": "It can sometimes be easy to forget that the people looking at your maps are not as familiar with the data, area, and topic as you are. People from all over the world map end up looking at your map, so it is always important to make sure everyone – regardless of their background knowledge – is able to interpret and read your map. For the example shown in this document so far, people from Eastern Canada may recognize the Hudson’s Bay area in the map, yet many of us may be initially confused as to where this study area is located. There are a few ways by which we can make this easier for our map-viewer to interpret. On of these ways is by inserting grid-lines which show lat/lon lines across our map. To do so, navigate to the ‘Grid’ option in the Insert bar for your layout, and select one of the grid options.\n\n\n\nGridlines\n\n\nThis will add grid-lines to our drawing order, as well as map view. Similarly to the legend, we can right click on the grid lines in our drawing order, select properties, and make adjustments as we wish to alter the appearance of thegrid lines (not shown here).",
    "crumbs": [
      "Cartography",
      "ArcGIS Pro Demo"
    ]
  },
  {
    "objectID": "Cartography/arcgis_pro_demo.html#north-arrow-and-scale-bar",
    "href": "Cartography/arcgis_pro_demo.html#north-arrow-and-scale-bar",
    "title": "ArcGIS Pro Demo",
    "section": "",
    "text": "Now that we have got ourselves a nice looking map, we have to add the finishing touches. No map is complete without the essential North Arrow and Scale Bars. Thankfuly, both are easy to add! Simply select the ‘North Arrow’ Dropdown at the top of your screen, and choose whichever strikes your fancy.\nFor scale bars, simply select the ‘Scale Bar’ dropdown, select one of the available options, and drag a box where you would like to place it. Now it is important to note that when you add a scale bar or north arrow, it will do so based on the map frame you have selected in your layout. Since we are making use of an inset in this example, we will then need to make sure to add a second scale bar to show the scale of our inset. Simply select the inset map frame in the layout, and add a second scale bar – placing it in an appropriate spot.",
    "crumbs": [
      "Cartography",
      "ArcGIS Pro Demo"
    ]
  }
]
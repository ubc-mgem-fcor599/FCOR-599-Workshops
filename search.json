[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "FCOR 599: Workshop Artifacts",
    "section": "",
    "text": "Home Page\nHey there,\nThis webpage contains workshop artifacts created by your FCOR 599 TA’s. Many of these artifacts were initially developed as workshops, and have been archived here for your reference. The topics range from cartography to advanced figure development and python scripting - most of which were requested by previous cohorts of your peers. If you have any questions, or have suggestions for additional modules that can be included here, please talk to your FCOR 599 teaching team.\n\n\n\nReuseCC BY 4.0",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "cartography.html",
    "href": "cartography.html",
    "title": "Cartography",
    "section": "",
    "text": "“All maps are lies, but some are useful” ~ Dr. Paul Pickell, circa 2020\nCartography is the art and science of creating, studying, and distributing maps and other visual representations of geographical areas. It involves a combination of scientific and artistic skills to communicate information about a place.\n\n\n\nEratosthenes’ World Map (220 BCE) showing the results of Alexander the Great’s conquests. Eratosthenes was the first geographer to include parallels and meridians in his maps, allowing for the calculation of distance.",
    "crumbs": [
      "Cartography"
    ]
  },
  {
    "objectID": "cartography.html#quarto",
    "href": "cartography.html#quarto",
    "title": "Cartography",
    "section": "",
    "text": "blah blah blah",
    "crumbs": [
      "Cartography"
    ]
  },
  {
    "objectID": "art_of_maps.html",
    "href": "art_of_maps.html",
    "title": "The Art of Map Making",
    "section": "",
    "text": "Lets add some text here about the history of maps. Some are very beautiful, some less so. Although we rightfully place emphasis on ensuring the scientific integrity of maps, the artistic component of map making is a key component of science communication, and should not be overlooked.",
    "crumbs": [
      "Cartography",
      "The Art of Map Making"
    ]
  },
  {
    "objectID": "cartography.html#what-is-cartography",
    "href": "cartography.html#what-is-cartography",
    "title": "Cartography",
    "section": "",
    "text": "Cartography is the art and science of creating, studying, and distributing maps and other visual representations of geographical areas. It involves a combination of scientific and artistic skills to communicate information about a place.",
    "crumbs": [
      "Cartography"
    ]
  },
  {
    "objectID": "arcgis_pro_demo.html",
    "href": "arcgis_pro_demo.html",
    "title": "ArcGIS Pro Demo",
    "section": "",
    "text": "As MGEM students, you all have access to ArcGIS Pro, a powerful GIS software that allows users to perform geospatial tasks and create beautiful maps. This demo focuses on the map-making capabilities of ArcGIS Pro, and provides an easy reference guide for the implementation of core cartography concepts and best-practices.",
    "crumbs": [
      "Cartography",
      "ArcGIS Pro Demo"
    ]
  },
  {
    "objectID": "interactive_maps.html",
    "href": "interactive_maps.html",
    "title": "Interactive Maps",
    "section": "",
    "text": "Although conventional maps are static and do not allow for user interaction, geospatial practitioners have developed exciting new ways in which we can present geographic information in interactive formats. Although not exhaustive by any means, this section will cover several key ways in which you can create digital maps that allow for user-interaction.",
    "crumbs": [
      "Interactive Maps"
    ]
  },
  {
    "objectID": "leaflet.html",
    "href": "leaflet.html",
    "title": "Leaflet",
    "section": "",
    "text": "The Basics:\nMany software and coding packages can be used to create interactive maps. In this particular demo, we will show you an easy way to produce interactive maps in leaflet - a popular R package. Leaflet is intuitive, fast, and has many arguments that allow us to easily adjust the way in which we present our maps. In the example below, we used NTEMs land cover from 2020 to product a simple interactive map for Vancouver Island. In the code below, you will notice that we add in a basemap using the ‘addProviderTiles’ argument. You can browse for available leaflet basemaps here: https://leaflet-extras.github.io/leaflet-providers/preview/\n\nl &lt;- leaflet(width = 600, height = 600)%&gt;%\n  \n  #lets use some base imagery from ESRI\n  addProviderTiles(\"Esri.WorldImagery\") %&gt;%\n  \n  #now lets add our NTEMS land cover from 2020\n  addRasterImage(ntems2020, \n                 #you can increase the allowable size of the rast here\n                 maxBytes = 10 * 1024 *1024) %&gt;%\n  #add a legend\n  addRasterLegend(ntems2020, opacity = 1)%&gt;%\n  #add scale bar\n  addScaleBar(position = c(\"bottomleft\"))\n\n\n\n\n\n\n\n \nComparing/Showing Multiple Layers:\nNow let’s step things up a notch, and add some additional content to our map. For the purposes of this demonstration, let’s say you have been tasked with showcasing changes in land cover on Vancouver Island from 2000 to 2020. To do so, we can use 2 key leaflet functionalities: 1) adding a toggle menu - allowing us to switch between layers, 2) adding a ‘slider’, which we can use to visualize two layers side-by-side.\n1) In order to add a toggle menu and provide NTEMs land cover of both 2000 and 2020 in our map, we do need to provide a name for our layers using the ‘group’ argument within the ‘addRasterImage’ function.\n\nl2 &lt;- leaflet(width = 600, height = 600)%&gt;%\n  \n  #lets use some base imagery from ESRI\n  addProviderTiles(\"Esri.WorldImagery\") %&gt;%\n  \n  #now lets add our NTEMS land cover from 2000\n  addRasterImage(ntems2000, \n                 #you can increase the allowable size of the rast here\n                 maxBytes = 10 * 1024 *1024,\n                 #provide a name for the layer\n                 group = \"LC-2000\") %&gt;%\n  \n  #now lets add our NTEMS land cover from 2020\n  addRasterImage(ntems2020, \n                 #you can increase the allowable size of the rast here\n                 maxBytes = 10 * 1024 *1024,\n                 #provide a name for the layer\n                 group = \"LC-2020\") %&gt;%\n  \n  #allow for layers to be toggles on/off by adding them to the layers control\n  addLayersControl(baseGroups = c(\"LC-2000\",\"LC-2020\")) %&gt;%\n  \n  #add a legend\n  addRasterLegend(ntems2000, opacity = 1)%&gt;%\n  \n  #add scale bar\n  addScaleBar(position = c(\"bottomleft\"))\n\n\n\n\n\n\n\n \n2) In order to visualize layers side-by-side and compare them using a window slider, we need to create a left and right pane, and assign our NTEMS land cover rasters to one of these panes.\n\nl3 &lt;- leaflet(width = 600, height = 600)%&gt;%\n  \n  #set up the two map panes\n  addMapPane(\"right\", zIndex = 1) %&gt;%\n  addMapPane(\"left\",  zIndex = 2) %&gt;%\n  \n  #add the ESRI basemap to both map panes\n  addProviderTiles(\"Esri.WorldImagery\", group = \"base\", layerId = \"baseid1\", options = pathOptions(pane = \"right\")) %&gt;%\n  addProviderTiles(\"Esri.WorldImagery\", group = \"base\", layerId = \"baseid2\", options = pathOptions(pane = \"left\")) %&gt;%\n  \n  #now lets add our NTEMS land cover from 2000\n  addRasterImage(ntems2000, \n                 #you can increase the allowable size of the rast here\n                 maxBytes = 10 * 1024 *1024,\n                 #provide a name for the layer\n                 group = \"LC-2000\",\n                 #assign to a pane\n                 options = leafletOptions(pane = \"left\")) %&gt;%\n  \n  #now lets add our NTEMS land cover from 2020\n  addRasterImage(ntems2020, \n                 #you can increase the allowable size of the rast here\n                 maxBytes = 10 * 1024 *1024,\n                 #provide a name for the layer\n                 group = \"LC-2020\",\n                 #assign to a pane\n                 options = leafletOptions(pane = \"right\")) %&gt;%\n  \n  #allow for layers to be toggles on/off by adding them to the layers control\n  addLayersControl(overlayGroups = c(\"LC-2000\", \"LC-2020\")) %&gt;%\n  \n  #add slider control\n  addSidebyside(layerId = \"sidecontrols\",\n                rightId = \"baseid1\",\n                leftId  = \"baseid2\",\n                options = list(padding = 0)) %&gt;%\n  \n  #add a legend\n  addRasterLegend(ntems2000, opacity = 1)%&gt;%\n  \n  #add scale bar\n  addScaleBar(position = c(\"bottomleft\"))",
    "crumbs": [
      "Interactive Maps",
      "Leaflet"
    ]
  },
  {
    "objectID": "Landing_Page/index.html",
    "href": "Landing_Page/index.html",
    "title": "FCOR 599: Workshop Artifacts",
    "section": "",
    "text": "Home Page\nHey there,\nThis webpage contains workshop artifacts created by your FCOR 599 TA’s. Many of these artifacts were initially developed as workshops, and have been archived here for your reference. The topics range from cartography to advanced figure development and python scripting - most of which were requested by previous cohorts of your peers. If you have any questions, or have suggestions for additional modules that can be included here, please talk to your FCOR 599 teaching team.\n\n\n\nReuseCC BY 4.0",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "Cartography/arcgis_pro_demo.html",
    "href": "Cartography/arcgis_pro_demo.html",
    "title": "ArcGIS Pro Demo",
    "section": "",
    "text": "As MGEM students, you all have access to ArcGIS Pro, a powerful GIS software that allows users to perform geospatial tasks and create beautiful maps. This demo focuses on the map-making capabilities of ArcGIS Pro and provides an easy reference guide for implementing core cartographic concepts and best practices. While you may have experience using ArcGIS either in or outside of MGEM, you can use this guide as a best practice resource to refer to either during your courses, or any time you’re trying to solve a tricky map.\n\n\nDisplaying your map frame in an appropriate coordinate system is important for visualization. For example, the two photos below show very different projections, and while both are technically not wrong, the one using the Mercator is clearly much better suited for our data\n\n\n\nRobinson\n\n\n\n\n\nMercator\n\n\nYou can change the projection of your map view by right-clicking on the ‘Map’ in your drawing order, and going to properties (below-left). Under the Coordinate Systems tab, you may then select a projection suitable for viewing your map (bottom-right).\nTip: Using the search bar can be the fastest way to find a projection you’re looking for, but the layers drop-down will have all the projections of any layers on your map already ready for easy selection. You can also save your most common projections under Favorites if you find yourself using the same projections over and over.\n\n\n\nSelecting a projection\n\n\n\n\n\nIn order to help our map-viewers out a little more, we can insert another map frame on our layout, showing where in Canada we are. To do so we will want to put this data in a separate ‘Map’ tab. To create one, simply click on the ‘New Map’ button on the top left of your Arc screen. Now that we have this new ’Map”, and have added our data, we can go back to our layout, and add our helpful extent map.\n\n\n\nSome of the helpful buttons for creating an inset map highlighted\n\n\nAfter selecting your layout, navigate to the ‘Insert’ tab on the top of your screen, and select ‘Map Frame’. This will give you an overview of all the maps you have created in your Arc Project, and will allow you to select one to add to your layout. We can now select the one created above, and add it to our layout by dragging a box in the spot where we wish to place it. You can then add elements such as leader lines, and separate scale bars if you feel it is appropriate.\n\n\n\n\n\nLegends are a fundamental component of any map. It is where we give the map-viewer the tools they need to interpret the data that we are presenting to them. Inserting a Legend is relatively straightforward – you can simply navigate to the ‘Insert’ tab for your layout, and click on ‘Legend’. However, once you have inserted a Legend, you may find it doesn’t look exactly appealing, and we may have to take some steps to clean things up a bit. First and foremost, there may be layers on display which we do not wish to include in our legend – to avoid clutter.\n\n\n\nCustomizing you legend can probably be one of the more frustrating things to do in ArcGIS. The quickest way to make changes is to use the properties of the legend, accessed by right clicking it and selecting the Properties option at the bottom. This will open a window on the right with lots and lots of options on things you can change. See this link for some helpful tips Legends Tips\nChanging the name of your layers can be one of the easiest things to forget when creating a map in ArcGIS, but probably the biggest difference maker when creating a map. To do so, simply right click the layer to access its Properties. In the top option, General, there is a name bar where you can type whatever name you feel is best, the great thing about this is you can use spaces and capitalized letters which often isn’t the default with GIS!\n\n\n\n\nIt can sometimes be easy to forget that the people looking at your maps are not as familiar with the data, area, and topic as you are. People from all over the world map end up looking at your map, so it is always important to make sure everyone – regardless of their background knowledge – is able to interpret and read your map. For the example shown in this document so far, people from Eastern Canada may recognize the Hudson’s Bay area in the map, yet many of us may be initially confused as to where this study area is located. There are a few ways by which we can make this easier for our map-viewer to interpret. On of these ways is by inserting grid-lines which show lat/lon lines across our map. To do so, navigate to the ‘Grid’ option in the Insert bar for your layout, and select one of the grid options.\n\n\n\nGridlines\n\n\nThis will add grid-lines to our drawing order, as well as map view. Similarly to the legend, we can right click on the grid lines in our drawing order, select properties, and make adjustments as we wish to alter the appearance of thegrid lines (not shown here).\n\n\n\nNow that we have got ourselves a nice looking map, we have to add the finishing touches. No map is complete without the essential North Arrow and Scale Bars. Thankfuly, both are easy to add! Simply select the ‘North Arrow’ Dropdown at the top of your screen, and choose whichever strikes your fancy.\nFor scale bars, simply select the ‘Scale Bar’ dropdown, select one of the available options, and drag a box where you would like to place it. Now it is important to note that when you add a scale bar or north arrow, it will do so based on the map frame you have selected in your layout. Since we are making use of an inset in this example, we will then need to make sure to add a second scale bar to show the scale of our inset. Simply select the inset map frame in the layout, and add a second scale bar – placing it in an appropriate spot.",
    "crumbs": [
      "Cartography",
      "ArcGIS Pro Demo"
    ]
  },
  {
    "objectID": "Cartography/art_of_maps.html",
    "href": "Cartography/art_of_maps.html",
    "title": "The Art of Map Making",
    "section": "",
    "text": "Although the emphasis in this course and programme is rightly on ensuring the scientific integrity of maps, the artistic component of mapmaking is a key component of science communication and should not be overlooked. Cartography is the art and science of mapmaking. Finding the balance between art and science can be very difficult and will look different for each individual map maker. However, finding this balance is key to creating beautiful maps that people want to look at, but that also effectively communicate your data and your take-home message.\nMap making, especially cartography, is an art as we have just discussed. There are so many beautiful maps and amazing ways to display data or information. While here at MGEM, or in any GIS position or work you do, it’s always helpful and inspiring to find maps that tell a story visually. These can either inspire you to make better maps, or maybe even give you ideas about how you might want to visualise data.\n\n\nThere are many beautiful maps out in the world that are more art than science but that doesn’t disqualify them from being called a map. Here are a few examples of what might not traditionally be called maps in a scientific sense, but can be used as either a cool visualization or maybe even some inspiration for your work:\n\n\n\n\n\n\n\nWhistler village, Canada, by James Niehues\n\n\nMaps like the one above are a great example that not every map needs to have every single detail shown, like we’ve talked about “all maps are lies”, so sometimes you need to lie a little to better convey a message and visualize your work.\n\n\n\n3D map of Manhattan by Luis Dilger\n\n\nWhile these shift a little bit from what we talked about in the cartography section of today, hopefully these can serve as a reminder that map making is an art its core, don’t be afraid to put your own style and touch on your maps!",
    "crumbs": [
      "Cartography",
      "The Art of Map Making"
    ]
  },
  {
    "objectID": "Cartography/cartography.html",
    "href": "Cartography/cartography.html",
    "title": "Cartography",
    "section": "",
    "text": "Cartography is the art and science of creating, studying, and distributing maps and other visual representations of geographical areas. It involves a combination of scientific and artistic skills to communicate information about a place. In this workshop module, you will learn about the history and modern applications of cartography, followed by some specific demonstrations on the art of map making and advanced map making in ArcGIS Pro.\n\nBrief History of Cartography\nIn our modern world, we have access to detailed street maps, global satellite imagery, and GPS navigation. Through these tools, maps are often seen as direct representations of our environment - but how did we arrive at this point? Maps are one of the oldest forms of human communication, serving as tools which help us make sense of our surroundings at various scales (Harley and Woodward 1994). Historically, the map served as an appealing method of communication since it did not require formal literacy from its’ creator or user. However, this does not mean maps were easy to produce - having to provide two-dimensional combinations of shapes, sizes and orientations between locations. Indeed, many early maps failed to to take one or more of these elements into account, resulting in maps they may be more symbolic that literal in their representation of the world. Today, many of these works are on display at museums across the world, valued as anthropological artifacts mroe than as geographic reference material. For example, one of the earliest and most famous world maps was produced on clay tablets in Babylon ~ 600 BCE. This map captured the Babylon and Euphrates rivers, along with the neighboring cities of Assyria and Susa. Outside the circular disk representing the known world, triangular shapes point to lands from Babylonian myth and cosmology (“Babylonian World Map Tablet,” n.d.)\n\n\n\nBablynonian World Map (circa ~600 BCE)\n\n\nAs scientific knowledge advanced throughout classical antiquity, advances in mapping followed suit. The Greeks were among the first to explore mathematical concepts for representing the Earth’s curved surface on a two-dimensional plane - starting in the 6th century BCE. It wasn’t until the 2nd century CE however, that Greek Mathematician and Astrologer Ptolemy (100-170 CE) produced the planishpaerium, a celestial chart mapping stars onto a two-dimensional plane using the first stereographic projection (Harley and Woodward 1994). His geographia provided an instructional framework for the projection of geographic coordinates onto two-dimensional planes, forming the foundation of cartographic advances for centuries to come. Shortly after Ptolemy’s success in the Western world, Chinese cartographer Pei Xiu (224-271 CE) revolutionized map-making in China by prescribing key principles for the use of rectangular grids and graduated scales in measuring distances for the creation of maps.\nDuring the middle ages (5th to 15th centuries) advancement in map-making was largely concentrated in the Islamic world. Built on the foundations of Ptolemy’s methods, maps of the known world were expanded and improved based on information from explorers and merchants travelling from the Muslim world to Spain, India, Africa, China and Russia. Notably, the 9th century Persian mathematician and geographer Habash al-Hasib al-Marwazi developed one of the earliest examples of spherical trigonometry in cartography by projecting coordinates to different coordinate systems. Founded in the early 10th century, these methods were applied to develop atlases and world maps at the famous Balkhi school of terrestrial mapping in Baghdad (Wheatley 1996) (Hiatt and Brill Online Books 2021). Meanwhile in Europe, most maps produced during this era served more as symbolic representations than mathematical navigation tools. These maps were not typically made to serve as general reference tools for navigation, typically being confined to specific areas and use-cases (Harley and Woodward 1994). It was not until the 11th century that the transmission of scientific knowledge from the Arabic-Islamic world began to signicantly effect European-Christian life (Hiatt and Brill Online Books 2021).\nThe next major period of cartographic advancement occurred during the ‘Age of Exploration’ (1450-1750 CE), where European nations began navigating and colonizing the globe. With a particular focus on navigating ships across vast oceans, the Mercator projection was invented in 1569 by the Belgian geographer/cartographer Gerardus Mercator (“Gerardus Mercator,” n.d.). Although many advances in cartography have taken place since, the Mercator projection remains possibly the most famous projection of all time, hanging on many a classroom wall to this day.\n\n\n\nGerardus Mercator’s 1569 Map of the World\n\n\nDespite these technological advances in mathematics and map-making, representations of our environments continued to contain notable flaws and mistakes. In the early 1500’s, Spanish author Garcia Rodriguez de Montalvo first described the ‘mythical island’ of California. Despite exploration of the area by explorers (who determined California was a peninsula) map-makers simply denied their claims and continued to portray California as an island over the next two centuries. Although seemingly obvious now, such ‘mistakes’ reflect a core concept of cartography that persists today - that maps reflect knowledge, ideas and assumptions which are a susceptible to human error. In our modern era, we have access to highly accurate information about our environments, countries, cities, navigation routes, etc. Regardless, the way in which we present this information to an audience is an exercise that requires diligence and expertise. In the workshops associated to this Cartography section, we will discuss some key considerations and best-practices for modern map-making.\n\n\n\n1720 Map of California by Nicholas de Fer (Paris)\n\n\n\n\n\n\n\nReferences\n\n“Babylonian World Map Tablet.” n.d. https://www.britishmuseum.org/collection/object/W_1882-0714-509.\n\n\n“Gerardus Mercator.” n.d. https://education.nationalgeographic.org/resource/gerardus-mercator.\n\n\nHarley, John Brian, and David Woodward. 1994. “Cartography in Prehistoric, Ancient, and Medieval Europe and the Mediterranean (1987). Vol. 1 of the History of Cartography., Eds.” Cartography in the Traditional East and Southeast Asian Societies 2.\n\n\nHiatt, Alfred, and Brill Online Books. 2021. Cartography Between Christian Europe and the Arabic-Islamic World, 1100-1500: Divergent Traditions. 1st ed. Vol. 3. Book, Whole. Leiden;Boston; Brill. https://ubc.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwfV3PS8MwFH647aA3dYpzbuQyT1aypK7pcRsbCsOT95I2KfZSocyD_70vr-nsRvESQiDkyw-Sl5fvywOQ4pkHJ3sC7ggqUsaoVIcZrmsTZlxZtZibWFgr9AlVp5Hj_5X9N_EdAabJXy5CFxIzemzU_tXe_wI9E9yzoDBXi_gL527ktQccM0Qq5GiCYbqsdFpkAU1RkWEB_WWKIzCjw5MHaFNxzOOSwtQ4OoVTRbn6lTY18aoHPbyJ1AEWjmzZltbfHWjbSxhYp3K4gjNbXsO5D4X--TOEXasHzONnB_Ssxs4QOUPc7Bg1I8xP7ID3Bsbbzcf6NcD2E-8pStz3bwJNLnkL_fKrtHfAZJ4qp181Tq0wj3MtpYnTEC-SeSa55iNgTWcSet71nNJks1ov0NZC624Ew65GRjBpFzePbQk99cXRy313tTFcCEcrIS_IA_T31bed0DBOaXSnMFiudu9vv_anvEM.\n\n\nWheatley, Paul. 1996. “Asia in the History of Cartography. \"The History of Cartography, Volume Two, Book One: Cartography in the Traditional Islamic and South Asian Societies. Volume Two, Book Two: Cartography in the Traditional East and Southeast Asian Societies\". Edited by j. B. Harley and David Woodward.” Imago Mundi (Lympne) 48 (Journal Article): 216. https://ubc.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwtV1JT8JAFB6Bi16Ma1zQvOix0NCFJSYewKBConBo4pEAnSYcKIYlht_pH_K9N1PasOrBS9N0yjeh38f0zeMtQji2WcgvrQluYNu9vo_mc7nctd0S1THvWT6Koxho304iVCf1HaXGxBf_lXm8htxTJu0f2F-A4gU8Rw3gEVWAx1_pAKfsRsGMqiaIzskaT3W1ahPpt72NwxwJy2uY4X2xY5XzI1ohZ7UnboxmwdefP9AuRlacLgnL3fqMKmdtqmBR2qWvw6bz3dj17mQaA1MPomVw_F6mUffZqkYzu2kaNZPSlmgh5BBsCug3PkYj7lydtNMbQ4pPGc5Cf8BNT-bDz1AmvCb8DtPu_kVwpa-zCZedJwrsjcHiKCpOJitU8sWS6r8cvShUSdDFSr-mgne72uq0G61O6x03IlS7fegP-tNHGeZnk7RIO5bu7rBwCaD9p__nUtOtWARs5nhH4lDvT6CqhHQsUjI8EfsvUvNwupelZwyDEPCRg1YMjAJICgruvI2DOVCEA5KcA6IbUEoPyVsi9ATZoIUESBsw38BcQyykVVw824lLIopBSUTLwHcmKAlBbw5NE2omKAnxx1hCEEnoTNw_172n13z0eDv6Nzrp0B6hYqHd7TjnIhOOQnkhoC97lPVtIUN9l3ZR0nFtKrdZDqQVuMGlyG5Duto-fC0OYjVmRWY6nskbrvtxy_r4AcfVtLQ.",
    "crumbs": [
      "Cartography"
    ]
  },
  {
    "objectID": "Interactive_Maps/interactive_maps.html",
    "href": "Interactive_Maps/interactive_maps.html",
    "title": "Interactive Maps",
    "section": "",
    "text": "Although conventional maps are static and do not allow for user interaction, geospatial practitioners have developed exciting new ways in which we can present geographic information in interactive formats. Although not exhaustive by any means, this section will cover several key ways in which you can create digital maps that allow for user-interaction.",
    "crumbs": [
      "Interactive Maps"
    ]
  },
  {
    "objectID": "Interactive_Maps/leaflet.html",
    "href": "Interactive_Maps/leaflet.html",
    "title": "Leaflet",
    "section": "",
    "text": "Many software and coding packages can be used to create interactive maps. In this particular demo, we will show you an easy way to produce interactive maps in leaflet - a popular R package. Leaflet is intuitive, fast, and has many arguments that allow us to easily adjust the way in which we present our maps. In the example below, we used NTEMs land cover from 2020 to produce a simple interactive map for Vancouver Island. In the code below, you will notice that we add in a basemap using the ‘addProviderTiles’ argument. You can browse for available leaflet basemaps here: https://leaflet-extras.github.io/leaflet-providers/preview/\n\nl &lt;- leaflet(width = 600, height = 600)%&gt;%\n  \n  #lets use some base imagery from ESRI\n  addProviderTiles(\"Esri.WorldImagery\") %&gt;%\n  \n  #now lets add our NTEMS land cover from 2020\n  addRasterImage(ntems2020, \n                 #you can increase the allowable size of the rast here\n                 maxBytes = 10 * 1024 *1024) %&gt;%\n  #add a legend\n  addRasterLegend(ntems2020, opacity = 1)%&gt;%\n  #add scale bar\n  addScaleBar(position = c(\"bottomleft\"))",
    "crumbs": [
      "Interactive Maps",
      "Leaflet"
    ]
  },
  {
    "objectID": "E-Portfolio/eportfolio.html",
    "href": "E-Portfolio/eportfolio.html",
    "title": "E-Portfolio",
    "section": "",
    "text": "As part of FCOR 599, you are required to produce a professional E-Portfolio. This portfolio is intended to capture the breadth of skills you have developed throughout the program, including scientific writing & reporting, figure design, cartography, coding, etc. As has been introduced in the E-Portfolio workshop, a portfolio is essentially an organized digital collection of artifacts that highlight key pieces of work, accomplishments and skills. This is a great place for you to present your learning, experience, achievements, etc. - and serves as a great reference for researchers, colleagues and potential employers to see what you’re all about.\nIn other words, an E-Portfolio goes beyond what you might present in a resume or social media (i.e. linkedin) page, and allows you to express yourself through written work, images, media, etc. Rather than focusing on presenting entire bodies of finished work like a report, your E-Portfolio is a great place to demonstrate your learning and skills by presenting smaller pieces of work. Whilst many of your MGEM deliverables are the product of rubrics and assignment instructions, your E-Portfolio is ultimately entirely your own - so feel free to adjust, edit, add, and remove from your program deliverables as you see fit.\nWe highly recommend to design elements of learning into your E-Portfolio. Rather than just sharing a figure, you may want to also share some annotated code that you used to produce said figure. You could also add several iterations of a figure (of varying complexity) to demonstrate your learning trajectory. Before we dive into the techincal aspects of building your E-Portfolio using Quarto & GitHub, here are some key considerations from the UBC library workshop to remember:\n\nYour work will be visible to anyone on the internet. Ensure that you are representing yourself accurately.\nProvide credit to those who have contributed to your work.\nRespect and follow copyright and privacy laws where appropriate.",
    "crumbs": [
      "E-portfolio"
    ]
  },
  {
    "objectID": "E-Portfolio/eportfolio.html#quarto",
    "href": "E-Portfolio/eportfolio.html#quarto",
    "title": "E-Portfolio",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org.",
    "crumbs": [
      "E-portfolio (Quarto)"
    ]
  },
  {
    "objectID": "E-Portfolio/eportfolio.html#running-code",
    "href": "E-Portfolio/eportfolio.html#running-code",
    "title": "E-Portfolio",
    "section": "Running Code",
    "text": "Running Code\nWhen you click the Render button a document will be generated that includes both content and the output of embedded code. You can embed code like this:\n\n1 + 1\n\n[1] 2\n\n\nYou can add options to executable code like this\n\n\n[1] 4\n\n\nThe echo: false option disables the printing of code (only output is displayed).",
    "crumbs": [
      "E-portfolio (Quarto)"
    ]
  },
  {
    "objectID": "E-Portfolio/eportfolio.html#building-a-portfolio-in-quarto",
    "href": "E-Portfolio/eportfolio.html#building-a-portfolio-in-quarto",
    "title": "E-Portfolio",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org. In this module, we will be using Quarto to construct an E-portfolio. The key advantage of building your portfolio in Quarto is that you can easily integrate any workflow, results, figures etc. that you have created in R-Studio. This workshop repository itself was built in Quarto, and is hosted on Github. In order to build your own portfolio, we have put together a simple github repository that provides the basic files you will need. In order to interact with the repository and build your own e-portfolio using quarto and github, you will need the following:\n\nA github account.\nGithub deskptop (make sure you are logged in).\nR-Studio.\nThe sample repository (available here).",
    "crumbs": [
      "E-portfolio (Quarto)"
    ]
  },
  {
    "objectID": "E-Portfolio/eportfolio.html#e-portfolio-basics",
    "href": "E-Portfolio/eportfolio.html#e-portfolio-basics",
    "title": "E-Portfolio",
    "section": "",
    "text": "As part of FCOR 599, you are required to produce a professional E-Portfolio. This portfolio is intended to capture the breadth of skills you have developed throughout the program, including scientific writing & reporting, figure design, cartography, coding, etc. As has been introduced in the E-Portfolio workshop, a portfolio is essentially an organized digital collection of artifacts that highlight key pieces of work, accomplishments and skills. This is a great place for you to present your learning, experience, achievements, etc. - and serves as a great reference for researchers, colleagues and potential employers to see what you’re all about.\nIn other words, an E-Portfolio goes beyond what you might present in a resume or social media (i.e. linkedin) page, and allows you to express yourself through written work, images, media, etc. Rather than focusing on presenting entire bodies of finished work like a report, your E-Portfolio is a great place to demonstrate your learning and skills by presenting smaller pieces of work. Whilst many of your MGEM deliverables are the product of rubrics and assignment instructions, your E-Portfolio is ultimately entirely your own - so feel free to adjust, edit, add, and remove from your program deliverables as you see fit.\nWe highly recommend to design elements of learning into your E-Portfolio. Rather than just sharing a figure, you may want to also share some annotated code that you used to produce said figure. You could also add several iterations of a figure (of varying complexity) to demonstrate your learning trajectory. Before we dive into the techincal aspects of building your E-Portfolio using Quarto & GitHub, here are some key considerations from the UBC library workshop to remember:\n\nYour work will be visible to anyone on the internet. Ensure that you are representing yourself accurately.\nProvide credit to those who have contributed to your work.\nRespect and follow copyright and privacy laws where appropriate.",
    "crumbs": [
      "E-portfolio"
    ]
  },
  {
    "objectID": "E-Portfolio/eportfolio.html#building-an-e-portfolio-in-quarto",
    "href": "E-Portfolio/eportfolio.html#building-an-e-portfolio-in-quarto",
    "title": "E-Portfolio",
    "section": "Building an E-Portfolio in Quarto",
    "text": "Building an E-Portfolio in Quarto\nIn your E-Portfolio workshop, you were introduced to UBC blogs, where you can host a portfolio via wordpress. Since many of you are quite familiar with coding in R-studio at this stage in the pogram, the demo below will demonstrate how you can build a portfolio using Quarto in R-Studio. Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org.\nThe key advantage of building your portfolio in Quarto is that you can easily integrate any workflow, results, figures etc. that you have created in R-Studio. This workshop repository itself was built in Quarto, and is hosted on Github. In order to build your own portfolio, we have put together a simple github repository that provides the basic files you will need. In order to interact with the repository and build your own e-portfolio using quarto and github, you will need the following:\n\nA github account.\nGithub deskptop (make sure you are logged in).\nR-Studio.\nThe sample repository (available here).\n\nQuarto Portfolio Instructions:\nBefore we begin, make sure you have Github desktop installed on your device, that you are logged in to your github account in the desktop app, and that you have R-Studio installed on your device.\n\nNavigate to the sample repository using the link above.\nNow ‘fork’ the repository - this will create a copy of all of the files on your github account. You can make changes to this ‘forked’ repository without affecting the original or getting things mixed up with your peers. Make sure you provide a descriptive name for the forked repo.\nOpen up your Github Desktop app and navigate to ‘File &gt; Clone Repository’. This will show you all of the repositories that are available to be cloned based on your github account. Find the forked repo and clone it to a local path. You will get a pop-up that asks you how you plan to use this fork - make sure you select the ‘for my own purposes’ option.\nIn the Github Desktop app, click on the ‘Show in Explorer’ button - this will navigate to the folder on your computer where all the repo files are stored. This folder is where you will make changes to your E-Portfolio files.\nOpen up an R-Studio session and click on ‘File &gt; Open File’. Navigate to your explorer folder with all of the repo files, and open the “_quarto.yml” file. This file controls the indexing of your E-Portfolio. At the top, you will notice there is a file path for your output directory - change this to the folder containing your cloned repository and save the file.\nNext, open up the ‘index.qmd’ file. Edit the file with your own profile picture (if you’d like), contact information, and introduction blurb. When you are finished editing the page, save the .qmd file and hit ‘render’. This will give you a preview of what the page will look like in your E-Portfolio. Repeat this step for the ‘resume.qmd’ file.\nIn your Github Desktop, you will now notice that there are local changes to the repository files based on your edits. You can push these edits to your github by clicking ‘commit to main’.\n\nIn order to customize your E-Portfolio, we encourage you to review the following resources:\n\nQuarto HTML Basics\nQuarto HTML Options\nQuarto Theming\n\nOnce you are satisfied with the content of your E-Portfolio, it is time to publish your website. Before you do so, make sure you have committed all local changes from your desktop. Once you are ready:\n\nOpen your github account in your web browser, and navigate to your E-Portfolio repository.\nIn the top bar, select ‘Settings’ and navigate to ‘Pages’ under the ‘Code and automation’ column.\nUnder ‘Build and deployment’ &gt; ‘Branch’, select the ‘Main’ branch, and click save.\nYour website is now being built. This will take a few minutes, so be patient and refresh the page after ~ 2-5 minutes. Once complete, a url for your website will now be available to you.",
    "crumbs": [
      "E-portfolio"
    ]
  },
  {
    "objectID": "Interactive_Maps/leaflet.html#the-basics",
    "href": "Interactive_Maps/leaflet.html#the-basics",
    "title": "Leaflet",
    "section": "",
    "text": "Many software and coding packages can be used to create interactive maps. In this particular demo, we will show you an easy way to produce interactive maps in leaflet - a popular R package. Leaflet is intuitive, fast, and has many arguments that allow us to easily adjust the way in which we present our maps. In the example below, we used NTEMs land cover from 2020 to produce a simple interactive map for Vancouver Island. In the code below, you will notice that we add in a basemap using the ‘addProviderTiles’ argument. You can browse for available leaflet basemaps here: https://leaflet-extras.github.io/leaflet-providers/preview/\n\nl &lt;- leaflet(width = 600, height = 600)%&gt;%\n  \n  #lets use some base imagery from ESRI\n  addProviderTiles(\"Esri.WorldImagery\") %&gt;%\n  \n  #now lets add our NTEMS land cover from 2020\n  addRasterImage(ntems2020, \n                 #you can increase the allowable size of the rast here\n                 maxBytes = 10 * 1024 *1024) %&gt;%\n  #add a legend\n  addRasterLegend(ntems2020, opacity = 1)%&gt;%\n  #add scale bar\n  addScaleBar(position = c(\"bottomleft\"))",
    "crumbs": [
      "Interactive Maps",
      "Leaflet"
    ]
  },
  {
    "objectID": "Interactive_Maps/leaflet.html#comparingshowing-multiple-layers",
    "href": "Interactive_Maps/leaflet.html#comparingshowing-multiple-layers",
    "title": "Leaflet",
    "section": "Comparing/Showing Multiple Layers",
    "text": "Comparing/Showing Multiple Layers\nNow let’s step things up a notch, and add some additional content to our map. For the purposes of this demonstration, let’s say you have been tasked with showcasing changes in land cover on Vancouver Island from 2000 to 2020. To do so, we can use 2 key leaflet functionalities: 1) adding a toggle menu - allowing us to switch between layers, 2) adding a ‘slider’, which we can use to visualize two layers side-by-side.\n1) In order to add a toggle menu and provide NTEMs land cover of both 2000 and 2020 in our map, we do need to provide a name for our layers using the ‘group’ argument within the ‘addRasterImage’ function.\n\nl2 &lt;- leaflet(width = 600, height = 600)%&gt;%\n  \n  #lets use some base imagery from ESRI\n  addProviderTiles(\"Esri.WorldImagery\") %&gt;%\n  \n  #now lets add our NTEMS land cover from 2000\n  addRasterImage(ntems2000, \n                 #you can increase the allowable size of the rast here\n                 maxBytes = 10 * 1024 *1024,\n                 #provide a name for the layer\n                 group = \"LC-2000\") %&gt;%\n  \n  #now lets add our NTEMS land cover from 2020\n  addRasterImage(ntems2020, \n                 #you can increase the allowable size of the rast here\n                 maxBytes = 10 * 1024 *1024,\n                 #provide a name for the layer\n                 group = \"LC-2020\") %&gt;%\n  \n  #allow for layers to be toggles on/off by adding them to the layers control\n  addLayersControl(baseGroups = c(\"LC-2000\",\"LC-2020\")) %&gt;%\n  \n  #add a legend\n  addRasterLegend(ntems2000, opacity = 1)%&gt;%\n  \n  #add scale bar\n  addScaleBar(position = c(\"bottomleft\"))\n\n\n\n\n\n\n\n \n2) In order to visualize layers side-by-side and compare them using a window slider, we need to create a left and right pane, and assign our NTEMS land cover rasters to one of these panes.\n\nl3 &lt;- leaflet(width = 600, height = 600)%&gt;%\n  \n  #set up the two map panes\n  addMapPane(\"right\", zIndex = 1) %&gt;%\n  addMapPane(\"left\",  zIndex = 2) %&gt;%\n  \n  #add the ESRI basemap to both map panes\n  addProviderTiles(\"Esri.WorldImagery\", group = \"base\", layerId = \"baseid1\", options = pathOptions(pane = \"right\")) %&gt;%\n  addProviderTiles(\"Esri.WorldImagery\", group = \"base\", layerId = \"baseid2\", options = pathOptions(pane = \"left\")) %&gt;%\n  \n  #now lets add our NTEMS land cover from 2000\n  addRasterImage(ntems2000, \n                 #you can increase the allowable size of the rast here\n                 maxBytes = 10 * 1024 *1024,\n                 #provide a name for the layer\n                 group = \"LC-2000\",\n                 #assign to a pane\n                 options = leafletOptions(pane = \"left\")) %&gt;%\n  \n  #now lets add our NTEMS land cover from 2020\n  addRasterImage(ntems2020, \n                 #you can increase the allowable size of the rast here\n                 maxBytes = 10 * 1024 *1024,\n                 #provide a name for the layer\n                 group = \"LC-2020\",\n                 #assign to a pane\n                 options = leafletOptions(pane = \"right\")) %&gt;%\n  \n  #allow for layers to be toggles on/off by adding them to the layers control\n  addLayersControl(overlayGroups = c(\"LC-2000\", \"LC-2020\")) %&gt;%\n  \n  #add slider control\n  addSidebyside(layerId = \"sidecontrols\",\n                rightId = \"baseid1\",\n                leftId  = \"baseid2\",\n                options = list(padding = 0)) %&gt;%\n  \n  #add a legend\n  addRasterLegend(ntems2000, opacity = 1)%&gt;%\n  \n  #add scale bar\n  addScaleBar(position = c(\"bottomleft\"))",
    "crumbs": [
      "Interactive Maps",
      "Leaflet"
    ]
  },
  {
    "objectID": "CodingCrossover/codingcrossover.html",
    "href": "CodingCrossover/codingcrossover.html",
    "title": "Coding Crossover",
    "section": "",
    "text": "This repository provides a side-by-side comparison of how to perform common geomatics tasks in R and Python. It focuses on the libraries terra and sf in R, and rasterio, numpy, pandas, and geopandas in Python.",
    "crumbs": [
      "Coding Crossover"
    ]
  },
  {
    "objectID": "CodingCrossover/codingcrossover.html#quarto",
    "href": "CodingCrossover/codingcrossover.html#quarto",
    "title": "Coding Crossover",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org.",
    "crumbs": [
      "Coding Crossover"
    ]
  },
  {
    "objectID": "CodingCrossover/codingcrossover.html#running-code",
    "href": "CodingCrossover/codingcrossover.html#running-code",
    "title": "Coding Crossover",
    "section": "Running Code",
    "text": "Running Code\nWhen you click the Render button a document will be generated that includes both content and the output of embedded code. You can embed code like this:\n\n1 + 1\n\n[1] 2\n\n\nYou can add options to executable code like this\n\n\n[1] 4\n\n\nThe echo: false option disables the printing of code (only output is displayed).",
    "crumbs": [
      "Coding Crossover"
    ]
  },
  {
    "objectID": "CodingCrossover/scripts/supervised_classification.html",
    "href": "CodingCrossover/scripts/supervised_classification.html",
    "title": "Supervised Image Classification in Python",
    "section": "",
    "text": "This notebook will walk you through how to do the supervised image classification that was completed in GEM 520 but this time we will complete it Python. It is recommended that you create a new folder with your training polygons and the raster image, as you do not want to overwrite any information from your lab for this process. We will only be going over the scripting part of the lab in this activity to show the differences between R and Python, so it is encouraged that you have your R scripts from that lab open as well to see what the similarities and differences are.\nWe have already installed the correct packages used in this script when you ran the create_environment.py script. Now we can import the packages that we will need to run this activity.\nimport fiona\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport rasterio\nfrom matplotlib.colors import ListedColormap\nfrom rasterio.features import geometry_mask\nfrom skimage import exposure\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, confusion_matrix, f1_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.svm import SVC\nWe will start by reading in the Landsat image into Python and plotting it.\nNote: This image can also be found here if you are unable to find the image from this assignment.\n# Read in the Landsat image (CHANGE PATH TO YOUR SYSTEM)\nwith rasterio.open(\n    r\"D:\\MurrayBrent\\git\\CodingCrossover\\data\\LC09_L2SP_047026_20240716_20240717_02_T1_SR_BSTACK.tif\"\n) as src:\n    raster = src.read()  # read raster as an array\n    transform = src.transform  # get the transform information\n\n# Create a true colour composite\nrgb_image = np.stack(\n    (raster[2], raster[1], raster[0]),\n    axis=-1,\n)  # remember that python starts with 0\n\n# Plot the true colour composite\nplt.figure(figsize=(10, 10))  # initalize figure and set size\nplt.axis(\"off\")  # turn axis off for visualization\nplt.imshow(rgb_image)  # show the true colour composite\nYou will notice when we plot this image that it is very dark and that there are some pixels that have a nan value. Below is a function that will implement an image stretch and replace the nan values with 0. We will then plot the true colour composite again.\ndef percentile_stretch(band, lower_percentile=2, upper_percentile=98):\n    band[np.isnan(band)] = 0  # set nan values to 0\n    band_min, band_max = np.percentile(\n        band, (lower_percentile, upper_percentile)\n    )  # get min and max values based on defined percentiles\n    stretched_band = (band - band_min) / (\n        band_max - band_min\n    )  # perform stretch on band\n    return np.clip(stretched_band, 0, 1)  # return band within value range (0-1)\n# Create a true colour composite with stretch\nrgb_image = np.stack(\n    (\n        percentile_stretch(raster[2]),\n        percentile_stretch(raster[1]),\n        percentile_stretch(raster[0]),\n    ),\n    axis=-1,\n)  # remember that python starts with 0\n\n# Plot the true colour composite\nplt.figure(figsize=(10, 10))  # initalize figure and set size\nplt.axis(\"off\")  # turn axis off for visualization\nplt.imshow(rgb_image)  # show the true colour composite\nThen, we load the delineated polygons and plot them with the image.\nNote: A version of these polygons can also be found here if you are unable to find your polygons from the original assignment.\n# Read in classification polygons as geopandas dataframe (CHANGE PATH TO YOUR SYSTEM)\nwith fiona.open(\n    r\"D:\\MurrayBrent\\git\\CodingCrossover\\data\\classification_polygons.shp\"\n) as poly:\n    gdf = gpd.GeoDataFrame.from_features(poly, crs=poly.crs)\n# Plot the image with the polygons\nfig, ax = plt.subplots(figsize=(10, 10))  # initialize figure\nax.imshow(\n    rgb_image,\n    extent=(src.bounds.left, src.bounds.right, src.bounds.bottom, src.bounds.top),\n)  # plot the image\ngdf.boundary.plot(ax=ax, color=\"red\", linewidth=1)  # plot the boundary of the polygons\nplt.axis(\"off\")  # turn axis off for visualization\nplt.show()  # show full plot\nYou will notice when we plotted the polygon boundaries that we called it straight from the geopandas dataframe (gdf). Both geopandas and pandas have built in plotting using matplotlib, so we dont need to specifically call any matplotlib functions. The functions that are built into geopandas and pandas use the standard matplotlib convention, meaning you can edit and change the plots in the same way you would in matplotlib.\nHere is a summary of the number of polygons per class.\npoly_summary = gdf[\"lc_class\"].value_counts()  # get a count of the `lc_class` field\npoly_summary\nFor each land cover class, we will use 70% of the polygons to train the classification algorithm and the remaining 30% for validation. We are going to add a column to the dataframe called ‘set’ to identify which polygons will be used for training and which will be used for validation based on a stratified random sample of the ‘lc_class’ column. We will then split the dataframe into two one for training and one for validation.\n# Encode 'lc_class' so that it is a class number (factor in R)\ngdf[\"lc_class_encoded\"] = gdf[\"lc_class\"].astype(\"category\").cat.codes\n# Split the data into a 70:30 split\ntrain_idx, val_idx = train_test_split(\n    gdf.index, test_size=0.3, stratify=gdf[\"lc_class\"], random_state=1234\n)  # stratified random sample based on 'lc_class'\n\n# Create new column 'set'\ngdf[\"set\"] = \"Training\"  # set default value to training\ngdf.loc[val_idx, \"set\"] = \"Validation\"  # replace value with 'Validation'\n\n# Create a Training and a Validation dataframe\ntrain_gdf = gdf[gdf[\"set\"] == \"Training\"]  # training dataframe\nval_gdf = gdf[gdf[\"set\"] == \"Validation\"]  # validation dataframe\nWe now need to get the raster data ready to perform the maximum likelihood classification. We need to get the shape of the raster, replace any nan values, and flatten the raster for easier processing.\n# Preprocess raster for classificaiton\n(\n    B,  # band\n    H,  # height\n    W,  # width\n) = raster.shape  # get shape of raster\nraster = np.nan_to_num(raster, nan=0)  # replace nan to 0\nflattened_raster = raster.reshape(B, -1).T  # Flatten raster to shape (H*W, B)\nNow we can extract the values of the Landsat image based on the training polygons.\n# Prepare training data\nx_train, y_train = [], []  # empty lists for pixel values and labels\nfor idx, row in train_gdf.iterrows():  # iterate through each polygon\n    # Generate a mask for the polygon\n    mask = geometry_mask(\n        [row.geometry], transform=transform, invert=True, out_shape=(H, W)\n    )\n\n    # Collect pixel values and labels\n    pixels = flattened_raster[mask.flatten()]  # extract pixel values\n    labels = np.full(len(pixels), row[\"lc_class_encoded\"])  # get label\n\n    # Append to lists\n    x_train.append(pixels)\n    y_train.append(labels)\n\n# Concatenate training data\nx_train = np.vstack(x_train)\ny_train = np.concatenate(y_train)\nThe maximum likelihood classification will be performed using the GaussianNB() function from the scikit-learn package. The GaussianNB() function implements the Gaussian Naive Bayes algorithm for classification. This function fits to the training data we extracted in the previous step and then predicting the class for each pixel in the raster image. For more information on this function visit the scikit-learn user guide.\n# Train maximum likeihood classifier (Gaussian Naive Bayes)\nclassifier = GaussianNB()  # call model to use\nclassifier.fit(x_train, y_train)  # fit/train model to training data\n\n# Classify entier raster\npredicted = classifier.predict(flattened_raster)  # predict class to each pixel\nclassified_raster = predicted.reshape(\n    H, W\n)  # reshape prediction from flattened raster to original dimensions\nNow let’s plot the classified raster to see how this model worked.\n# Set appropriate colours for each class\ncolors = [\"#A6D96A\", \"#33A02C\", \"#DE3B13\", \"#D63CF1\", \"#00D2D2\", \"#F1A026\", \"#2B83BA\"]\ncmap = ListedColormap(colors)\n\n# Plot classified image\nplt.figure(figsize=(10, 10))  # initialize figure and set size\nplt.axis(\"off\")  # turn axis off for visualization\nplt.imshow(classified_raster, cmap=cmap)  # plot classified raster with defined colours\nUsing the validation polygons, we can extract the predicted classes and the ‘true’ values so we can calculate our accuracy metrics and create a confusion matrix.\n# Prepare validation data\ntrue_classes, predicted_classes = [], []  # empty lists for true and predicted classes\nfor idx, row in val_gdf.iterrows():  # iterate through each polygon\n    # Generate a mask for the polygon\n    mask = geometry_mask(\n        [row.geometry], transform=transform, invert=True, out_shape=(H, W)\n    )\n\n    # Extract true clas labels\n    true_label = row[\"lc_class_encoded\"]  # Column with the true encoded class labels\n    true_values = np.full(np.sum(mask), true_label)\n\n    # Extract predicted class labels from classified raster\n    predicted_values = classified_raster[mask]\n\n    # Append to lists\n    true_classes.extend(true_values)\n    predicted_classes.extend(predicted_values)\n\n# Convert lists to numpy arrays\ntrue_classes = np.array(true_classes)\npredicted_classes = np.array(predicted_classes)\nNow we can calculate the overall accuracy and F1 score.\n# Calculate accuracy metrics and print values\noa = accuracy_score(true_classes, predicted_classes)  # overall accuracy\nf1 = f1_score(true_classes, predicted_classes, average=\"weighted\")  # f1 score\nprint(f\"Overall Accuracy: {oa}\\nF1 Score: {f1}\")\nWe can also create a confusion matrix and calculate the Producer’s and User’s accuracies.\n# Create confusion matrix\nconf_matrix = confusion_matrix(true_classes, predicted_classes)\n\n# Calculate producers and users accuracies from confusion matrix\npa = np.diag(conf_matrix) / np.sum(conf_matrix, axis=1)  # producers accuracy\nua = np.diag(conf_matrix) / np.sum(conf_matrix, axis=0)  # users accuracy\n\n# Create dataframe for confusion matrix\nclasses = np.unique(gdf[\"lc_class\"])  # get unique class label\nconf_matrix_df = pd.DataFrame(\n    conf_matrix.T, index=classes, columns=classes\n)  # create dataframe\n\n# Add producers and users accuracies to dataframe\nconf_matrix_df.loc[\"Producer's Accuracy\"] = np.round(pa * 100, 3)\nconf_matrix_df[\"User's Accuracy\"] = np.append(\n    np.round(ua * 100, 2), [np.nan]\n)  # Append NaN for alignment\n\n# Add titles to show which values are Predicted and which are Actual\nconf_matrix_df.index.name = \"Predicted\"\nconf_matrix_df.columns.name = \"Actual\"\n\n# Print confusion matrix\nconf_matrix_df"
  },
  {
    "objectID": "CodingCrossover/scripts/supervised_classification.html#comparison-to-other-classifiers",
    "href": "CodingCrossover/scripts/supervised_classification.html#comparison-to-other-classifiers",
    "title": "Supervised Image Classification in Python",
    "section": "Comparison to other classifiers",
    "text": "Comparison to other classifiers\nNow that we have the training and validation data created we can run other classifiers to see how they differ. We should use the same data and split as we did previously for a true comparison of these models.\n\nRandom Forest\nFirst let’s train a Random Forest Classification. Similar to the GaussianNB() function we can use the RandomForestClassifier() function from scikit-learn (User Guide).\nIn this example we will have 100 ‘trees’ in our forest but feel free to adjust this parameter to see how the output changes.\n\n# Train Random Forest Classifier\nrf_classifier = RandomForestClassifier(\n    n_estimators=100, random_state=42\n)  # call model to use and set parameters\nrf_classifier.fit(x_train, y_train)  # fit/train model to training data\n\n# Classify entier raster\npredicted = rf_classifier.predict(flattened_raster)  # predict class to each pixel\nclassified_raster = predicted.reshape(\n    H, W\n)  # reshape prediction from flattened raster to original dimensions\n\n\n# Set appropriate colours for each class\ncolors = [\"#A6D96A\", \"#33A02C\", \"#DE3B13\", \"#D63CF1\", \"#00D2D2\", \"#F1A026\", \"#2B83BA\"]\ncmap = ListedColormap(colors)\n\n# Plot classified image\nplt.figure(figsize=(10, 10))  # initialize figure and set size\nplt.axis(\"off\")  # turn axis off for visualization\nplt.imshow(classified_raster, cmap=cmap)  # plot classified raster with defined colours\n\n\n# Prepare validation data\ntrue_classes, predicted_classes = [], []  # empty lists for true and predicted classes\nfor idx, row in val_gdf.iterrows():  # iterate through each polygon\n    # Generate a mask for the polygon\n    mask = geometry_mask(\n        [row.geometry], transform=transform, invert=True, out_shape=(H, W)\n    )\n\n    # Extract true clas labels\n    true_label = row[\"lc_class_encoded\"]  # Column with the true encoded class labels\n    true_values = np.full(np.sum(mask), true_label)\n\n    # Extract predicted class labels from classified raster\n    predicted_values = classified_raster[mask]\n\n    # Append to lists\n    true_classes.extend(true_values)\n    predicted_classes.extend(predicted_values)\n\n# Convert lists to numpy arrays\ntrue_classes = np.array(true_classes)\npredicted_classes = np.array(predicted_classes)\n\n\n# Calculate accuracy metrics and print values\noa = accuracy_score(true_classes, predicted_classes)  # overall accuracy\nf1 = f1_score(true_classes, predicted_classes, average=\"weighted\")  # f1 score\nprint(f\"Overall Accuracy: {oa}\\nF1 Score: {f1}\")\n\n\n# Create confusion matrix\nconf_matrix = confusion_matrix(true_classes, predicted_classes)\n\n# Calculate producers and users accuracies from confusion matrix\npa = np.diag(conf_matrix) / np.sum(conf_matrix, axis=1)  # producers accuracy\nua = np.diag(conf_matrix) / np.sum(conf_matrix, axis=0)  # users accuracy\n\n# Create dataframe for confusion matrix\nclasses = np.unique(gdf[\"lc_class\"])  # get unique class label\nconf_matrix_df = pd.DataFrame(\n    conf_matrix.T, index=classes, columns=classes\n)  # create dataframe\n\n# Add producers and users accuracies to dataframe\nconf_matrix_df.loc[\"Producer's Accuracy\"] = np.round(pa * 100, 3)\nconf_matrix_df[\"User's Accuracy\"] = np.append(\n    np.round(ua * 100, 2), [np.nan]\n)  # Append NaN for alignment\n\n# Add titles to show which values are Predicted and which are Actual\nconf_matrix_df.index.name = \"Predicted\"\nconf_matrix_df.columns.name = \"Actual\"\n\n# Print confusion matrix\nconf_matrix_df\n\n\nRandom Forest - Feature Importance\nAn additional analysis we can do with Random Forest is see the feature importance of the different inputs for the classification. This allows us to further understand why our outputs might be influenced by our inputs.\n\nfeature_importance = rf_classifier.feature_importances_\nbands = [\"Blue\", \"Green\", \"Red\", \"NIR\", \"SWIR1\", \"SWIR2\"]\nfor band, importance in zip(bands, feature_importance):\n    print(f\"{band}: {importance}\")\n\nplt.figure(figsize=(10, 6))\nplt.barh(bands, feature_importance, color=\"orange\")\nplt.xlabel(\"Feature Importance\")\nplt.ylabel(\"Band\")\nplt.title(\"Feature Importance in Random Forest\")\nplt.show()\n\n\n\n\nSupport Vector Machine\nNow lets train a Support Vector Machine (SVM) using the SVC() function (User Guide)\n\n# Train Support Vector Machine (SVM) Classifier\nsvm_classifier = SVC(\n    kernel=\"linear\", C=1.0, random_state=42\n)  # call model to use and set parameters\nsvm_classifier.fit(x_train, y_train)  # fit/train model to training data\n\n# Classify entier raster\npredicted = svm_classifier.predict(flattened_raster)  # predict class to each pixel\nclassified_raster = predicted.reshape(\n    H, W\n)  # reshape prediction from flattened raster to original dimensions\n\n\n# Set appropriate colours for each class\ncolors = [\"#A6D96A\", \"#33A02C\", \"#DE3B13\", \"#D63CF1\", \"#00D2D2\", \"#F1A026\", \"#2B83BA\"]\ncmap = ListedColormap(colors)\n\n# Plot classified image\nplt.figure(figsize=(10, 10))  # initialize figure and set size\nplt.axis(\"off\")  # turn axis off for visualization\nplt.imshow(classified_raster, cmap=cmap)  # plot classified raster with defined colours\n\n\n# Prepare validation data\ntrue_classes, predicted_classes = [], []  # empty lists for true and predicted classes\nfor idx, row in val_gdf.iterrows():  # iterate through each polygon\n    # Generate a mask for the polygon\n    mask = geometry_mask(\n        [row.geometry], transform=transform, invert=True, out_shape=(H, W)\n    )\n\n    # Extract true clas labels\n    true_label = row[\"lc_class_encoded\"]  # Column with the true encoded class labels\n    true_values = np.full(np.sum(mask), true_label)\n\n    # Extract predicted class labels from classified raster\n    predicted_values = classified_raster[mask]\n\n    # Append to lists\n    true_classes.extend(true_values)\n    predicted_classes.extend(predicted_values)\n\n# Convert lists to numpy arrays\ntrue_classes = np.array(true_classes)\npredicted_classes = np.array(predicted_classes)\n\n\n# Calculate accuracy metrics and print values\noa = accuracy_score(true_classes, predicted_classes)  # overall accuracy\nf1 = f1_score(true_classes, predicted_classes, average=\"weighted\")  # f1 score\nprint(f\"Overall Accuracy: {oa}\\nF1 Score: {f1}\")\n\n\n# Create confusion matrix\nconf_matrix = confusion_matrix(true_classes, predicted_classes)\n\n# Calculate producers and users accuracies from confusion matrix\npa = np.diag(conf_matrix) / np.sum(conf_matrix, axis=1)  # producers accuracy\nua = np.diag(conf_matrix) / np.sum(conf_matrix, axis=0)  # users accuracy\n\n# Create dataframe for confusion matrix\nclasses = np.unique(gdf[\"lc_class\"])  # get unique class label\nconf_matrix_df = pd.DataFrame(\n    conf_matrix.T, index=classes, columns=classes\n)  # create dataframe\n\n# Add producers and users accuracies to dataframe\nconf_matrix_df.loc[\"Producer's Accuracy\"] = np.round(pa * 100, 3)\nconf_matrix_df[\"User's Accuracy\"] = np.append(\n    np.round(ua * 100, 2), [np.nan]\n)  # Append NaN for alignment\n\n# Add titles to show which values are Predicted and which are Actual\nconf_matrix_df.index.name = \"Predicted\"\nconf_matrix_df.columns.name = \"Actual\"\n\n# Print confusion matrix\nconf_matrix_df\n\n\n\nNeural Networks (Multi-Layer Perceptron)\nFinally, let’s train a simple neural network to compare the other classification outputs. This neural network is a Multi-Layer Perceptron with three hidden layers containing 100, 50, and 25 neurons. Feel free to adjust the number of layers as well as the number of neurons to see how this changes the output. For more information on the MLPClassifier() function see the User Guide.\n\n# Train Multi-Layer Perceptron Classifier\nmlp_classifier = MLPClassifier(\n    hidden_layer_sizes=(\n        100,\n        50,\n        25,\n    ),  # Three hidden layer with 100, 50, and 25 neurons\n    activation=\"relu\",  # Activation function for hidden layers\n    solver=\"adam\",  # Optimization algorithm\n    max_iter=300,  # Maximum number of iterations\n    random_state=42,\n)\nmlp_classifier.fit(x_train, y_train)  # fit/train model to training data\n\n# Classify entier raster\npredicted = mlp_classifier.predict(flattened_raster)  # predict class to each pixel\nclassified_raster = predicted.reshape(\n    H, W\n)  # reshape prediction from flattened raster to original dimensions\n\n\n# Set appropriate colours for each class\ncolors = [\"#A6D96A\", \"#33A02C\", \"#DE3B13\", \"#D63CF1\", \"#00D2D2\", \"#F1A026\", \"#2B83BA\"]\ncmap = ListedColormap(colors)\n\n# Plot classified image\nplt.figure(figsize=(10, 10))  # initialize figure and set size\nplt.axis(\"off\")  # turn axis off for visualization\nplt.imshow(classified_raster, cmap=cmap)  # plot classified raster with defined colours\n\n\n# Prepare validation data\ntrue_classes, predicted_classes = [], []  # empty lists for true and predicted classes\nfor idx, row in val_gdf.iterrows():  # iterate through each polygon\n    # Generate a mask for the polygon\n    mask = geometry_mask(\n        [row.geometry], transform=transform, invert=True, out_shape=(H, W)\n    )\n\n    # Extract true clas labels\n    true_label = row[\"lc_class_encoded\"]  # Column with the true encoded class labels\n    true_values = np.full(np.sum(mask), true_label)\n\n    # Extract predicted class labels from classified raster\n    predicted_values = classified_raster[mask]\n\n    # Append to lists\n    true_classes.extend(true_values)\n    predicted_classes.extend(predicted_values)\n\n# Convert lists to numpy arrays\ntrue_classes = np.array(true_classes)\npredicted_classes = np.array(predicted_classes)\n\n\n# Calculate accuracy metrics and print values\noa = accuracy_score(true_classes, predicted_classes)  # overall accuracy\nf1 = f1_score(true_classes, predicted_classes, average=\"weighted\")  # f1 score\nprint(f\"Overall Accuracy: {oa}\\nF1 Score: {f1}\")\n\n\n# Create confusion matrix\nconf_matrix = confusion_matrix(true_classes, predicted_classes)\n\n# Calculate producers and users accuracies from confusion matrix\npa = np.diag(conf_matrix) / np.sum(conf_matrix, axis=1)  # producers accuracy\nua = np.diag(conf_matrix) / np.sum(conf_matrix, axis=0)  # users accuracy\n\n# Create dataframe for confusion matrix\nclasses = np.unique(gdf[\"lc_class\"])  # get unique class label\nconf_matrix_df = pd.DataFrame(\n    conf_matrix.T, index=classes, columns=classes\n)  # create dataframe\n\n# Add producers and users accuracies to dataframe\nconf_matrix_df.loc[\"Producer's Accuracy\"] = np.round(pa * 100, 3)\nconf_matrix_df[\"User's Accuracy\"] = np.append(\n    np.round(ua * 100, 2), [np.nan]\n)  # Append NaN for alignment\n\n# Add titles to show which values are Predicted and which are Actual\nconf_matrix_df.index.name = \"Predicted\"\nconf_matrix_df.columns.name = \"Actual\"\n\n# Print confusion matrix\nconf_matrix_df"
  },
  {
    "objectID": "CodingCrossover/scripts/supervised_classification.html#questions",
    "href": "CodingCrossover/scripts/supervised_classification.html#questions",
    "title": "Supervised Image Classification in Python",
    "section": "Questions",
    "text": "Questions\nQuestion 1 - Why is it important to use the same training and validation data when comparing different model outputs?\nQuestion 2 - Which classifier performed best with your data? Why do you think this is?\nScreenshot - Save a screenshot of the map from your best model."
  },
  {
    "objectID": "CodingCrossover/codingcrossover.html#key-differences-in-python-vs.-r",
    "href": "CodingCrossover/codingcrossover.html#key-differences-in-python-vs.-r",
    "title": "Coding Crossover",
    "section": "Key Differences in Python vs. R",
    "text": "Key Differences in Python vs. R\nThere are some key differences between Python and R that may take some time to get used to when switching between them.\nIndexing:\n\nPython uses zero-based indexing (lists, arrays start from index 0).\nR uses one-based indexing (vectors, matrices start from index 1).\n\nData structures:\n\nPython’s primary sequence structures are lists (mutable) and tuples (immutable), and numpy arrays for numerical operations.\nR’s core structures are vectores, matrices, data frames and lists, where vectors are a fundamental unit of operation.\n\nVectorization and broadcasting\n\nR is inherently vectorized; many operations naturally apply element-wise without extra effort.\nPython requires libraries like NumPy for similar vectorized operations and broadcasting.\n\nFunction arguments\n\nIn Python, keyword arguments (kwargs) are passed by name after positional arguments, and default values are common.\nIn R, arguments can be matched by position or name, and partial argument matching (unique abbreviations) is allowed.\n\nAssignment\n\nPython uses = for assignment.\nR commonly uses &lt;- for assignment, though = can also be used.\n\nLooping and iteration\n\nPython encourages explicit loops (e.g., for, while), and list comprehension is widely used.\nsquares = [x**2 for x in range(10)] # example list comprehension\nR encourages vectorized operations and apply functions over explicit for loops for efficiency and clarity.\n\nString handling\n\nPython has robust built-in string operations, slicing and methods.\nR relies on more external packages (like stringr) for advanced text manipulation, though basic operations are available natively.",
    "crumbs": [
      "Coding Crossover"
    ]
  },
  {
    "objectID": "CodingCrossover/codingcrossover.html#common-geomatics-libraries",
    "href": "CodingCrossover/codingcrossover.html#common-geomatics-libraries",
    "title": "Coding Crossover",
    "section": "Common Geomatics Libraries",
    "text": "Common Geomatics Libraries\nR Libraries\n\n\n\n\n\n\n\nLibrary\nDescription\n\n\n\n\nterra\nFor spatial data manipulation, raster data processing, and geospatial analysis.\n\n\nsf\nFor handling vector spatial data, including shapefiles, GeoJSON, and other formats.\n\n\ndplyr\nFor data manipulation.\n\n\ncaret\nFor training and plotting classification and regression models.\n\n\nggplot2\nFor creating graphics with provided data.\n\n\n\nPython Libraries\n\n\n\n\n\n\n\nLibrary\nDescription\n\n\n\n\nrasterio\nFor raster file I/O and processing.\n\n\nnumpy\nFor numerical data manipulation, often used with raster data.\n\n\npandas\nFor tabular data manipulation.\n\n\ngeopandas\nFor handling vector spatial data, extending pandas to work with geospatial formats.\n\n\nshapely\nFor manipulation and analysis of geometric objects.\n\n\nscikit-learn\nFor training classification, regression, and clustering models, and data preprocessing.\n\n\nmatplotlib\nFor creating graphics with provided data.",
    "crumbs": [
      "Coding Crossover"
    ]
  },
  {
    "objectID": "CodingCrossover/codingcrossover.html#importing-libraries",
    "href": "CodingCrossover/codingcrossover.html#importing-libraries",
    "title": "Coding Crossover",
    "section": "Importing Libraries",
    "text": "Importing Libraries\nR\n# Import libraries \nlibrary(terra)     # For raster operations \nlibrary(sf)        # For vector operations \nlibrary(dplyr)     # For data manipulation \nlibrary(ggplot2)   # For creating visualizations\nPython\n# Import libraries\nimport rasterio                                                     # For raster operations \nimport geopandas as gpd                                             # For vector data \nimport numpy as np                                                  # For numerical data \nimport pandas as pd                                                 # For tabular data manipulation \nimport matplotlib.pyplot as plt                                     # For creating visulizations \nfrom rasterio.features import rasterize                             # For rasterizing vector data \nfrom rasterio.mask import mask                                      # For masking raster data \nfrom rasterio.warp import calculate_default_transform, reproject    # For raster reprojection \nfrom shapely.geometry import box                                    # For creating bounding box",
    "crumbs": [
      "Coding Crossover"
    ]
  },
  {
    "objectID": "CodingCrossover/codingcrossover.html#cheat-sheet-common-geomatics-functions",
    "href": "CodingCrossover/codingcrossover.html#cheat-sheet-common-geomatics-functions",
    "title": "Coding Crossover",
    "section": "Cheat Sheet: Common Geomatics Functions",
    "text": "Cheat Sheet: Common Geomatics Functions\n\n\n\n\n\n\n\n\nFunctionality\nR (terra, sf)\nPython (rasterio, geopandas, etc.)\n\n\n\n\nRead a shapefile\nshp &lt;- sf::st_read(\"path/to/file.shp\")\nshp = gpd.read_file(\"path/to/file.shp\")\n\n\nWrite a shapefile\nsf::st_write(shp, \"path/to/output.shp\")\nshp.to_file(\"path/to/output.shp\")\n\n\nRead a raster\nraster &lt;- terra::rast(\"path/to/file.tif\")\nwith rasterio.open(\"path/to/file.tif\") as src:\n    raster = src.read()\n\n\nWrite a raster\nterra::writeRaster(raster, \"path/to/output.tif\", overwrite=TRUE)\nwith rasterio.open(\"path/to/output.tif\", \"w\", **kwargs) as dst:\n    dst.write(raster)\n\n\nCalculate NDVI\nndvi &lt;- (nir - red) / (nir + red)\n(assuming nir and red are terra raster objects)\nndvi = (nir - red) / (nir + red)\n(assuming nir and red are numpy arrays)\n\n\nClip a raster by extent\nclipped &lt;- terra::crop(raster, extent)\nclipped, _ = mask(src, shapes, crop=True)\n\n\nClip a vector by extent\nclipped &lt;- sf::st_crop(vector, xmin = x1, ymin = y1, xmax = x2, ymax = y2)\nbbox = box(x1, y1, x2, y2)\nclipped = vector.clip(bbox)\n\n\nReproject a shapefile\nreproj &lt;- sf::st_transform(shp, crs = 4326)\nshp = shp.to_crs(epsg=4326)\n\n\nReproject a raster\nreproj &lt;- terra::project(raster, \"EPSG:4326\")\nreprojected_raster = reproject(src, transform)\n\n\nCalculate area of polygons\nshp$area &lt;- sf::st_area(shp)\nshp[\"area\"] = shp.geometry.area\n\n\nSort polygons by attribute\nsorted &lt;- shp[order(shp$attribute), ]\nsorted = shp.sort_values(\"attribute\")\n\n\nExtract raster values\nvalues &lt;- terra::extract(raster, sf::st_coordinates(points))\nvalues = [raster[row, col] for row, col in points] (requires array coordinates for numpy)\n\n\nBuffer around features\nbuffered &lt;- sf::st_buffer(shp, dist = 500)\nbuffered = shp.buffer(500)\n\n\nRasterize a vector layer\nrasterized &lt;- terra::rasterize(shp, raster)\nrasterized = rasterize([(geom, 1) for geom in shp.geometry], out_shape=shape, transform=transform)",
    "crumbs": [
      "Coding Crossover"
    ]
  },
  {
    "objectID": "CodingCrossover/codingcrossover.html#classification-example",
    "href": "CodingCrossover/codingcrossover.html#classification-example",
    "title": "Coding Crossover",
    "section": "Classification Example",
    "text": "Classification Example\nIn GEM520 there was a lab assignment that focused on how to perform a supervised image classification using QGIS and R to represent the 7 land cover classes for the Gulf Islands. Within this lab training and validation polygons were delineated using QGIS and then used to train a Maximum Likelihood Classifier in R. In this example we will be using those same polygons and Landsat image but we will be doing the classification step using Python instead.\nNote: it is recommended that you use the same polygons that you delineated for the lab to see if there are any differences in the outputs, but if you do not have them still you can access them here.\n\nStep 1\nBefore being able to run this example you will need to set up a Conda environment with the correct packages installed. To do this you will first need to download the create_environment.py script from here.\nNext you need to open up Anaconda Prompt and type in python [path/to/create_environment.py]. This will create a new Conda environment for you with the correct packages and then open a new Jupyter Lab IDE.\nNote: you do not need to run this example in the Jupter Lab IDE but the live tutorial will be done using it.\n\n\nStep 2\nOnce the environment is created and Jupyter Lab is opened you can download the supervised_classification.ipynb from here. This notebook will walk you through similar steps to the ones found in the original lab assignment. Open this notebook and run each of the code chunks.\nNote: you will need to change the file paths within this notebook to the ones in your system and run each code chunk to show your results.",
    "crumbs": [
      "Coding Crossover"
    ]
  },
  {
    "objectID": "Cartography/art_of_maps.html#data",
    "href": "Cartography/art_of_maps.html#data",
    "title": "The Art of Map Making",
    "section": "Data",
    "text": "Data\nWhile the data you chose to map and display isn’t something that will or won’t be mandated and controlled, it’s always important think about what data you want to map, and why. For example, a study area map is very common and almost expected for many journals or papers in GIS and remote sensing due to the fact that giving the reader an idea of where the study is can be essential for understanding the context of the work.\nAs for everything besides a study map, a good rule of thumb on whether to make a map is if there is a spatial element in your data, then its probably a good idea! However, always keep your maps as simple as you can, an overcrowded map is one of the easiest ways to have your reader simply ignore your map or not get the message\n\n\n\nAn example of a map with maybe too much data\n\n\nWhen it comes to how much, or which data, to add on your map always keep things as simple as possible and it’s never a bad idea to just make a few maps.",
    "crumbs": [
      "Cartography",
      "The Art of Map Making"
    ]
  },
  {
    "objectID": "Cartography/art_of_maps.html#colour",
    "href": "Cartography/art_of_maps.html#colour",
    "title": "The Art of Map Making",
    "section": "Colour",
    "text": "Colour\nThe colours you chose for you map, like many things in cartography, is up to you but you can definitely get it wrong. For example, when it comes to publication, sometimes you may need to have colours that are colourblind friendly or even can print in black and white. However, those may be laid out for you in plain to read rules, but today I think its best to think of some rules or guidelines that aren’t as obvious. Such as for land classification:\n\nWater is blue\nGreen for vegetation\nBrown for mountains or rough terrain\n\nSounds simple enough, but easy to stick to ideas like this take just a second to step back and think of which colour you’re choosing and why. What data your representing can also help decide your colour, for example a map showing hotter temperatures in blue might not be trusted as much as one that shows the same in red….\nAs for choosing a colour ramp that is diverging or sequential depends on your range of data, but resources such as ColourBrewer are an amazing place to go back for inspiration and any help:\nColourBrewer",
    "crumbs": [
      "Cartography",
      "The Art of Map Making"
    ]
  },
  {
    "objectID": "Cartography/art_of_maps.html#examples-of-artistic-maps",
    "href": "Cartography/art_of_maps.html#examples-of-artistic-maps",
    "title": "The Art of Map Making",
    "section": "",
    "text": "There are many beautiful maps out in the world that are more art than science but that doesn’t disqualify them from being called a map. Here are a few examples of what might not traditionally be called maps in a scientific sense, but can be used as either a cool visualization or maybe even some inspiration for your work:\n\n\n\n\n\n\n\nWhistler village, Canada, by James Niehues\n\n\nMaps like the one above are a great example that not every map needs to have every single detail shown, like we’ve talked about “all maps are lies”, so sometimes you need to lie a little to better convey a message and visualize your work.\n\n\n\n3D map of Manhattan by Luis Dilger\n\n\nWhile these shift a little bit from what we talked about in the cartography section of today, hopefully these can serve as a reminder that map making is an art its core, don’t be afraid to put your own style and touch on your maps!",
    "crumbs": [
      "Cartography",
      "The Art of Map Making"
    ]
  },
  {
    "objectID": "Cartography/arcgis_pro_demo.html#projections",
    "href": "Cartography/arcgis_pro_demo.html#projections",
    "title": "ArcGIS Pro Demo",
    "section": "",
    "text": "Displaying your map frame in an appropriate coordinate system is important for visualization. For example, the two photos below show very different projections, and while both are technically not wrong, the one using the Mercator is clearly much better suited for our data\n\n\n\nRobinson\n\n\n\n\n\nMercator\n\n\nYou can change the projection of your map view by right-clicking on the ‘Map’ in your drawing order, and going to properties (below-left). Under the Coordinate Systems tab, you may then select a projection suitable for viewing your map (bottom-right).\nTip: Using the search bar can be the fastest way to find a projection you’re looking for, but the layers drop-down will have all the projections of any layers on your map already ready for easy selection. You can also save your most common projections under Favorites if you find yourself using the same projections over and over.\n\n\n\nSelecting a projection",
    "crumbs": [
      "Cartography",
      "ArcGIS Pro Demo"
    ]
  },
  {
    "objectID": "Cartography/arcgis_pro_demo.html#inset-maps",
    "href": "Cartography/arcgis_pro_demo.html#inset-maps",
    "title": "ArcGIS Pro Demo",
    "section": "",
    "text": "In order to help our map-viewers out a little more, we can insert another map frame on our layout, showing where in Canada we are. To do so we will want to put this data in a separate ‘Map’ tab. To create one, simply click on the ‘New Map’ button on the top left of your Arc screen. Now that we have this new ’Map”, and have added our data, we can go back to our layout, and add our helpful extent map.\n\n\n\nSome of the helpful buttons for creating an inset map highlighted\n\n\nAfter selecting your layout, navigate to the ‘Insert’ tab on the top of your screen, and select ‘Map Frame’. This will give you an overview of all the maps you have created in your Arc Project, and will allow you to select one to add to your layout. We can now select the one created above, and add it to our layout by dragging a box in the spot where we wish to place it. You can then add elements such as leader lines, and separate scale bars if you feel it is appropriate.",
    "crumbs": [
      "Cartography",
      "ArcGIS Pro Demo"
    ]
  },
  {
    "objectID": "Cartography/arcgis_pro_demo.html#legends",
    "href": "Cartography/arcgis_pro_demo.html#legends",
    "title": "ArcGIS Pro Demo",
    "section": "",
    "text": "Legends are a fundamental component of any map. It is where we give the map-viewer the tools they need to interpret the data that we are presenting to them. Inserting a Legend is relatively straightforward – you can simply navigate to the ‘Insert’ tab for your layout, and click on ‘Legend’. However, once you have inserted a Legend, you may find it doesn’t look exactly appealing, and we may have to take some steps to clean things up a bit. First and foremost, there may be layers on display which we do not wish to include in our legend – to avoid clutter.\n\n\n\nCustomizing you legend can probably be one of the more frustrating things to do in ArcGIS. The quickest way to make changes is to use the properties of the legend, accessed by right clicking it and selecting the Properties option at the bottom. This will open a window on the right with lots and lots of options on things you can change. See this link for some helpful tips Legends Tips\nChanging the name of your layers can be one of the easiest things to forget when creating a map in ArcGIS, but probably the biggest difference maker when creating a map. To do so, simply right click the layer to access its Properties. In the top option, General, there is a name bar where you can type whatever name you feel is best, the great thing about this is you can use spaces and capitalized letters which often isn’t the default with GIS!",
    "crumbs": [
      "Cartography",
      "ArcGIS Pro Demo"
    ]
  },
  {
    "objectID": "Cartography/arcgis_pro_demo.html#gridlines-and-graticules",
    "href": "Cartography/arcgis_pro_demo.html#gridlines-and-graticules",
    "title": "ArcGIS Pro Demo",
    "section": "",
    "text": "It can sometimes be easy to forget that the people looking at your maps are not as familiar with the data, area, and topic as you are. People from all over the world map end up looking at your map, so it is always important to make sure everyone – regardless of their background knowledge – is able to interpret and read your map. For the example shown in this document so far, people from Eastern Canada may recognize the Hudson’s Bay area in the map, yet many of us may be initially confused as to where this study area is located. There are a few ways by which we can make this easier for our map-viewer to interpret. On of these ways is by inserting grid-lines which show lat/lon lines across our map. To do so, navigate to the ‘Grid’ option in the Insert bar for your layout, and select one of the grid options.\n\n\n\nGridlines\n\n\nThis will add grid-lines to our drawing order, as well as map view. Similarly to the legend, we can right click on the grid lines in our drawing order, select properties, and make adjustments as we wish to alter the appearance of thegrid lines (not shown here).",
    "crumbs": [
      "Cartography",
      "ArcGIS Pro Demo"
    ]
  },
  {
    "objectID": "Cartography/arcgis_pro_demo.html#north-arrow-and-scale-bar",
    "href": "Cartography/arcgis_pro_demo.html#north-arrow-and-scale-bar",
    "title": "ArcGIS Pro Demo",
    "section": "",
    "text": "Now that we have got ourselves a nice looking map, we have to add the finishing touches. No map is complete without the essential North Arrow and Scale Bars. Thankfuly, both are easy to add! Simply select the ‘North Arrow’ Dropdown at the top of your screen, and choose whichever strikes your fancy.\nFor scale bars, simply select the ‘Scale Bar’ dropdown, select one of the available options, and drag a box where you would like to place it. Now it is important to note that when you add a scale bar or north arrow, it will do so based on the map frame you have selected in your layout. Since we are making use of an inset in this example, we will then need to make sure to add a second scale bar to show the scale of our inset. Simply select the inset map frame in the layout, and add a second scale bar – placing it in an appropriate spot.",
    "crumbs": [
      "Cartography",
      "ArcGIS Pro Demo"
    ]
  },
  {
    "objectID": "Shiny/shiny.html#point-cloud-visualization",
    "href": "Shiny/shiny.html#point-cloud-visualization",
    "title": "Point Cloud Visualization and Shiny Apps",
    "section": "Point Cloud Visualization",
    "text": "Point Cloud Visualization\n\nRotating Point Clouds with lidR\n\n\n\nExample of a GIF you can produce! (Please don’t use this exact one for submission)\n\n\nDownload the Rotating LAS GIF Script and sample data (.zip)\nContains:\nrotating_gif.R - an R script containing the rotating GIF from las/laz function\nrotating_las_gif.Rproj - an R project file, use this to ensure the example paths work\nlas_ex\\ - folder containing five example 400m2 plots of drone lidar data to play with\nInstructions:\n\nDownload and extract contents to a folder\nOpen the rotating_las_gif R Project using RStudio\nOpen rotating_gif.R in RStudio, run the script to generate your first gif\nPlay around with different options until you’re happy with your gif\n\n\n\nPotree\n\n\n\n\n\n\nCheck out Potree\nCheck out Potree Desktop (not recommended for UBC laptops, requires node.js install)\nCheck out these Potree examples (find a cool one for your assignment)\n\nRiver example",
    "crumbs": [
      "Shiny"
    ]
  },
  {
    "objectID": "Shiny/shiny.html#shiny-apps",
    "href": "Shiny/shiny.html#shiny-apps",
    "title": "Point Cloud Visualization and Shiny Apps",
    "section": "Shiny Apps",
    "text": "Shiny Apps\n\nThe TreeDetectoR Shiny App\n\n\n\nTree detection in a Shiny app, try it yourself below!\n\n\nDownload the ITD example ShinyApp (.zip)\nContains:\nitd_shiny.R - an R script containing the tree detection Shiny App components\nitd_shiny.Rproj - an R project file, use this to ensure the example paths work\ndata/chm_ext - four example 0.25 m Canopy Height Models (CHM)\nInstructions:\n\nDownload and extract contents to a folder\nOpen the itd_shiny R Project using RStudio\nOpen itd_shiny.R in RStudio and run entire script to initate the shiny app\nLoad an example CHM (or your own) and play around\n\n\n\nMore resources\n\nGetting started with shinyapps.io (web hosting)\nRead the Shiny textbook, there is no better resource.\n\n\n\n\nMastering Shiny - Free textbook by Hadley Wickham",
    "crumbs": [
      "Shiny"
    ]
  },
  {
    "objectID": "Shiny/shiny.html#deliverables",
    "href": "Shiny/shiny.html#deliverables",
    "title": "Point Cloud Visualization and Shiny Apps",
    "section": "Deliverables",
    "text": "Deliverables\n\nTake three PNG screenshots of tree detection results from the ITD shiny app\n\nTry out different window sizes, visualization options etc\n\nTake a screenshot of your favourite Potree example point cloud, write two sentences about why you found it interesting or “cool”.\n\n\n\nCreate your own rotating GIF from a point cloud\n\nMake sure this is less than 50mb in size\nFeel free to just use the example laz files provided\n\n\nDownload the FCOR 599 Submission Template (.docx)\nUpload to Canvas\n\nWord document with four screenshots and your two sentences\nYour own rotating GIF!",
    "crumbs": [
      "Shiny"
    ]
  },
  {
    "objectID": "ggplot/MEGEM_ggplot/ggplot.html",
    "href": "ggplot/MEGEM_ggplot/ggplot.html",
    "title": "Report ready figures using ggplot2",
    "section": "",
    "text": "In this workshop module you will learn how to set up different types of plots (scatterplot, barplot, boxplot, multi-panel plots) and customize them using the aesthetics, legend and theme parameters. We will also discuss what makes a show-stopping figure that is ready to publish.\nKey principles for scientific figures:",
    "crumbs": [
      "Report-Ready Figures in ggplot"
    ]
  },
  {
    "objectID": "ggplot/MEGEM_ggplot/ggplot.html#scatterplot",
    "href": "ggplot/MEGEM_ggplot/ggplot.html#scatterplot",
    "title": "Report ready figures using ggplot2",
    "section": "Scatterplot",
    "text": "Scatterplot\nWe can use the built in iris dataset to build a simple scatterplot between Sepal.Length and Sepal.Width. We use the color parameter to create groups by Species.\n\nlibrary(ggplot2)\nhead(iris)\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n4          4.6         3.1          1.5         0.2  setosa\n5          5.0         3.6          1.4         0.2  setosa\n6          5.4         3.9          1.7         0.4  setosa\n\n\n\n### FUGLY \nggplot(aes(x = Sepal.Length, y = Sepal.Width, color = Species), data = iris) + # The color parameter defines groups in the data and uses a different color for each group\n  geom_point() + # aesthetics are \"inherited\" from the first ggplot() line \n  geom_smooth(method = \"lm\") # fit a linear model through each group of \"Species\"\n\n\n\n\n\n\n\n\nUsing a few extra parameters we can make the plot look a lot nicer. The essentials:\n\nxlab & ylab: Define x and y-labels instead of default variable names\nalpha: Controls the transparency of points, lines or polygons. It varies between 0 and 1 - with values closer to 0 being more transparent. This is important when you have overlapping elements on a plot.\ntheme_classic or theme_bw: Removes the default grey background from the plot and goes a long way in tidying up the figure. theme_classic removes gridlines but theme_bw does not.\ntheme: We can control many different aspects of how the plot looks. In particular we should make the axis and legend text bigger using element_text() and specifying a font size. We can also change the font face and type.\n\n\nggplot(aes(x = Sepal.Length, y = Sepal.Width, color = Species), data = iris) +\n  geom_point(alpha = 0.5, size = 2)+ ## adjust point size and transparency \n  xlab(\"Sepal Width (cm)\") + ## set x and y labels \n  ylab(\"Sepal Length (cm)\") +\n  geom_smooth(method = \"lm\") +\n  theme_classic() + ## a nice theme that removes the grey background and graticules\n  theme(axis.text = element_text(size = 14), ## font size of legend/axis \n        axis.title = element_text(size = 16),\n        legend.text = element_text(size = 14),\n        legend.title = element_text(size = 16),\n        legend.position = \"bottom\")\n\n\n\n\n\n\n\n\nThis plot is getting closer - but there are sill issues with the legend. Notice how the legend includes the grey fill and how points inherit the transparency from the alpha = 0.5 argument. The base ggplot colors are also a little tacky.\nWe can use scale_color_manual and scale_fill_manual to set the colors of the points and standard error ribbons. The online R Color picker allows you to easily copy and paste codes for all R colors! To clean up the legend we can also remove the line and fill information and override the point transparency.\n\nggplot(aes(x = Sepal.Length, y = Sepal.Width, color = Species, fill = Species), data = iris) +\n  geom_point(alpha = 0.5, size = 2) +\n  scale_color_manual(name = \"\", values = c(\"slateblue\", \"skyblue1\", \"steelblue4\")) + # manually set the point colors and remove \"Species\" from the legend \n  scale_fill_manual(name = \"\", values = c(\"slateblue\", \"skyblue1\", \"steelblue4\")) + # the standard error around the lines is controlled by the \"fill\" \n  scale_x_continuous(breaks = seq(1, 8, by = 0.5))+ # set the x-axis breakpoints\n  xlab(\"Sepal Width (cm)\") +\n  ylab(\"Sepal Length (cm)\") +\n  geom_smooth(alpha = 0.2, linewidth = 0.75, method = \"lm\", show.legend = FALSE)+ # adjust the transparency and size of the lines and remove the fill from the legend\n  theme_classic() +\n  guides(colour = guide_legend(override.aes = list(alpha = 1))) + # override the point transparency in the legend\n  theme(axis.text = element_text(size = 14),\n        axis.title = element_text(size = 16),\n        legend.text = element_text(size = 14, face = \"italic\"), # add italics for species names \n        legend.title = element_text(size = 16),\n        legend.position = \"bottom\")\n\n\n\n\n\n\n\n\nThis plot is looking pretty good! But if we are plotting multiple groups of data we might want to consider using a multi-panel plot for each group. This is easy to set up using facet_wrap(~Species). facet_wrap() is very flexible and some of the key arguments include:\n\nscales: Do you want all panels to have the same x and y axis range? The default is fixed but scales = free finds the min/max values for each group in the plot.\nnrow and ncol: Set the number of rows and columns.\nlabeller: Controls the text label of each panel. You can change the size and font of the label in theme() using theme(strip.text = element_text()) .\n\n\n# Multi-panel plot \nggplot(aes(x = Sepal.Length, y = Sepal.Width, color = Species, fill = Species), data = iris) +\n  facet_wrap(~Species, scales = \"free\") + # plot by Species and set different x-axes for each plot (alternative is scales = \"fixed\")\n  geom_point(alpha = 0.5, size = 3) +\n  scale_color_manual(name = \"\", values = c(\"slateblue\", \"skyblue1\", \"steelblue4\")) +\n  scale_fill_manual(name = \"\", values = c(\"slateblue\", \"skyblue1\", \"steelblue4\")) +\n  scale_x_continuous(breaks = seq(1, 8, by = 0.5))+\n  xlab(\"Sepal Width (cm)\") +\n  ylab(\"Sepal Length (cm)\") +\n  geom_smooth(alpha = 0.2, method = \"lm\", linewidth = 0.75) +\n  theme_classic() +\n  theme(axis.text = element_text(size = 11),\n        axis.title = element_text(size = 16),\n        strip.text = element_text(size = 14, face = \"italic\"),\n        legend.position = \"none\") # remove the legend\n\n\n\n\nFigure 1: Linear relationships between sepal length and width (cm) by iris species. The shaded area shows the standard error around the fitted trend.",
    "crumbs": [
      "Report-Ready Figures in ggplot"
    ]
  },
  {
    "objectID": "ggplot/MEGEM_ggplot/ggplot.html#boxplots",
    "href": "ggplot/MEGEM_ggplot/ggplot.html#boxplots",
    "title": "Report ready figures using ggplot2",
    "section": "Boxplots",
    "text": "Boxplots\nBoxplots can be used to show the distribution of numeric data between different groups. We will use the diamonds dataset within the ggplot2 package to show how diamond price differs among cut and clarity categories.\n\nhead(diamonds)\n\n# A tibble: 6 × 10\n  carat cut       color clarity depth table price     x     y     z\n  &lt;dbl&gt; &lt;ord&gt;     &lt;ord&gt; &lt;ord&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1  0.23 Ideal     E     SI2      61.5    55   326  3.95  3.98  2.43\n2  0.21 Premium   E     SI1      59.8    61   326  3.89  3.84  2.31\n3  0.23 Good      E     VS1      56.9    65   327  4.05  4.07  2.31\n4  0.29 Premium   I     VS2      62.4    58   334  4.2   4.23  2.63\n5  0.31 Good      J     SI2      63.3    58   335  4.34  4.35  2.75\n6  0.24 Very Good J     VVS2     62.8    57   336  3.94  3.96  2.48\n\n\n\nggplot(aes(x = cut, y = price), data = diamonds) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\nUsing the fill argument we can color the boxplots by categories of cut. scale_fill_brewer() can be used to select predefined color palettes by name.\n\nggplot(aes(x = cut, y = price, fill = cut), data = diamonds) +\n  geom_boxplot(alpha = 0.8, outlier.alpha = 0.05, outlier.size = 2)+ # adjust the size and transparency of the outliers - we could also remove them completely using alpha = 0 \n  scale_fill_brewer(palette = \"Blues\")+ # use \"brewer\" for set color palettes \n  xlab(\"Cut\")+\n  ylab(\"Price (USD)\")+\n  theme_classic()+\n  theme(axis.text = element_text(size = 12),\n        axis.title = element_text(size = 16),\n        legend.position = \"none\")\n\n\n\n\n\n\n\n\nIf we want to create grouped barplots we just need to use the fill argument to define a second grouping variable - in this case clarity.\n\nggplot(aes(x = cut, y = price, fill = clarity), data = diamonds) + # use the fill argument to group by a second category\n  geom_boxplot(alpha = 0.6, outlier.alpha = 0.05) +\n  scale_fill_brewer(palette = \"Spectral\") +\n  xlab(\"Cut\") +\n  ylab(\"Price (USD)\") +\n  theme_classic() +\n  theme(axis.text = element_text(size = 11),\n        axis.title = element_text(size = 16),\n        legend.position = \"right\")",
    "crumbs": [
      "Report-Ready Figures in ggplot"
    ]
  },
  {
    "objectID": "ggplot/MEGEM_ggplot/ggplot.html#density-plots",
    "href": "ggplot/MEGEM_ggplot/ggplot.html#density-plots",
    "title": "Report ready figures using ggplot2",
    "section": "Density plots",
    "text": "Density plots\nAn alternative to boxplots, density plots also show the distribution of numeric variables by estimating a probability density function. In a density plot the area under the curve sums to 1 with “peaks”represnting x-values that are more likely to occur. You can think of it like we are “smoothing” out the bars of a typical frequency histogram to create a continuous line. These plots are especially good for displaying data that is not normally distributed. Note that violin plots are ugly and should never be used.\nThe figure below shows a frequency histogram with the probability density function plotted on top.\n\nlibrary(dplyr)\ndiamonds %&gt;% filter(clarity == \"I1\") %&gt;% # filter one level of clarity for plotting and pass the filtered dataset into ggplot\n  ggplot(aes(x = price/1000, y = ..density..))+ # scale price to 1000's of USD\n  geom_histogram(binwidth = 1, color = \"black\", alpha = 0.3)+ # alpha controls the transparency of the fill \n  geom_density(color = \"blue\",linewidth = 0.8, alpha = 0.8)+\n  xlab(\"Price (1000 USD)\")+\n  ylab(\"Density\")+\n  theme_classic()+\n  theme(axis.text = element_text(size = 11),\n        axis.title = element_text(size = 16))\n\n\n\n\n\n\n\n\nDensity plots can be used to compare the distribution of multiple groups. The fill parameter specifies the color of the area under the curve. Setting alpha to a relatively low value ensures that the plots do not block each other.\nWe can change the title and the names of the groups in the legend we when we set the color scheme using scale_fill_manual() or scale_color_manual().\n\nname: Defines the title of the legend\nvalues: Defines the colors\nlabels: We can pass a vector of strings (one for each factor level) to specify the group names.\n\n\ndiamonds %&gt;% filter(clarity == \"I1\" | clarity == \"VVS2\") %&gt;% # filter two levels of clarity\n  ggplot(aes(x = price/1000, fill = clarity, color = clarity))+ # scale the price in terms of 1000's of dollars\n  geom_density(alpha = 0.4, linewidth = 0.1)+ #adjust transparency and color of the density plots\n  scale_fill_manual(name = \"Clarity\", values = c(\"#FFB90F\", \"#00BFFF\"))+ # define color and fill for each level of \"clarity\"\n  scale_color_manual(name = \"Clarity\", values = c(\"#FFB90F\", \"#00BFFF\"))+\n  geom_vline(xintercept = 3.20, linetype = \"dashed\", color = \"#FFB90F\")+ # add vertical lines to show peaks in the data\n  geom_vline(xintercept = 0.83, linetype = \"dashed\", color = \"#00BFFF\")+\n  xlab(\"Price (1000 USD)\")+\n  ylab(\"Density\")+\n  theme_bw()+\n  theme(axis.text = element_text(size = 11),\n        axis.title = element_text(size = 16),\n        legend.position = \"bottom\")\n\n\n\n\n\n\n\n\nWe can also use the ggridges package to stack multiple density plots vertically and compare the distribution of many groups at once.\n\nlibrary(ggridges)\n\nggplot(aes(x = price, y = clarity, fill = clarity), data = diamonds)+\n  geom_density_ridges2(quantile_lines = TRUE, quantiles = 2, alpha = 0.5, linewidth = 0.2)+\n  xlim(c(0, 10000))+\n  xlab(\"Price (USD)\")+\n  ylab(\"Clarity\")+\n  theme_bw()+\n  theme(legend.position = \"none\")+\n  theme(axis.text = element_text(size = 11),\n        axis.title = element_text(size = 16))",
    "crumbs": [
      "Report-Ready Figures in ggplot"
    ]
  },
  {
    "objectID": "ggplot/MEGEM_ggplot/ggplot.html#barplots",
    "href": "ggplot/MEGEM_ggplot/ggplot.html#barplots",
    "title": "Report ready figures using ggplot2",
    "section": "Barplots",
    "text": "Barplots\nWe can use barplots to compare the frequency or counts of groups within data. When we use geom_bar() we provide an x value representing the variable we want to count. We can count the frequency of different types of cars using the mpg dataset. The height of the bar represents the number of rows within each class.\n\nlibrary(ggplot2)\nhead(mpg)\n\n# A tibble: 6 × 11\n  manufacturer model displ  year   cyl trans      drv     cty   hwy fl    class \n  &lt;chr&gt;        &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt;      &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; \n1 audi         a4      1.8  1999     4 auto(l5)   f        18    29 p     compa…\n2 audi         a4      1.8  1999     4 manual(m5) f        21    29 p     compa…\n3 audi         a4      2    2008     4 manual(m6) f        20    31 p     compa…\n4 audi         a4      2    2008     4 auto(av)   f        21    30 p     compa…\n5 audi         a4      2.8  1999     6 auto(l5)   f        16    26 p     compa…\n6 audi         a4      2.8  1999     6 manual(m5) f        18    26 p     compa…\n\n\n\nggplot(aes(x = class, fill = class), data = mpg)+\n  geom_bar(alpha = 0.8, color = \"black\")+\n  scale_fill_brewer(palette = 'Reds')+\n  xlab(\"Class\")+\n  ylab(\"Count\")+\n  theme_bw()+\n  theme(legend.position = \"none\")+\n  theme(axis.text = element_text(size = 11),\n        axis.title = element_text(size = 16))\n\n\n\n\n\n\n\n\nA stacked barplot can show the frequency of groups within groups using the fill parameter and defining a second grouping variable.\nWe can also use the labels() argument in scale_fill_brewer() to change the group labels in the legend.\n\nggplot(aes(x = class, fill = drv), data = mpg)+\n  geom_bar(alpha = 0.8, color = \"black\")+\n  scale_fill_brewer(palette = 'Spectral', name = \"Drive Type\", labels = c(\"4 wheel\", \"Front\", \"Rear\"))+ # set the color palette and change the legend name and labels for each group \n  xlab(\"Class\")+\n  ylab(\"Count\")+\n  theme_bw()+\n  theme(legend.position = \"bottom\")+\n  theme(axis.text = element_text(size = 12),\n        axis.title = element_text(size = 16),\n        legend.text = element_text(size = 12))\n\n\n\n\n\n\n\n\nSometimes instead of counting rows within a dataset we already have a summary statistic or value calculated and we want to the height of the bar to represent this value, rather than a count. We can define the height of the bar using y in the aes() parameters and changing the statistic type to “identity” (which means the values are not aggregated into counts before plotting). This can be achieved using geom_col() in or geom_bar(stat = \"identity\") .\nThis example shows a Variable Importance plot from a Random Forests model displayed as a barplot. We have reordered the levels of Variable by Importance so that the variables with the greatest importance are plotted first. coord_flip() rotates the plot 90 degrees.\n\n# make some sample variable importance data \ndt = data.frame(Variable = c(\"Temperature\", \"Precipitation\", \"Slope\", \"Aspect\", \"Elevation\"), Importance = c(0.8, 0.2, 0.6, 0.3, 0.4))\n\nggplot(aes(x = reorder(Variable, Importance), y = Importance, fill = Variable), data = dt)+\n  geom_bar(stat = \"identity\", color = \"black\", alpha = 0.8, width = 0.8)+\n  coord_flip()+\n  scale_fill_brewer(palette = \"Blues\")+\n  ylab(\"Scaled Importance\")+\n  xlab(\"Random Forests Variable\")+\n  theme_bw()+\n  theme(axis.text = element_text(size = 12),\n        axis.title = element_text(size = 16),\n        legend.position = \"none\")",
    "crumbs": [
      "Report-Ready Figures in ggplot"
    ]
  },
  {
    "objectID": "ggplot/MEGEM_ggplot/ggplot.html#exporting-figures-from-r",
    "href": "ggplot/MEGEM_ggplot/ggplot.html#exporting-figures-from-r",
    "title": "Report ready figures using ggplot2",
    "section": "Exporting figures from R",
    "text": "Exporting figures from R\nNow that you have made some beautiful ggplot figures it is time to export them as high quality images! Do not take a screenshot of the R plotting window and submit it! There are two methods shown below the key parameters are:\n\nres or dpi: Resolution of the image - should be 300 dpi (dots per pixel)\nheight and width: Dimensions of the figure in units you define (“inches” in the example)\nYou should look at your figure after exporting it and experiment with different dimensions to make sure that everything is visible and scaled correctly. If parts of the figure are cut off you can increase the dimensions or make text size smaller.\n\n\n# define plot\nyour_plot = ggplot(aes(x = Sepal.Length, y = Sepal.Width, color = Species), data = iris)+\n  geom_point()\n\n## Export a high resolution .png of the plot \n## You will want to experiment with the height/width to get the best dimensions\npng(\"filepath_here.png\", height = 4, width = 8, units = \"in\", res = 300)\nyour_plot\ndev.off()\n\n## Using ggsave()\nggsave(filename = \"filepath_here.png\", your_plot,  height = 4, width = 8, units = \"in\", dpi = 300)\n\nHere are two examples of the same plot exported with different height/width dimensions:\n\n\n\nHeight = 4in, Width = 8in\n\n\n\n\n\nHeight = 4in, Width = 4in",
    "crumbs": [
      "Report-Ready Figures in ggplot"
    ]
  },
  {
    "objectID": "ggplot/MEGEM_ggplot/ggplot.html#exercises",
    "href": "ggplot/MEGEM_ggplot/ggplot.html#exercises",
    "title": "Report ready figures using ggplot2",
    "section": "Exercises",
    "text": "Exercises\nTry to recreate the following plots! Links to data descriptions included.\nUsing the midwest dataset from the ggplot2 package:\n\n\n\n\n\n\n\n\n\nTips: The color palette is “Dark2”\nUsing the msleep dataset in ggplot2:\n\n\n\n\n\n\n\n\n\nTips:\n\nThe color palette is “Spectral”.\nYou will need to manipulate the dataset before passing it to ggplot.",
    "crumbs": [
      "Report-Ready Figures in ggplot"
    ]
  },
  {
    "objectID": "GitHub_workshop/GitHub_workshop/Intro_to_GitHub.html",
    "href": "GitHub_workshop/GitHub_workshop/Intro_to_GitHub.html",
    "title": "Using GitHub for the Version Control of your Dreams",
    "section": "",
    "text": "Welcome to the GitHub Introduction Workshop! In this document, we will start at the basics of using GitHub for version control and collaboration and by the end hopefully you will feel equipped with the necessary skills to integrate these practices into your project workflows!\nBefore we start, make sure that you:\n🍄 have a GitHub account\n🦩have GitHub Desktop i\n🍋 have a positive attitude towards version control and reproducibility :D",
    "crumbs": [
      "Github Intro"
    ]
  },
  {
    "objectID": "GitHub_workshop/GitHub_workshop/Intro_to_GitHub.html#introduction",
    "href": "GitHub_workshop/GitHub_workshop/Intro_to_GitHub.html#introduction",
    "title": "Using GitHub for the Version Control of your Dreams",
    "section": "",
    "text": "Welcome to the GitHub Introduction Workshop! In this document, we will start at the basics of using GitHub for version control and collaboration and by the end hopefully you will feel equipped with the necessary skills to integrate these practices into your project workflows!\nBefore we start, make sure that you:\n🍄 have a GitHub account\n🦩have GitHub Desktop i\n🍋 have a positive attitude towards version control and reproducibility :D",
    "crumbs": [
      "Github Intro"
    ]
  },
  {
    "objectID": "GitHub_workshop/GitHub_workshop/Intro_to_GitHub.html#what-is-github",
    "href": "GitHub_workshop/GitHub_workshop/Intro_to_GitHub.html#what-is-github",
    "title": "Using GitHub for the Version Control of your Dreams",
    "section": "What is GitHub?",
    "text": "What is GitHub?\nGitHub is a code hosting platform for version control and collaboration. From anywhere, you and others can work on projects together. Git is a version control software that allows you to store your code and files in one location and keeps track of your changes as you work on a project.\n\n\n\n\n\n\n\n\nFeatures\nGit\nGitHub\n\n\n\n\nWhat\nVersion Control System\nCloud-based Git hosting platform\n\n\nWhy\nTracks changes to files locally\nStores repositories online and facilitates collaboration\n\n\nWhere\nLocally on your computer\nRemote (Online)\n\n\nHow\nCommand Line, VS code, GUI\nGitHub.com, GitHub Desktop\n\n\n\nGitHub Desktop is a free graphical user interface (GUI) that simplifies interfacing with Git and GitHub without the need to use the command line. GitHub desktop provides not all but most of the functionality you are likely to need and is a great option when you are just starting to familiarize yourself with using GitHub. It is great if you prefer a visual interface, don’t require advanced Git functionality, and want a simple way to manage individual or small team projects! Everything done in this tutorial can be done using GitHub Desktop\n\nWhy do we want to use GitHub?\n\nstandard version control\nreproducibility\naccountability\naccuracy\nshowcasing your work*\n\n*when you go to apply to a job, the first thing your future employer is going to do is Google you and if the job includes coding, they are likely going to look for some of your previous work so using GitHub is a GREAT way to show off your skills - in terms of programming and organization! You can show that you:\na) know how to code\nb) have proper code management\nc) are willing to share to the open science community",
    "crumbs": [
      "Github Intro"
    ]
  },
  {
    "objectID": "GitHub_workshop/GitHub_workshop/Intro_to_GitHub.html#github-basics-individual-workflow",
    "href": "GitHub_workshop/GitHub_workshop/Intro_to_GitHub.html#github-basics-individual-workflow",
    "title": "Using GitHub for the Version Control of your Dreams",
    "section": "GitHub Basics: Individual Workflow",
    "text": "GitHub Basics: Individual Workflow\nThis section provides a possible workflow that you could replicate when working on your own individual project. A lot of the ways that you will interact with GitHub and version control is based on personal preference (aka what works for you and your project) but there are some best practices that are often recommended. This workflow assumes that you are not collaborating with others on the same repo and is using only the most basic Git functions to store your changes and track your project history.\nLet’s start with some terms that you need to know!\n\nDefinitions\nGit - Core technology that GitHub is built on, designed as an open-source program for tracking changes. The “behind the scenes” program interfaced through GitHub\nRepository - (Repo) Analogous to a project folder; Contains all project files and stores the version history of each file. You can decide for this to be public or private depending on your purpose!\nClone - A copy of of a repo that lives on your local computer instead of on a website’s server\nCommit - A “revision” that is an individual change to a file or set of files. When you make a commit to save your work, Git creates a unique ID (a.k.a the “SHA” or “hash”) so there is a record of the specific changes committed along with who made them and when.\nPush - When you successfully push changes to a remote repository, you update the remote branch with changes from your local branch.\nPull - Bring changes from remote branch to your local branch.\nOrigin/remote origin - the upstream repo i.e. the one hosted on GitHub.com\nuse this key to remember where each action should occur\n\n\n\nIcon Key for Git Actions\n\n\n\n\nExample workflow\n\n\n\nExample workflow for using GitHub to manage your own project without collaborators\n\n\nUsing this example you can replicate the following steps:\n\nClone repo\n\nthis makes a copy of the repo on your local computer\nthere is still a “link” between your local clone and the remote origin\nwhen you make a clone, this will appear as a folder on your local machine where you will work from\n\n\n\n\nMake Changes\n\nthis could be adding new files, editing existing files, anything that is part of your usual work that you want to keep track of!\nbusiness as usual as you work on your project!\n\nSave Changes\n\nSave files normally\n\nCommit Changes\n\nCommit early and commit often!\nlump “bite size” amount of change into commits\na commit is tracked using Git - a unique hash is generated\nadd a USEFUL and CONCISE comment and description to each of your commits so they are easy to refer back to later\n\nPush Changes\n\nPush (i.e. send and save) commits to remote origin\nCan push multiple commits\ncommits will be reflected on GitHub.com and visible to you and other users who have access to the repo\n\n*Pull Changes\n\npull changes to remote local\nupdates your local clone to reflect all changes pushed to remote origin\nless relevant if it’s just you working on your scripts!\n\n\n\n\nTips\n\nCommits should contain similar types of edits so if you need to go back to a certain stage, it is easy to isolate where you made certain changes\nmake thoughtful commit summaries and description - you will thank yourself later\n\nit makes your life exponentially more difficult when you have to go back to your code sometimes YEARS later and see that your commit comment says “lots of changes, fixed model” instead of something actually useful and descriptive of the chunk of changes you made\n\nDO NOT STORE YOUR DATA IN YOUR GITHUB REPO - it’s okay to store some test data especially if you are making your methods and code open source however GitHub has limited file space and there are better places for you to back up your data - Try to only store code and documents on GitHub  More on this later\nGeneral rule: Push your changes at least once a day but only if it makes sense i.e. you want to keep your changes :)",
    "crumbs": [
      "Github Intro"
    ]
  },
  {
    "objectID": "GitHub_workshop/GitHub_workshop/Intro_to_GitHub.html#github-basics-collaboration-workflow",
    "href": "GitHub_workshop/GitHub_workshop/Intro_to_GitHub.html#github-basics-collaboration-workflow",
    "title": "Using GitHub for the Version Control of your Dreams",
    "section": "GitHub Basics: Collaboration Workflow",
    "text": "GitHub Basics: Collaboration Workflow\nSo now that you are a pro with tracking changes for an individual project, now we will go over a workflow that you could adopt when collaborating on a project. This workflow is geared towards multiple people sharing code and working on different feature development or tasks simultaneously.\nFor example, imagine that you’re a consultant working on a team of remote sensing analysts who are working on a project for one of their clients. Your goal is develop a machine learning model that predicts harmful algal blooms in the Salish Sea using future climate scenarios and Landsat imagery. Your deadline is coming up for this project and you have a working model but you think there is an opportunity to make it better. You are working on fine tuning model parameters and your coworker is simultaneously working on developing an RShiny app for the client to be able to easily use and interact with your model outputs.\nUsing the Individual Workflow, you might run into some compatibility issues since every time one of you change the repo, the other person would have to pull their changes down and keep their clone up to date with the remote origin. If your repos get out of sync, you may not be able to push your commits if Git can’t figure out how the version history works out … thank goodness we have other Git functionality available to us to work around this issue!\nSome new definitions to help with your collaborative efforts!\n\nDefinitions\nBranch - A parallel version of a repo that is contained within the repo. A branch allows you to work freely without disrupting the “live” version of the code. Whenever you make a new repo, the initial repo branch, and where you should store the “live” version of the code, is called ‘main’. New branches can be created for developing and testing new features without having to initially incorporate them into the “main” branch. When you are happy with your changes and want to bring over your new features to the “main” branch, you submit a pull request and eventually merge your branch onto the main branch\n\n\n\nConceptually how branching works\n\n\nIn our example, my coworker and I would each make a new branch from main. On my branch, I can edit model inputs and try different weights without changing the working version of the model that is nicely stored away on the main branch. On theirs, they can develop the GUI and test the functionality using the working model, without seeing my model tuning, before merging the finalized Shiny app into the main branch.\nPull Request - Proposed changes to a repository submitted by a user and accepted or rejected by a repo’s collaborators.\nMerge - takes the changes from one branch (in the same repo or from a fork) and applies them to another\nFork - personal copy of another user’s repo that lives on your account. Allows users to make changes to repo without affecting the original. User’s can still open a pull request to merge changes to original repo. Great if you want to use someone’s code without making changes OR editing code for your own purpose if you don’t have write access to the original repo.\n\n\nExample workflow\n\n\n\n\n\n\n\n\n\n\nUsing this example you can replicate the following steps:\n\nClone repo\nMake a Branch\n\nmakes a parallel version of the repo\n\nPublish Branch\n\ntell GitHub that you have made a new branch\notherwise you won’t see this on your remote origin, only on your local machine\n\nMake Changes\nSave Changes\nCommit Changes\nPush Changes\n\ncommits are send to remote origin of NEW BRANCH not main\n\nSubmit Pull Request\n\nRequest to bring changes from your new branch over to the main branch\nChanges will be reviewed by repo maintainer\npotential to request changes, undergo review at this stage\n\nMerge Pull Request\n\nBring Changes over\n\nDelete Branch\n\nRemove branch on your GitHub Desktop and GitHub.com\nthis seems to keep things cleaner\n\nFetch origin\n\nreturn to main branch on GitHub Desktop and fetch origin\nchecks if there are changes (which there should be after you\n\nPull Changes\n\nbring merged changes into main branch on local\n\n*Pull Changes\n\nIf someone else merges a branch or makes changes you can still pull these changes to your development or main branch during your workflow\n\n\n\n\nTips:\n\nkeep things organized and stay up to date with remote origin",
    "crumbs": [
      "Github Intro"
    ]
  },
  {
    "objectID": "GitHub_workshop/GitHub_workshop/Intro_to_GitHub.html#tips-tricks-for-an-efficient-workflow",
    "href": "GitHub_workshop/GitHub_workshop/Intro_to_GitHub.html#tips-tricks-for-an-efficient-workflow",
    "title": "Using GitHub for the Version Control of your Dreams",
    "section": "Tips & Tricks for an efficient Workflow",
    "text": "Tips & Tricks for an efficient Workflow\n\nDo’s and Don’t\n\n\n\n\n\n\n\nDO\n\nuse GitHub for version control on individual and collaborative projects\ncommit often with meaningful descriptions\nkeep your local clone up to date with remote origin\nstore data outside of GitHub repo\nuse branches when working on joint repo collaboratively\nuse pull requests\nuse forks when using code without making edits or if you don’t have permission to edit repo\nuse GitHub to market your skills and abilities\npractice on a testing repo until you are familiar with function calls\n\n\n\nDON’T\n\ncommit large chunks of changes that don’t relate\ncommit directly to main if you are working with others\nmerge pull requests without reviewing changes first\npull changes before you push so your repo is synced with the main\nstore data in your GitHub repo\nbe afraid to mess up!\n\n\n\n\n\n\nOther Ways to use Git and GitHub\n\nRStudio\ncommand line\nVSCode\nJupyter Notebooks\n\n\n\nSetting up a GitHub Repo\nWhen you are starting a project for the first time you can go to your GitHub account &gt; Repositories and click “New”. You can then write a nice project description, chose if it will be public or private, add a README file (this will show up on the main page of your repo) and add a .gitignore template file. Click “Create repository”\na .gitignore file allows you to tell Git which files or folders in your Git folder to ignore so you don’t have to track unnecessary files. This often keeps things clean and greatly reduces the number of files in your repo.\n\n\nPermissions\nWhen setting up a GitHub repository you can decide if you want your repo to be Private or Public.\nPublic repo - Anyone can view them but only authorized users can make changes\nPrivate repo - only selected users can view and modify them\nYou can also decide the level of permission for different users for your repos.\n\n\n\n\n\n\n\n\n\nRole\nDescription\nRead Access?\nWrite Access?\n\n\n\n\nOwner\nfull control over repo\n\n\n\n\nAdministrator\ncan manage settings, collaborators, and branches\n\n\n\n\nWrite\ncan push code, create branches, and open pull requests\n\n\n\n\nRead\nCan only view the repo\n\n⛔\n\n\nMaintainer\nManages teams and workflows for organization\n\n\n\n\n\nTo manage this you can go to your repo &gt; settings &gt; collaborators and teams and then click “Add people” and add their GitHub username or email. You can then chose their permission level.\n\n\nFile Organization\nBest practice is often to use a file structure that is easy to follow, is easy for others to contribute to, and is scale-able! As you’re getting started on a project, take the time to set up a logical file structure that will continue to work for you the longer you work on your project! It is MUCH harder to do this after you have started a project and already have a ton of disorder in your file structure. This also makes your GitHub repo more attractive to other users - it makes you look like you know what you’re doing and it will make them want to bother looking through your code!\na good place to start may be….\n my-project/\n│\n├── docs/             \n│   ├── index.md     \n│   ├── installation.md  \n│   └── contributing.md  \n│\n├── data/            \n│   ├── src \n│   │   ├── landsat.tiff\n│   │   └── MODIS.tiff\n│   ├── input \n│   │   ├── training.csv\n│   │   └── testing.csv\n│   ├── model_outputs\n│   │   └── output.csv\n│\n├── scripts/         \n│   ├── clean_input_data_01.R\n│   ├── merge_landsat_MODIS_02.R\n│   ├── run_rf_model_03.R\n│   └── generate_boxplot_04.R  \n│\n├── figs/             \n│   └── boxplot.png.md  \n│\n├── .gitignore       \n├── README.md        \n├── LICENSE          \nA tip: think about your syntax style and stick with it! It is a nightmare to look at one folder and see a mixture of these….\nmy_file_names.py\nFileName.py\nfile-name.py\na useful reference: https://www.britishecologicalsociety.org/wp-content/uploads/2017/12/guide-to-reproducible-code.pdf\n\n\nREADME\nwhat is a README?\nThe first thing that people shuold see when they visit your GitHub page! It’s an information doc that helps explain your project, attract contributors, and improve usability. It makes your project look exponentially better if you have a nice, pretty, and organized README.\nIt should contain:\n\nproject description\ninstallation instructions (for packages)\nusage guide\nscreenshots/demos\nhow others can contribute\nlicense and co-authors/partnerships/sponsors\n\nA good example: sgsR package repo (tgoodbody)\n\n\nGitHub Issues\nGitHub Issues is a task tracking and project management tool built directly into GitHub repos. It can help you oranize work, track progress, and collaborate efficiently. It is useful for tracking bugs, assigning tasks, labeling issues, and linking issues to PRs\n\n\nGitHub CoPilot\nAs you work with GitHub, you may want to use CoPilot. It is an AI-powered code assistant developed by GitHub and OpenAI. It helps by providing real-time code suggestions, autocompletions, and functions based on comments or existing code. You can use it through VSCode and it is free for students!",
    "crumbs": [
      "Github Intro"
    ]
  },
  {
    "objectID": "GitHub_workshop/GitHub_workshop/Intro_to_GitHub.html#activity",
    "href": "GitHub_workshop/GitHub_workshop/Intro_to_GitHub.html#activity",
    "title": "Using GitHub for the Version Control of your Dreams",
    "section": "Activity",
    "text": "Activity\n\nSign into your GitHub Account\nNavigate to the FCOR-599 GitHub tutorial Repo\nClone the GitHub Repo to your local computer using method of choice (git, GitHub Desktop, etc.)\nCreate a new Branch called “LASTNAME_FIRSTNAME_branch”\nPublish your new Branch - say “yes I want to make this a fork” since you won’t have write access to the repo\nSet up a file organization structure for a new project\nAdd a README file called “README_LASTNAME_FIRSTNAME.md” and write a brief description that you could use for your 599 project - If you already have one.. Great! Make it better in some way and submit that (add a photo? Change the font? add in your contact info?)\nCommit changes\nPush Changes to remote origin\nTake a screenshot of your GitHub forked repo with your README and template folders and submit to canvas activity\n**You will receive a participation grade based on the existence of this branch with your README :)",
    "crumbs": [
      "Github Intro"
    ]
  }
]
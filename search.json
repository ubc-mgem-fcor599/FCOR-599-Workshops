[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "FCOR 599: Workshop Artifacts",
    "section": "",
    "text": "Home Page\nHey there,\nThis webpage contains workshop artifacts created by your FCOR 599 TA’s. Many of these artifacts were initially developed as workshops, and have been archived here for your reference. The topics range from cartography to advanced figure development and python scripting - most of which were requested by previous cohorts of your peers. If you have any questions, or have suggestions for additional modules that can be included here, please talk to your FCOR 599 teaching team.\n\n\n\nReuseCC BY 4.0",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "cartography.html",
    "href": "cartography.html",
    "title": "Cartography",
    "section": "",
    "text": "“All maps are lies, but some are useful” ~ Dr. Paul Pickell, circa 2020\nCartography is the art and science of creating, studying, and distributing maps and other visual representations of geographical areas. It involves a combination of scientific and artistic skills to communicate information about a place.\n\n\n\nEratosthenes’ World Map (220 BCE) showing the results of Alexander the Great’s conquests. Eratosthenes was the first geographer to include parallels and meridians in his maps, allowing for the calculation of distance.",
    "crumbs": [
      "Cartography"
    ]
  },
  {
    "objectID": "cartography.html#quarto",
    "href": "cartography.html#quarto",
    "title": "Cartography",
    "section": "",
    "text": "blah blah blah",
    "crumbs": [
      "Cartography"
    ]
  },
  {
    "objectID": "art_of_maps.html",
    "href": "art_of_maps.html",
    "title": "The Art of Map Making",
    "section": "",
    "text": "Lets add some text here about the history of maps. Some are very beautiful, some less so. Although we rightfully place emphasis on ensuring the scientific integrity of maps, the artistic component of map making is a key component of science communication, and should not be overlooked.",
    "crumbs": [
      "Cartography",
      "The Art of Map Making"
    ]
  },
  {
    "objectID": "cartography.html#what-is-cartography",
    "href": "cartography.html#what-is-cartography",
    "title": "Cartography",
    "section": "",
    "text": "Cartography is the art and science of creating, studying, and distributing maps and other visual representations of geographical areas. It involves a combination of scientific and artistic skills to communicate information about a place.",
    "crumbs": [
      "Cartography"
    ]
  },
  {
    "objectID": "arcgis_pro_demo.html",
    "href": "arcgis_pro_demo.html",
    "title": "ArcGIS Pro Demo",
    "section": "",
    "text": "As MGEM students, you all have access to ArcGIS Pro, a powerful GIS software that allows users to perform geospatial tasks and create beautiful maps. This demo focuses on the map-making capabilities of ArcGIS Pro, and provides an easy reference guide for the implementation of core cartography concepts and best-practices.",
    "crumbs": [
      "Cartography",
      "ArcGIS Pro Demo"
    ]
  },
  {
    "objectID": "interactive_maps.html",
    "href": "interactive_maps.html",
    "title": "Interactive Maps",
    "section": "",
    "text": "Although conventional maps are static and do not allow for user interaction, geospatial practitioners have developed exciting new ways in which we can present geographic information in interactive formats. Although not exhaustive by any means, this section will cover several key ways in which you can create digital maps that allow for user-interaction.",
    "crumbs": [
      "Interactive Maps"
    ]
  },
  {
    "objectID": "leaflet.html",
    "href": "leaflet.html",
    "title": "Leaflet",
    "section": "",
    "text": "The Basics:\nMany software and coding packages can be used to create interactive maps. In this particular demo, we will show you an easy way to produce interactive maps in leaflet - a popular R package. Leaflet is intuitive, fast, and has many arguments that allow us to easily adjust the way in which we present our maps. In the example below, we used NTEMs land cover from 2020 to product a simple interactive map for Vancouver Island. In the code below, you will notice that we add in a basemap using the ‘addProviderTiles’ argument. You can browse for available leaflet basemaps here: https://leaflet-extras.github.io/leaflet-providers/preview/\n\nl &lt;- leaflet(width = 600, height = 600)%&gt;%\n  \n  #lets use some base imagery from ESRI\n  addProviderTiles(\"Esri.WorldImagery\") %&gt;%\n  \n  #now lets add our NTEMS land cover from 2020\n  addRasterImage(ntems2020, \n                 #you can increase the allowable size of the rast here\n                 maxBytes = 10 * 1024 *1024) %&gt;%\n  #add a legend\n  addRasterLegend(ntems2020, opacity = 1)%&gt;%\n  #add scale bar\n  addScaleBar(position = c(\"bottomleft\"))\n\n\n\n\n\n\n\n \nComparing/Showing Multiple Layers:\nNow let’s step things up a notch, and add some additional content to our map. For the purposes of this demonstration, let’s say you have been tasked with showcasing changes in land cover on Vancouver Island from 2000 to 2020. To do so, we can use 2 key leaflet functionalities: 1) adding a toggle menu - allowing us to switch between layers, 2) adding a ‘slider’, which we can use to visualize two layers side-by-side.\n1) In order to add a toggle menu and provide NTEMs land cover of both 2000 and 2020 in our map, we do need to provide a name for our layers using the ‘group’ argument within the ‘addRasterImage’ function.\n\nl2 &lt;- leaflet(width = 600, height = 600)%&gt;%\n  \n  #lets use some base imagery from ESRI\n  addProviderTiles(\"Esri.WorldImagery\") %&gt;%\n  \n  #now lets add our NTEMS land cover from 2000\n  addRasterImage(ntems2000, \n                 #you can increase the allowable size of the rast here\n                 maxBytes = 10 * 1024 *1024,\n                 #provide a name for the layer\n                 group = \"LC-2000\") %&gt;%\n  \n  #now lets add our NTEMS land cover from 2020\n  addRasterImage(ntems2020, \n                 #you can increase the allowable size of the rast here\n                 maxBytes = 10 * 1024 *1024,\n                 #provide a name for the layer\n                 group = \"LC-2020\") %&gt;%\n  \n  #allow for layers to be toggles on/off by adding them to the layers control\n  addLayersControl(baseGroups = c(\"LC-2000\",\"LC-2020\")) %&gt;%\n  \n  #add a legend\n  addRasterLegend(ntems2000, opacity = 1)%&gt;%\n  \n  #add scale bar\n  addScaleBar(position = c(\"bottomleft\"))\n\n\n\n\n\n\n\n \n2) In order to visualize layers side-by-side and compare them using a window slider, we need to create a left and right pane, and assign our NTEMS land cover rasters to one of these panes.\n\nl3 &lt;- leaflet(width = 600, height = 600)%&gt;%\n  \n  #set up the two map panes\n  addMapPane(\"right\", zIndex = 1) %&gt;%\n  addMapPane(\"left\",  zIndex = 2) %&gt;%\n  \n  #add the ESRI basemap to both map panes\n  addProviderTiles(\"Esri.WorldImagery\", group = \"base\", layerId = \"baseid1\", options = pathOptions(pane = \"right\")) %&gt;%\n  addProviderTiles(\"Esri.WorldImagery\", group = \"base\", layerId = \"baseid2\", options = pathOptions(pane = \"left\")) %&gt;%\n  \n  #now lets add our NTEMS land cover from 2000\n  addRasterImage(ntems2000, \n                 #you can increase the allowable size of the rast here\n                 maxBytes = 10 * 1024 *1024,\n                 #provide a name for the layer\n                 group = \"LC-2000\",\n                 #assign to a pane\n                 options = leafletOptions(pane = \"left\")) %&gt;%\n  \n  #now lets add our NTEMS land cover from 2020\n  addRasterImage(ntems2020, \n                 #you can increase the allowable size of the rast here\n                 maxBytes = 10 * 1024 *1024,\n                 #provide a name for the layer\n                 group = \"LC-2020\",\n                 #assign to a pane\n                 options = leafletOptions(pane = \"right\")) %&gt;%\n  \n  #allow for layers to be toggles on/off by adding them to the layers control\n  addLayersControl(overlayGroups = c(\"LC-2000\", \"LC-2020\")) %&gt;%\n  \n  #add slider control\n  addSidebyside(layerId = \"sidecontrols\",\n                rightId = \"baseid1\",\n                leftId  = \"baseid2\",\n                options = list(padding = 0)) %&gt;%\n  \n  #add a legend\n  addRasterLegend(ntems2000, opacity = 1)%&gt;%\n  \n  #add scale bar\n  addScaleBar(position = c(\"bottomleft\"))",
    "crumbs": [
      "Interactive Maps",
      "Leaflet"
    ]
  },
  {
    "objectID": "Landing_Page/index.html",
    "href": "Landing_Page/index.html",
    "title": "FCOR 599: Workshop Artifacts",
    "section": "",
    "text": "Home Page\nHey there,\nThis webpage contains workshop artifacts created by your FCOR 599 TA’s. Many of these artifacts were initially developed as workshops, and have been archived here for your reference. The topics range from cartography to advanced figure development and python scripting - most of which were requested by previous cohorts of your peers. If you have any questions, or have suggestions for additional modules that can be included here, please talk to your FCOR 599 teaching team.\n\n\n\nReuseCC BY 4.0",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "Cartography/arcgis_pro_demo.html",
    "href": "Cartography/arcgis_pro_demo.html",
    "title": "ArcGIS Pro Demo",
    "section": "",
    "text": "This section is under construction\nAs MGEM students, you all have access to ArcGIS Pro, a powerful GIS software that allows users to perform geospatial tasks and create beautiful maps. This demo focuses on the map-making capabilities of ArcGIS Pro, and provides an easy reference guide for the implementation of core cartography concepts and best-practices.",
    "crumbs": [
      "Cartography",
      "ArcGIS Pro Demo"
    ]
  },
  {
    "objectID": "Cartography/art_of_maps.html",
    "href": "Cartography/art_of_maps.html",
    "title": "The Art of Map Making",
    "section": "",
    "text": "This section is under construction\nLets add some text here about the history of maps. Some are very beautiful, some less so. Although we rightfully place emphasis on ensuring the scientific integrity of maps, the artistic component of map making is a key component of science communication, and should not be overlooked.",
    "crumbs": [
      "Cartography",
      "The Art of Map Making"
    ]
  },
  {
    "objectID": "Cartography/cartography.html",
    "href": "Cartography/cartography.html",
    "title": "Cartography",
    "section": "",
    "text": "This section is under construction\n“All maps are lies, but some are useful” ~ Dr. Paul Pickell, circa 2020\nCartography is the art and science of creating, studying, and distributing maps and other visual representations of geographical areas. It involves a combination of scientific and artistic skills to communicate information about a place.\n\n\n\nEratosthenes’ World Map (220 BCE) showing the results of Alexander the Great’s conquests. Eratosthenes was the first geographer to include parallels and meridians in his maps, allowing for the calculation of distance.",
    "crumbs": [
      "Cartography"
    ]
  },
  {
    "objectID": "Interactive_Maps/interactive_maps.html",
    "href": "Interactive_Maps/interactive_maps.html",
    "title": "Interactive Maps",
    "section": "",
    "text": "Although conventional maps are static and do not allow for user interaction, geospatial practitioners have developed exciting new ways in which we can present geographic information in interactive formats. Although not exhaustive by any means, this section will cover several key ways in which you can create digital maps that allow for user-interaction.",
    "crumbs": [
      "Interactive Maps"
    ]
  },
  {
    "objectID": "Interactive_Maps/leaflet.html",
    "href": "Interactive_Maps/leaflet.html",
    "title": "Leaflet",
    "section": "",
    "text": "Many software and coding packages can be used to create interactive maps. In this particular demo, we will show you an easy way to produce interactive maps in leaflet - a popular R package. Leaflet is intuitive, fast, and has many arguments that allow us to easily adjust the way in which we present our maps. In the example below, we used NTEMs land cover from 2020 to product a simple interactive map for Vancouver Island. In the code below, you will notice that we add in a basemap using the ‘addProviderTiles’ argument. You can browse for available leaflet basemaps here: https://leaflet-extras.github.io/leaflet-providers/preview/\n\nl &lt;- leaflet(width = 600, height = 600)%&gt;%\n  \n  #lets use some base imagery from ESRI\n  addProviderTiles(\"Esri.WorldImagery\") %&gt;%\n  \n  #now lets add our NTEMS land cover from 2020\n  addRasterImage(ntems2020, \n                 #you can increase the allowable size of the rast here\n                 maxBytes = 10 * 1024 *1024) %&gt;%\n  #add a legend\n  addRasterLegend(ntems2020, opacity = 1)%&gt;%\n  #add scale bar\n  addScaleBar(position = c(\"bottomleft\"))",
    "crumbs": [
      "Interactive Maps",
      "Leaflet"
    ]
  },
  {
    "objectID": "E-Portfolio/eportfolio.html",
    "href": "E-Portfolio/eportfolio.html",
    "title": "E-Portfolio",
    "section": "",
    "text": "As part of FCOR 599, you are required to produce a professional E-Portfolio. This portfolio is intended to capture the breadth of skills you have developed throughout the program, including scientific writing & reporting, figure design, cartography, coding, etc. As has been introduced in the E-Portfolio workshop, a portfolio is essentially an organized digital collection of artifacts that highlight key pieces of work, accomplishments and skills.",
    "crumbs": [
      "E-portfolio"
    ]
  },
  {
    "objectID": "E-Portfolio/eportfolio.html#quarto",
    "href": "E-Portfolio/eportfolio.html#quarto",
    "title": "E-Portfolio",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org.",
    "crumbs": [
      "E-portfolio (Quarto)"
    ]
  },
  {
    "objectID": "E-Portfolio/eportfolio.html#running-code",
    "href": "E-Portfolio/eportfolio.html#running-code",
    "title": "E-Portfolio",
    "section": "Running Code",
    "text": "Running Code\nWhen you click the Render button a document will be generated that includes both content and the output of embedded code. You can embed code like this:\n\n1 + 1\n\n[1] 2\n\n\nYou can add options to executable code like this\n\n\n[1] 4\n\n\nThe echo: false option disables the printing of code (only output is displayed).",
    "crumbs": [
      "E-portfolio (Quarto)"
    ]
  },
  {
    "objectID": "E-Portfolio/eportfolio.html#building-a-portfolio-in-quarto",
    "href": "E-Portfolio/eportfolio.html#building-a-portfolio-in-quarto",
    "title": "E-Portfolio",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org. In this module, we will be using Quarto to construct an E-portfolio. The key advantage of building your portfolio in Quarto is that you can easily integrate any workflow, results, figures etc. that you have created in R-Studio. This workshop repository itself was built in Quarto, and is hosted on Github. In order to build your own portfolio, we have put together a simple github repository that provides the basic files you will need. In order to interact with the repository and build your own e-portfolio using quarto and github, you will need the following:\n\nA github account.\nGithub deskptop (make sure you are logged in).\nR-Studio.\nThe sample repository (available here).",
    "crumbs": [
      "E-portfolio (Quarto)"
    ]
  },
  {
    "objectID": "E-Portfolio/eportfolio.html#e-portfolio-basics",
    "href": "E-Portfolio/eportfolio.html#e-portfolio-basics",
    "title": "E-Portfolio",
    "section": "",
    "text": "As part of FCOR 599, you are required to produce a professional E-Portfolio. This portfolio is intended to capture the breadth of skills you have developed throughout the program, including scientific writing & reporting, figure design, cartography, coding, etc. As has been introduced in the E-Portfolio workshop, a portfolio is essentially an organized digital collection of artifacts that highlight key pieces of work, accomplishments and skills.",
    "crumbs": [
      "E-portfolio"
    ]
  },
  {
    "objectID": "E-Portfolio/eportfolio.html#building-an-e-portfolio-in-quarto",
    "href": "E-Portfolio/eportfolio.html#building-an-e-portfolio-in-quarto",
    "title": "E-Portfolio",
    "section": "Building an E-Portfolio in Quarto",
    "text": "Building an E-Portfolio in Quarto\nIn your E-Portfolio workshop, you were introduced to UBC blogs, where you can host a portfolio via wordpress. Since many of you are quite familiar with coding in R-studio at this stage in the pogram, the demo below will demonstrate how you can build a portfolio using Quarto in R-Studio. Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org.\nIn this module, we will be using Quarto to construct an E-portfolio. The key advantage of building your portfolio in Quarto is that you can easily integrate any workflow, results, figures etc. that you have created in R-Studio. This workshop repository itself was built in Quarto, and is hosted on Github. In order to build your own portfolio, we have put together a simple github repository that provides the basic files you will need. In order to interact with the repository and build your own e-portfolio using quarto and github, you will need the following:\n\nA github account.\nGithub deskptop (make sure you are logged in).\nR-Studio.\nThe sample repository (available here).\n\nQuarto Portfolio Instructions:\nBefore we begin, make sure you have Github desktop installed on your device, that you are logged in to your github account in the desktop app, and that you have R-Studio installed on your device.\n\nNavigate to the sample repository using the link above.\nNow ‘fork’ the repository - this will create a copy of all of the files on your github account. You can make changes to this ‘forked’ repository without affecting the original or getting things mixed up with your peers. Make sure you provide a descriptive name for the forked repo.\nOpen up your Github Desktop app and navigate to ‘File &gt; Clone Repository’. This will show you all of the repositories that are available to be cloned based on your github account. Find the forked repo and clone it to a local path. You will get a pop-up that asks you how you plan to use this fork - make sure you select the ‘for my own purposes’ option.\nIn the Github Desktop app, click on the ‘Show in Explorer’ button - this will navigate to the folder on your computer where all the repo files are stored. This folder is where you will make changes to your E-Portfolio files.\nOpen up an R-Studio session and click on ‘File &gt; Open File’. Navigate to your explorer folder with all of the repo files, and open up the ‘index.qmd’ file. Edit the file with your own profile picture (if you’d like), contact information, and introduction blurb. When you are finished editing the page, save the .qmd file and hit ‘render’. This will give you a preview of what the page will look like in your E-Portfolio. Repeat this step for the ‘resume.qmd’ file.\nIn your Github Desktop, you will now notice that there are local changes to the repository files based on your edits. You can push these edits to your github by clicking ‘commit to main’.\n\nIn order to customize your E-Portfolio, we encourage you to review the following resources:\n\nQuarto HTML Basics\nQuarto HTML Options\nQuarto Theming\n\nOnce you are satisfied with the content of your E-Portfolio, it is time to publish your website. Before you do so, make sure you have committed all local changes from your desktop. Once you are ready:\n\nOpen your github account in your web browser, and navigate to your E-Portfolio repository.\nIn the top bar, select ‘Settings’ and navigate to ‘Pages’ under the ‘Code and automation’ column.\nUnder ‘Build and deployment’ &gt; ‘Branch’, select the ‘Main’ branch, and click save.\nYour website is now being built. This will take a few minutes, so be patient and refresh the page after ~ 2-5 minutes. Once complete, a url for your website will now be available to you.",
    "crumbs": [
      "E-portfolio"
    ]
  },
  {
    "objectID": "Interactive_Maps/leaflet.html#the-basics",
    "href": "Interactive_Maps/leaflet.html#the-basics",
    "title": "Leaflet",
    "section": "",
    "text": "Many software and coding packages can be used to create interactive maps. In this particular demo, we will show you an easy way to produce interactive maps in leaflet - a popular R package. Leaflet is intuitive, fast, and has many arguments that allow us to easily adjust the way in which we present our maps. In the example below, we used NTEMs land cover from 2020 to product a simple interactive map for Vancouver Island. In the code below, you will notice that we add in a basemap using the ‘addProviderTiles’ argument. You can browse for available leaflet basemaps here: https://leaflet-extras.github.io/leaflet-providers/preview/\n\nl &lt;- leaflet(width = 600, height = 600)%&gt;%\n  \n  #lets use some base imagery from ESRI\n  addProviderTiles(\"Esri.WorldImagery\") %&gt;%\n  \n  #now lets add our NTEMS land cover from 2020\n  addRasterImage(ntems2020, \n                 #you can increase the allowable size of the rast here\n                 maxBytes = 10 * 1024 *1024) %&gt;%\n  #add a legend\n  addRasterLegend(ntems2020, opacity = 1)%&gt;%\n  #add scale bar\n  addScaleBar(position = c(\"bottomleft\"))",
    "crumbs": [
      "Interactive Maps",
      "Leaflet"
    ]
  },
  {
    "objectID": "Interactive_Maps/leaflet.html#comparingshowing-multiple-layers",
    "href": "Interactive_Maps/leaflet.html#comparingshowing-multiple-layers",
    "title": "Leaflet",
    "section": "Comparing/Showing Multiple Layers",
    "text": "Comparing/Showing Multiple Layers\nNow let’s step things up a notch, and add some additional content to our map. For the purposes of this demonstration, let’s say you have been tasked with showcasing changes in land cover on Vancouver Island from 2000 to 2020. To do so, we can use 2 key leaflet functionalities: 1) adding a toggle menu - allowing us to switch between layers, 2) adding a ‘slider’, which we can use to visualize two layers side-by-side.\n1) In order to add a toggle menu and provide NTEMs land cover of both 2000 and 2020 in our map, we do need to provide a name for our layers using the ‘group’ argument within the ‘addRasterImage’ function.\n\nl2 &lt;- leaflet(width = 600, height = 600)%&gt;%\n  \n  #lets use some base imagery from ESRI\n  addProviderTiles(\"Esri.WorldImagery\") %&gt;%\n  \n  #now lets add our NTEMS land cover from 2000\n  addRasterImage(ntems2000, \n                 #you can increase the allowable size of the rast here\n                 maxBytes = 10 * 1024 *1024,\n                 #provide a name for the layer\n                 group = \"LC-2000\") %&gt;%\n  \n  #now lets add our NTEMS land cover from 2020\n  addRasterImage(ntems2020, \n                 #you can increase the allowable size of the rast here\n                 maxBytes = 10 * 1024 *1024,\n                 #provide a name for the layer\n                 group = \"LC-2020\") %&gt;%\n  \n  #allow for layers to be toggles on/off by adding them to the layers control\n  addLayersControl(baseGroups = c(\"LC-2000\",\"LC-2020\")) %&gt;%\n  \n  #add a legend\n  addRasterLegend(ntems2000, opacity = 1)%&gt;%\n  \n  #add scale bar\n  addScaleBar(position = c(\"bottomleft\"))\n\n\n\n\n\n\n\n \n2) In order to visualize layers side-by-side and compare them using a window slider, we need to create a left and right pane, and assign our NTEMS land cover rasters to one of these panes.\n\nl3 &lt;- leaflet(width = 600, height = 600)%&gt;%\n  \n  #set up the two map panes\n  addMapPane(\"right\", zIndex = 1) %&gt;%\n  addMapPane(\"left\",  zIndex = 2) %&gt;%\n  \n  #add the ESRI basemap to both map panes\n  addProviderTiles(\"Esri.WorldImagery\", group = \"base\", layerId = \"baseid1\", options = pathOptions(pane = \"right\")) %&gt;%\n  addProviderTiles(\"Esri.WorldImagery\", group = \"base\", layerId = \"baseid2\", options = pathOptions(pane = \"left\")) %&gt;%\n  \n  #now lets add our NTEMS land cover from 2000\n  addRasterImage(ntems2000, \n                 #you can increase the allowable size of the rast here\n                 maxBytes = 10 * 1024 *1024,\n                 #provide a name for the layer\n                 group = \"LC-2000\",\n                 #assign to a pane\n                 options = leafletOptions(pane = \"left\")) %&gt;%\n  \n  #now lets add our NTEMS land cover from 2020\n  addRasterImage(ntems2020, \n                 #you can increase the allowable size of the rast here\n                 maxBytes = 10 * 1024 *1024,\n                 #provide a name for the layer\n                 group = \"LC-2020\",\n                 #assign to a pane\n                 options = leafletOptions(pane = \"right\")) %&gt;%\n  \n  #allow for layers to be toggles on/off by adding them to the layers control\n  addLayersControl(overlayGroups = c(\"LC-2000\", \"LC-2020\")) %&gt;%\n  \n  #add slider control\n  addSidebyside(layerId = \"sidecontrols\",\n                rightId = \"baseid1\",\n                leftId  = \"baseid2\",\n                options = list(padding = 0)) %&gt;%\n  \n  #add a legend\n  addRasterLegend(ntems2000, opacity = 1)%&gt;%\n  \n  #add scale bar\n  addScaleBar(position = c(\"bottomleft\"))",
    "crumbs": [
      "Interactive Maps",
      "Leaflet"
    ]
  },
  {
    "objectID": "CodingCrossover/codingcrossover.html",
    "href": "CodingCrossover/codingcrossover.html",
    "title": "Coding Crossover",
    "section": "",
    "text": "This repository provides a side-by-side comparison of how to perform common geomatics tasks in R and Python. It focuses on the libraries terra and sf in R, and rasterio, numpy, pandas, and geopandas in Python.",
    "crumbs": [
      "Coding Crossover"
    ]
  },
  {
    "objectID": "CodingCrossover/codingcrossover.html#quarto",
    "href": "CodingCrossover/codingcrossover.html#quarto",
    "title": "Coding Crossover",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org.",
    "crumbs": [
      "Coding Crossover"
    ]
  },
  {
    "objectID": "CodingCrossover/codingcrossover.html#running-code",
    "href": "CodingCrossover/codingcrossover.html#running-code",
    "title": "Coding Crossover",
    "section": "Running Code",
    "text": "Running Code\nWhen you click the Render button a document will be generated that includes both content and the output of embedded code. You can embed code like this:\n\n1 + 1\n\n[1] 2\n\n\nYou can add options to executable code like this\n\n\n[1] 4\n\n\nThe echo: false option disables the printing of code (only output is displayed).",
    "crumbs": [
      "Coding Crossover"
    ]
  },
  {
    "objectID": "CodingCrossover/scripts/supervised_classification.html",
    "href": "CodingCrossover/scripts/supervised_classification.html",
    "title": "Supervised Image Classification in Python",
    "section": "",
    "text": "---\ntitle: \"Supervised Image Classification in Python\"\nformat:\n    html:\n        code-fold: false\njupyter: python3\n---\nThis notebook will walk you through how to do the supervised image classification that was completed in GEM 520 but this time we will complete it Python. It is recommended that you create a new folder with your training polygons and the raster image, as you do not want to overwrite any information from your lab for this process. We will only be going over the scripting part of the lab in this activity to show the differences between R and Python, so it is encouraged that you have your R scripts from that lab open as well to see what the similarities and differences are.\nWe have already installed the correct packages used in this script when you ran the create_environment.py script. Now we can import the packages that we will need to run this activity.\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport rasterio\nfrom matplotlib.colors import ListedColormap\nfrom rasterio.features import geometry_mask\nfrom skimage import exposure\nfrom sklearn.metrics import accuracy_score, confusion_matrix, f1_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neural_network import MLPClassifier\nWe will start by reading in the Landsat image into Python and plotting it.\nNote: This image can also be found here if you are unable to find the image from this assignment.\n# Read in the Landsat image (CHANGE PATH TO YOUR SYSTEM)\nwith rasterio.open(\n    r\"D:\\MurrayBrent\\git\\CodingCrossover\\data\\LC09_L2SP_047026_20240716_20240717_02_T1_SR_BSTACK.tif\"\n) as src:\n    raster = src.read()  # read raster as an array\n    transform = src.transform  # get the transform information\n\n# Create a true colour composite\nrgb_image = np.stack(\n    (raster[2], raster[1], raster[0]),\n    axis=-1,\n)  # remember that python starts with 0\n\n# Plot the true colour composite\nplt.figure(figsize=(10, 10))  # initalize figure and set size\nplt.axis(\"off\")  # turn axis off for visualization\nplt.imshow(rgb_image)  # show the true colour composite\nYou will notice when we plot this image that it is very dark and that there are some pixels that have a nan value. Below is a function that will implement an image stretch and replace the nan values with 0. We will then plot the true colour composite again.\ndef percentile_stretch(band, lower_percentile=2, upper_percentile=98):\n    band[np.isnan(band)] = 0  # set nan values to 0\n    band_min, band_max = np.percentile(\n        band, (lower_percentile, upper_percentile)\n    )  # get min and max values based on defined percentiles\n    stretched_band = (band - band_min) / (\n        band_max - band_min\n    )  # perform stretch on band\n    return np.clip(stretched_band, 0, 1)  # return band within value range (0-1)\n# Create a true colour composite with stretch\nrgb_image = np.stack(\n    (\n        percentile_stretch(raster[2]),\n        percentile_stretch(raster[1]),\n        percentile_stretch(raster[0]),\n    ),\n    axis=-1,\n)  # remember that python starts with 0\n\n# Plot the true colour composite\nplt.figure(figsize=(10, 10))  # initalize figure and set size\nplt.axis(\"off\")  # turn axis off for visualization\nplt.imshow(rgb_image)  # show the true colour composite\nThen, we load the delineated polygons and plot them with the image.\nNote: A version of these polygons can also be found here if you are unable to find your polygons from the original assignment.\n# Read in classification polygons as geopandas dataframe (CHANGE PATH TO YOUR SYSTEM)\ngdf = gpd.read_file(\n    r\"D:\\MurrayBrent\\git\\CodingCrossover\\data\\classification_polygons.shp\"\n)\n# Plot the image with the polygons\nfig, ax = plt.subplots(figsize=(10, 10))  # initialize figure\nax.imshow(\n    rgb_image,\n    extent=(src.bounds.left, src.bounds.right, src.bounds.bottom, src.bounds.top),\n)  # plot the image\ngdf.boundary.plot(ax=ax, color=\"red\", linewidth=1)  # plot the boundary of the polygons\nplt.axis(\"off\")  # turn axis off for visualization\nplt.show()  # show full plot\nYou will notice when we plotted the polygon boundaries that we called it straight from the geopandas dataframe (gdf). Both geopandas and pandas have built in plotting using matplotlib, so we dont need to specifically call any matplotlib functions. The functions that are built into geopandas and pandas use the standard matplotlib convention, meaning you can edit and change the plots in the same way you would in matplotlib.\nHere is a summary of the number of polygons per class.\npoly_summary = gdf[\"lc_class\"].value_counts()  # get a count of the `lc_class` field\npoly_summary\nFor each land cover class, we will use 70% of the polygons to train the classification algorithm and the remaining 30% for validation. We are going to add a column to the dataframe called ‘set’ to identify which polygons will be used for training and which will be used for validation based on a stratified random sample of the ‘lc_class’ column. We will then split the dataframe into two one for training and one for validation.\n# Encode 'lc_class' so that it is a class number (factor in R)\ngdf[\"lc_class_encoded\"] = gdf[\"lc_class\"].astype(\"category\").cat.codes\n# Split the data into a 70:30 split\ntrain_idx, val_idx = train_test_split(\n    gdf.index, test_size=0.3, stratify=gdf[\"lc_class\"], random_state=1234\n)  # stratified random sample based on 'lc_class'\n\n# Create new column 'set'\ngdf[\"set\"] = \"Training\"  # set default value to training\ngdf.loc[val_idx, \"set\"] = \"Validation\"  # replace value with 'Validation'\n\n# Create a Training and a Validation dataframe\ntrain_gdf = gdf[gdf[\"set\"] == \"Training\"]  # training dataframe\nval_gdf = gdf[gdf[\"set\"] == \"Validation\"]  # validation dataframe\nWe now need to get the raster data ready to perform the maximum likelihood classification. We need to get the shape of the raster, replace any nan values, and flatten the raster for easier processing.\n# Preprocess raster for classificaiton\n(\n    B,  # band\n    H,  # height\n    W,  # width\n) = raster.shape  # get shape of raster\nraster = np.nan_to_num(raster, nan=0)  # replace nan to 0\nflattened_raster = raster.reshape(B, -1).T  # Flatten raster to shape (H*W, B)\nNow we can extract the values of the Landsat image based on the training polygons.\n# Prepare training data\nx_train, y_train = [], []  # empty lists for pixel values and labels\nfor idx, row in train_gdf.iterrows():  # iterate through each polygon\n    # Generate a mask for the polygon\n    mask = geometry_mask(\n        [row.geometry], transform=transform, invert=True, out_shape=(H, W)\n    )\n\n    # Collect pixel values and labels\n    pixels = flattened_raster[mask.flatten()]  # extract pixel values\n    labels = np.full(len(pixels), row[\"lc_class_encoded\"])  # get label\n\n    # Append to lists\n    x_train.append(pixels)\n    y_train.append(labels)\n\n# Concatenate training data\nx_train = np.vstack(x_train)\ny_train = np.concatenate(y_train)\nThe maximum likelihood classification will be performed using the GaussianNB() Function from the scikit-learn package. The GaussianNB() function implements the Gaussian Naive Bayes algorithm for classification. This function fits to the training data we extracted in the previous step and then predicting the class for each pixel in the raster image.\n# Train maximum likeihood classifier (Gaussian Naive Bayes)\nclassifier = GaussianNB()  # call model to use\nclassifier.fit(x_train, y_train)  # fit/train model to training data\n\n# Classify entier raster\npredicted = classifier.predict(flattened_raster)  # predict class to each pixel\nclassified_raster = predicted.reshape(\n    H, W\n)  # reshape prediction from flattened raster to original dimensions\nNow let’s plot the classified raster to see how this model worked.\n# Set appropriate colours for each class\ncolors = [\"#A6D96A\", \"#33A02C\", \"#DE3B13\", \"#D63CF1\", \"#00D2D2\", \"#F1A026\", \"#2B83BA\"]\ncmap = ListedColormap(colors)\n\n# Plot classified image\nplt.figure(figsize=(10, 10))  # initialize figure and set size\nplt.axis(\"off\")  # turn axis off for visualization\nplt.imshow(classified_raster, cmap=cmap)  # plot classified raster with defined colours\nUsing the validation polygons, we can extract the predicted classes and the ‘true’ values so we can calculate our accuracy metrics and create a confusion matrix.\n# Prepare validation data\ntrue_classes, predicted_classes = [], []  # empty lists for true and predicted classes\nfor idx, row in val_gdf.iterrows():  # iterate through each polygon\n    # Generate a mask for the polygon\n    mask = geometry_mask(\n        [row.geometry], transform=transform, invert=True, out_shape=(H, W)\n    )\n\n    # Extract true clas labels\n    true_label = row[\"lc_class_encoded\"]  # Column with the true encoded class labels\n    true_values = np.full(np.sum(mask), true_label)\n\n    # Extract predicted class labels from classified raster\n    predicted_values = classified_raster[mask]\n\n    # Append to lists\n    true_classes.extend(true_values)\n    predicted_classes.extend(predicted_values)\n\n# Convert lists to numpy arrays\ntrue_classes = np.array(true_classes)\npredicted_classes = np.array(predicted_classes)\nNow we can calculate the overall accuracy and F1 score.\n# Calculate accuracy metrics and print values\noa = accuracy_score(true_classes, predicted_classes)  # overall accuracy\nf1 = f1_score(true_classes, predicted_classes, average=\"weighted\")  # f1 score\nprint(f\"Overall Accuracy: {oa}\\nF1 Score: {f1}\")\nWe can also create a confusion matrix and calculate the Producer’s and User’s accuracies.\n# Create confusion matrix\nconf_matrix = confusion_matrix(true_classes, predicted_classes)\n\n# Calculate producers and users accuracies from confusion matrix\npa = np.diag(conf_matrix) / np.sum(conf_matrix, axis=1)  # producers accuracy\nua = np.diag(conf_matrix) / np.sum(conf_matrix, axis=0)  # users accuracy\n\n# Create dataframe for confusion matrix\nclasses = np.unique(gdf[\"lc_class\"])  # get unique class label\nconf_matrix_df = pd.DataFrame(\n    conf_matrix.T, index=classes, columns=classes\n)  # create dataframe\n\n# Add producers and users accuracies to dataframe\nconf_matrix_df.loc[\"Producer's Accuracy\"] = np.round(pa * 100, 3)\nconf_matrix_df[\"User's Accuracy\"] = np.append(\n    np.round(ua * 100, 2), [np.nan]\n)  # Append NaN for alignment\n\n# Add titles to show which values are Predicted and which are Actual\nconf_matrix_df.index.name = \"Predicted\"\nconf_matrix_df.columns.name = \"Actual\"\n\n# Print confusion matrix\nconf_matrix_df"
  },
  {
    "objectID": "CodingCrossover/scripts/supervised_classification.html#comparison-to-other-classifiers",
    "href": "CodingCrossover/scripts/supervised_classification.html#comparison-to-other-classifiers",
    "title": "Supervised Image Classification in Python",
    "section": "Comparison to other classifiers",
    "text": "Comparison to other classifiers\nNow that we have the training and validation data created we can run other classifiers to see how they differ. We should use the same data and split as we did previously for a true comparison.\n\nRandom Forest\nFirst lets try training a Random Forest Classification. In this example we will have 100 ‘trees’ in our forest but feel free to adjust this parameter to see how the output changes.\n\n# Train Random Forest Classifier\nrf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)  # call model to use and set parameters\nrf_classifier.fit(x_train, y_train)  # fit/train model to training data\n\n# Classify entier raster\npredicted = rf_classifier.predict(flattened_raster)  # predict class to each pixel\nclassified_raster = predicted.reshape(\n    H, W\n)  # reshape prediction from flattened raster to original dimensions\n\n\n# Set appropriate colours for each class\ncolors = [\"#A6D96A\", \"#33A02C\", \"#DE3B13\", \"#D63CF1\", \"#00D2D2\", \"#F1A026\", \"#2B83BA\"]\ncmap = ListedColormap(colors)\n\n# Plot classified image\nplt.figure(figsize=(10, 10))  # initialize figure and set size\nplt.axis(\"off\")  # turn axis off for visualization\nplt.imshow(classified_raster, cmap=cmap)  # plot classified raster with defined colours\n\n\n# Prepare validation data\ntrue_classes, predicted_classes = [], []  # empty lists for true and predicted classes\nfor idx, row in val_gdf.iterrows():  # iterate through each polygon\n    # Generate a mask for the polygon\n    mask = geometry_mask(\n        [row.geometry], transform=transform, invert=True, out_shape=(H, W)\n    )\n\n    # Extract true clas labels\n    true_label = row[\"lc_class_encoded\"]  # Column with the true encoded class labels\n    true_values = np.full(np.sum(mask), true_label)\n\n    # Extract predicted class labels from classified raster\n    predicted_values = classified_raster[mask]\n\n    # Append to lists\n    true_classes.extend(true_values)\n    predicted_classes.extend(predicted_values)\n\n# Convert lists to numpy arrays\ntrue_classes = np.array(true_classes)\npredicted_classes = np.array(predicted_classes)\n\n\n# Calculate accuracy metrics and print values\noa = accuracy_score(true_classes, predicted_classes)  # overall accuracy\nf1 = f1_score(true_classes, predicted_classes, average=\"weighted\")  # f1 score\nprint(f\"Overall Accuracy: {oa}\\nF1 Score: {f1}\")\n\nAn additional analysis we can do with Random Forest is see the feature importance of the different inputs for the classification.\n\nfeature_importance = rf_classifier.feature_importances_\nbands = [\"Blue\", \"Green\", \"Red\", \"NIR\", \"SWIR1\", \"SWIR2\"]\nfor band, importance in zip(bands, feature_importance):\n    print(f\"{band}: {importance}\")\n\nplt.figure(figsize=(10, 6))\nplt.barh(bands, feature_importance, color=\"orange\")\nplt.xlabel(\"Feature Importance\")\nplt.ylabel(\"Band\")\nplt.title(\"Feature Importance in Random Forest\")\nplt.show()\n\n\n# Create confusion matrix\nconf_matrix = confusion_matrix(true_classes, predicted_classes)\n\n# Calculate producers and users accuracies from confusion matrix\npa = np.diag(conf_matrix) / np.sum(conf_matrix, axis=1)  # producers accuracy\nua = np.diag(conf_matrix) / np.sum(conf_matrix, axis=0)  # users accuracy\n\n# Create dataframe for confusion matrix\nclasses = np.unique(gdf[\"lc_class\"])  # get unique class label\nconf_matrix_df = pd.DataFrame(\n    conf_matrix.T, index=classes, columns=classes\n)  # create dataframe\n\n# Add producers and users accuracies to dataframe\nconf_matrix_df.loc[\"Producer's Accuracy\"] = np.round(pa * 100, 3)\nconf_matrix_df[\"User's Accuracy\"] = np.append(\n    np.round(ua * 100, 2), [np.nan]\n)  # Append NaN for alignment\n\n# Add titles to show which values are Predicted and which are Actual\nconf_matrix_df.index.name = \"Predicted\"\nconf_matrix_df.columns.name = \"Actual\"\n\n# Print confusion matrix\nconf_matrix_df\n\n\n\nSupport Vector Machine\nNow lets train a Support Vector Machine (SVM).\n\n# Train Support Vector Machine (SVM) Classifier\nsvm_classifier = SVC(kernel='linear', C=1.0, random_state=42)  # call model to use and set parameters\nsvm_classifier.fit(x_train, y_train)  # fit/train model to training data\n\n# Classify entier raster\npredicted = svm_classifier.predict(flattened_raster)  # predict class to each pixel\nclassified_raster = predicted.reshape(\n    H, W\n)  # reshape prediction from flattened raster to original dimensions\n\n\n# Set appropriate colours for each class\ncolors = [\"#A6D96A\", \"#33A02C\", \"#DE3B13\", \"#D63CF1\", \"#00D2D2\", \"#F1A026\", \"#2B83BA\"]\ncmap = ListedColormap(colors)\n\n# Plot classified image\nplt.figure(figsize=(10, 10))  # initialize figure and set size\nplt.axis(\"off\")  # turn axis off for visualization\nplt.imshow(classified_raster, cmap=cmap)  # plot classified raster with defined colours\n\n\n# Prepare validation data\ntrue_classes, predicted_classes = [], []  # empty lists for true and predicted classes\nfor idx, row in val_gdf.iterrows():  # iterate through each polygon\n    # Generate a mask for the polygon\n    mask = geometry_mask(\n        [row.geometry], transform=transform, invert=True, out_shape=(H, W)\n    )\n\n    # Extract true clas labels\n    true_label = row[\"lc_class_encoded\"]  # Column with the true encoded class labels\n    true_values = np.full(np.sum(mask), true_label)\n\n    # Extract predicted class labels from classified raster\n    predicted_values = classified_raster[mask]\n\n    # Append to lists\n    true_classes.extend(true_values)\n    predicted_classes.extend(predicted_values)\n\n# Convert lists to numpy arrays\ntrue_classes = np.array(true_classes)\npredicted_classes = np.array(predicted_classes)\n\n\n# Calculate accuracy metrics and print values\noa = accuracy_score(true_classes, predicted_classes)  # overall accuracy\nf1 = f1_score(true_classes, predicted_classes, average=\"weighted\")  # f1 score\nprint(f\"Overall Accuracy: {oa}\\nF1 Score: {f1}\")\n\n\n# Create confusion matrix\nconf_matrix = confusion_matrix(true_classes, predicted_classes)\n\n# Calculate producers and users accuracies from confusion matrix\npa = np.diag(conf_matrix) / np.sum(conf_matrix, axis=1)  # producers accuracy\nua = np.diag(conf_matrix) / np.sum(conf_matrix, axis=0)  # users accuracy\n\n# Create dataframe for confusion matrix\nclasses = np.unique(gdf[\"lc_class\"])  # get unique class label\nconf_matrix_df = pd.DataFrame(\n    conf_matrix.T, index=classes, columns=classes\n)  # create dataframe\n\n# Add producers and users accuracies to dataframe\nconf_matrix_df.loc[\"Producer's Accuracy\"] = np.round(pa * 100, 3)\nconf_matrix_df[\"User's Accuracy\"] = np.append(\n    np.round(ua * 100, 2), [np.nan]\n)  # Append NaN for alignment\n\n# Add titles to show which values are Predicted and which are Actual\nconf_matrix_df.index.name = \"Predicted\"\nconf_matrix_df.columns.name = \"Actual\"\n\n# Print confusion matrix\nconf_matrix_df\n\n\n\nNeural Networks (Multi-Layer Perceptron)\nFinally, lets train a simple neural network to compare the other classification outputs. This neural network is a Multi-Layer Perceptron with three hidden layers containing 100, 50, and 25 neurons. Feel free to adjust the number of layers as well as the number of neurons to see how this changes the output.\n\n# Train Multi-Layer Perceptron Classifier\nmlp_classifier = MLPClassifier(\n    hidden_layer_sizes=(1000, 500, 250),  # Three hidden layer with 100, 50, and 25 neurons\n    activation='relu',         # Activation function for hidden layers\n    solver='adam',             # Optimization algorithm\n    max_iter=300,              # Maximum number of iterations\n    random_state=42\n)\nmlp_classifier.fit(x_train, y_train)  # fit/train model to training data\n\n# Classify entier raster\npredicted = mlp_classifier.predict(flattened_raster)  # predict class to each pixel\nclassified_raster = predicted.reshape(\n    H, W\n)  # reshape prediction from flattened raster to original dimensions\n\n\n# Set appropriate colours for each class\ncolors = [\"#A6D96A\", \"#33A02C\", \"#DE3B13\", \"#D63CF1\", \"#00D2D2\", \"#F1A026\", \"#2B83BA\"]\ncmap = ListedColormap(colors)\n\n# Plot classified image\nplt.figure(figsize=(10, 10))  # initialize figure and set size\nplt.axis(\"off\")  # turn axis off for visualization\nplt.imshow(classified_raster, cmap=cmap)  # plot classified raster with defined colours\n\n\n# Prepare validation data\ntrue_classes, predicted_classes = [], []  # empty lists for true and predicted classes\nfor idx, row in val_gdf.iterrows():  # iterate through each polygon\n    # Generate a mask for the polygon\n    mask = geometry_mask(\n        [row.geometry], transform=transform, invert=True, out_shape=(H, W)\n    )\n\n    # Extract true clas labels\n    true_label = row[\"lc_class_encoded\"]  # Column with the true encoded class labels\n    true_values = np.full(np.sum(mask), true_label)\n\n    # Extract predicted class labels from classified raster\n    predicted_values = classified_raster[mask]\n\n    # Append to lists\n    true_classes.extend(true_values)\n    predicted_classes.extend(predicted_values)\n\n# Convert lists to numpy arrays\ntrue_classes = np.array(true_classes)\npredicted_classes = np.array(predicted_classes)\n\n\n# Calculate accuracy metrics and print values\noa = accuracy_score(true_classes, predicted_classes)  # overall accuracy\nf1 = f1_score(true_classes, predicted_classes, average=\"weighted\")  # f1 score\nprint(f\"Overall Accuracy: {oa}\\nF1 Score: {f1}\")\n\n\n# Create confusion matrix\nconf_matrix = confusion_matrix(true_classes, predicted_classes)\n\n# Calculate producers and users accuracies from confusion matrix\npa = np.diag(conf_matrix) / np.sum(conf_matrix, axis=1)  # producers accuracy\nua = np.diag(conf_matrix) / np.sum(conf_matrix, axis=0)  # users accuracy\n\n# Create dataframe for confusion matrix\nclasses = np.unique(gdf[\"lc_class\"])  # get unique class label\nconf_matrix_df = pd.DataFrame(\n    conf_matrix.T, index=classes, columns=classes\n)  # create dataframe\n\n# Add producers and users accuracies to dataframe\nconf_matrix_df.loc[\"Producer's Accuracy\"] = np.round(pa * 100, 3)\nconf_matrix_df[\"User's Accuracy\"] = np.append(\n    np.round(ua * 100, 2), [np.nan]\n)  # Append NaN for alignment\n\n# Add titles to show which values are Predicted and which are Actual\nconf_matrix_df.index.name = \"Predicted\"\nconf_matrix_df.columns.name = \"Actual\"\n\n# Print confusion matrix\nconf_matrix_df"
  },
  {
    "objectID": "CodingCrossover/scripts/supervised_classification.html#questions",
    "href": "CodingCrossover/scripts/supervised_classification.html#questions",
    "title": "Supervised Image Classification in Python",
    "section": "Questions",
    "text": "Questions\nQuestion 1 - Why is it important to use the same training and validation data when comparing different model outputs?\nQuestion 2 - Which classifier performed best with your data? Why do you think this is?"
  },
  {
    "objectID": "CodingCrossover/codingcrossover.html#key-differences-in-python-vs.-r",
    "href": "CodingCrossover/codingcrossover.html#key-differences-in-python-vs.-r",
    "title": "Coding Crossover",
    "section": "Key Differences in Python vs. R",
    "text": "Key Differences in Python vs. R\nThere are some key differences between Python and R that may take some time to get used to when switching between them.\nIndexing:\n\nPython uses zero-based indexing (lists, arrays start from index 0).\nR uses one-based indexing (vectors, matrices start from index 1).\n\nData structures:\n\nPython’s primary sequence structures are lists (mutable) and tuples (immutable), and numpy arrays for numerical operations.\nR’s core structures are vectores, matrices, data frames and lists, where vectors are a fundamental unit of operation.\n\nVectorization and broadcasting\n\nR is inherently vectorized; many operations naturally apply element-wise without extra effort.\nPython requires libraries like NumPy for similar vectorized operations and broadcasting.\n\nFunction arguments\n\nIn Python, keyword arguments (kwargs) are passed by name after positional arguments, and default values are common.\nIn R, arguments can be matched by position or name, and partial argument matching (unique abbreviations) is allowed.\n\nAssignment\n\nPython uses = for assignment.\nR commonly uses &lt;- for assignment, though = can also be used.\n\nLooping and iteration\n\nPython encourages explicit loops (e.g., for, while), and list comprehension is widely used.\nsquares = [x**2 for x in range(10)] # example list comprehension\nR encourages vectorized operations and apply functions over explicit for loops for efficiency and clarity.\n\nString handling\n\nPython has robust built-in string operations, slicing and methods.\nR relies on more external packages (like stringr) for advanced text manipulation, though basic operations are available natively.",
    "crumbs": [
      "Coding Crossover"
    ]
  },
  {
    "objectID": "CodingCrossover/codingcrossover.html#common-geomatics-libraries",
    "href": "CodingCrossover/codingcrossover.html#common-geomatics-libraries",
    "title": "Coding Crossover",
    "section": "Common Geomatics Libraries",
    "text": "Common Geomatics Libraries\nR Libraries\n\n\n\n\n\n\n\nLibrary\nDescription\n\n\n\n\nterra\nFor spatial data manipulation, raster data processing, and geospatial analysis.\n\n\nsf\nFor handling vector spatial data, including shapefiles, GeoJSON, and other formats.\n\n\ndplyr\nFor data manipulation.\n\n\ncaret\nFor training and plotting classification and regression models.\n\n\nggplot2\nFor creating graphics with provided data.\n\n\n\nPython Libraries\n\n\n\n\n\n\n\nLibrary\nDescription\n\n\n\n\nrasterio\nFor raster file I/O and processing.\n\n\nnumpy\nFor numerical data manipulation, often used with raster data.\n\n\npandas\nFor tabular data manipulation.\n\n\ngeopandas\nFor handling vector spatial data, extending pandas to work with geospatial formats.\n\n\nshapely\nFor manipulation and analysis of geometric objects.\n\n\nscikit-learn\nFor training classification, regression, and clustering models, and data preprocessing.\n\n\nmatplotlib\nFor creating graphics with provided data.",
    "crumbs": [
      "Coding Crossover"
    ]
  },
  {
    "objectID": "CodingCrossover/codingcrossover.html#importing-libraries",
    "href": "CodingCrossover/codingcrossover.html#importing-libraries",
    "title": "Coding Crossover",
    "section": "Importing Libraries",
    "text": "Importing Libraries\nR\n# Import libraries \nlibrary(terra)     # For raster operations \nlibrary(sf)        # For vector operations \nlibrary(dplyr)     # For data manipulation \nlibrary(ggplot2)   # For creating visualizations\nPython\n# Import libraries\nimport rasterio                                                     # For raster operations \nimport geopandas as gpd                                             # For vector data \nimport numpy as np                                                  # For numerical data \nimport pandas as pd                                                 # For tabular data manipulation \nimport matplotlib.pyplot as plt                                     # For creating visulizations \nfrom rasterio.features import rasterize                             # For rasterizing vector data \nfrom rasterio.mask import mask                                      # For masking raster data \nfrom rasterio.warp import calculate_default_transform, reproject    # For raster reprojection \nfrom shapely.geometry import box                                    # For creating bounding box",
    "crumbs": [
      "Coding Crossover"
    ]
  },
  {
    "objectID": "CodingCrossover/codingcrossover.html#cheat-sheet-common-geomatics-functions",
    "href": "CodingCrossover/codingcrossover.html#cheat-sheet-common-geomatics-functions",
    "title": "Coding Crossover",
    "section": "Cheat Sheet: Common Geomatics Functions",
    "text": "Cheat Sheet: Common Geomatics Functions\n\n\n\n\n\n\n\n\nFunctionality\nR (terra, sf)\nPython (rasterio, geopandas, etc.)\n\n\n\n\nRead a shapefile\nshp &lt;- sf::st_read(\"path/to/file.shp\")\nshp = gpd.read_file(\"path/to/file.shp\")\n\n\nWrite a shapefile\nsf::st_write(shp, \"path/to/output.shp\")\nshp.to_file(\"path/to/output.shp\")\n\n\nRead a raster\nraster &lt;- terra::rast(\"path/to/file.tif\")\nwith rasterio.open(\"path/to/file.tif\") as src:\n    raster = src.read()\n\n\nWrite a raster\nterra::writeRaster(raster, \"path/to/output.tif\", overwrite=TRUE)\nwith rasterio.open(\"path/to/output.tif\", \"w\", **kwargs) as dst:\n    dst.write(raster)\n\n\nCalculate NDVI\nndvi &lt;- (nir - red) / (nir + red)\n(assuming nir and red are terra raster objects)\nndvi = (nir - red) / (nir + red)\n(assuming nir and red are numpy arrays)\n\n\nClip a raster by extent\nclipped &lt;- terra::crop(raster, extent)\nclipped, _ = mask(src, shapes, crop=True)\n\n\nClip a vector by extent\nclipped &lt;- sf::st_crop(vector, xmin = x1, ymin = y1, xmax = x2, ymax = y2)\nbbox = box(x1, y1, x2, y2)\nclipped = vector.clip(bbox)\n\n\nReproject a shapefile\nreproj &lt;- sf::st_transform(shp, crs = 4326)\nshp = shp.to_crs(epsg=4326)\n\n\nReproject a raster\nreproj &lt;- terra::project(raster, \"EPSG:4326\")\nreprojected_raster = reproject(src, transform)\n\n\nCalculate area of polygons\nshp$area &lt;- sf::st_area(shp)\nshp[\"area\"] = shp.geometry.area\n\n\nSort polygons by attribute\nsorted &lt;- shp[order(shp$attribute), ]\nsorted = shp.sort_values(\"attribute\")\n\n\nExtract raster values\nvalues &lt;- terra::extract(raster, sf::st_coordinates(points))\nvalues = [raster[row, col] for row, col in points] (requires array coordinates for numpy)\n\n\nBuffer around features\nbuffered &lt;- sf::st_buffer(shp, dist = 500)\nbuffered = shp.buffer(500)\n\n\nRasterize a vector layer\nrasterized &lt;- terra::rasterize(shp, raster)\nrasterized = rasterize([(geom, 1) for geom in shp.geometry], out_shape=shape, transform=transform)",
    "crumbs": [
      "Coding Crossover"
    ]
  },
  {
    "objectID": "CodingCrossover/codingcrossover.html#classification-example",
    "href": "CodingCrossover/codingcrossover.html#classification-example",
    "title": "Coding Crossover",
    "section": "Classification Example",
    "text": "Classification Example\nIn GEM520 there was a lab assignment that focused on how to perform a supervised image classification using QGIS and R to represent the 7 land cover classes for the Gulf Islands. Within this lab training and validation polygons were delineated using QGIS and then used to train a Maximum Likelihood Classifier in R. In this example we will be using those same polygons and Landsat image but we will be doing the classification step using Python instead.\nNote: it is recommended that you use the same polygons that you delineated for the lab to see if there are any differences in the outputs, but if you do not have them still you can access them here.\n\nStep 1\nBefore being able to run this example you will need to set up a Conda environment with the correct packages installed. To do this you will first need to download the create_environment.py script from here.\nNext you need to open up Anaconda Prompt and type in python [path/to/create_environment.py]. This will create a new Conda environment for you with the correct packages and then open a new Jupyter Lab IDE.\nNote: you do not need to run this example in the Jupter Lab IDE but the live tutorial will be done using it.\n\n\nStep 2\nOnce the environment is created and Jupyter Lab is opened you can download the supervised_classification.ipynb from here. This notebook will walk you through similar steps to the ones found in the original lab assignment. Open this notebook and run each of the code chunks.\nNote: you will need to change the file paths within this notebook to the ones in your system and run each code chunk to show your results.",
    "crumbs": [
      "Coding Crossover"
    ]
  }
]